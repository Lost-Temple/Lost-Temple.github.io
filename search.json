[{"title":"均值不等式-001","url":"/2024/05/18/均值不等式-001/","content":"\n# 均值不等式\n\n均值不等式是数学中一类重要的不等式，它描述了数列或函数的平均值与其他值之间的关系。常见的均值不等式包括算术平均值不小于几何平均值、几何平均值不小于调和平均值等。下面简要介绍一些常见的均值不等式：\n\n1. 调和平均值\n\n   $\n   E=mc^2\n   $\n\n","tags":["均值不等式"],"categories":["数学","初中"]},{"title":"Docker知识点02","url":"/2024/05/17/Docker知识点02/","content":"\n# 前言\n\n需要搭建spark集群以及hadoop集群，并且使它间之间进行交互。目标：编写一个yaml，用于一键部署。本文先试验一个个部署，最终形成一个一键部署的方案。\n\n# 实践\n\n## hadoop集群单机部署试验\n\n1. 拉取appache官方镜像\n\n   ```she\n   docker pull apache/hadoop\n   ```\n\n2. 在服务器本地目录创建所需文件\n\n   - 创建`docker-compose.yaml`文件\n\n     ```yaml\n     version: \"3\"\n     services:\n        namenode:\n           image: apache/hadoop:3\n           networks:\n             - hadoop_network\n           hostname: namenode\n           command: [\"hdfs\", \"namenode\"]\n           ports:\n             - 9870:9870\n             - 8020:8020\n           env_file:\n             - ./config\n           environment:\n               ENSURE_NAMENODE_DIR: \"/tmp/hadoop-root/dfs/name\"\n        datanode:\n           image: apache/hadoop:3\n           networks:\n             - hadoop_network\n           command: [\"hdfs\", \"datanode\"]\n           env_file:\n             - ./config\n        resourcemanager:\n           image: apache/hadoop:3\n           networks:\n             - hadoop_network\n           hostname: resourcemanager\n           command: [\"yarn\", \"resourcemanager\"]\n           ports:\n              - 8088:8088\n           env_file:\n             - ./config\n           volumes:\n             - ./test.sh:/opt/test.sh\n        nodemanager:\n           image: apache/hadoop:3\n           networks:\n             - hadoop_network\n           command: [\"yarn\", \"nodemanager\"]\n           env_file:\n             - ./config\n     networks:\n       hadoop_network:\n         name: hadoop-net\n     ```\n     \n     > 自定义网络，这样定义是会自动创建这个网络的\n     \n     如果网络已经存在，那可以这样指定(在后续我们一键部署时这个很重要，需要让每个容器在同一网络内，`docker stack` 部署还需要这个网络为`overlay`网络)\n     \n     ```yaml\n     networks:\n       hadoop_network:\n         external: true\n         name: hadoop-net\n     ```\n\n   - 上述文件中有一个`config`文件用来设置一些环境变量，所以我们再创建一个`config`文件\n\n     ```shell\n     CORE-SITE.XML_fs.default.name=hdfs://namenode\n     CORE-SITE.XML_fs.defaultFS=hdfs://namenode\n     HDFS-SITE.XML_dfs.namenode.rpc-address=namenode:8020\n     HDFS-SITE.XML_dfs.replication=1\n     MAPRED-SITE.XML_mapreduce.framework.name=yarn\n     MAPRED-SITE.XML_yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=$HADOOP_HOME\n     MAPRED-SITE.XML_mapreduce.map.env=HADOOP_MAPRED_HOME=$HADOOP_HOME\n     MAPRED-SITE.XML_mapreduce.reduce.env=HADOOP_MAPRED_HOME=$HADOOP_HOME\n     YARN-SITE.XML_yarn.resourcemanager.hostname=resourcemanager\n     YARN-SITE.XML_yarn.nodemanager.pmem-check-enabled=false\n     YARN-SITE.XML_yarn.nodemanager.delete.debug-delay-sec=600\n     YARN-SITE.XML_yarn.nodemanager.vmem-check-enabled=false\n     YARN-SITE.XML_yarn.nodemanager.aux-services=mapreduce_shuffle\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.maximum-applications=10000\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.maximum-am-resource-percent=0.1\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.resource-calculator=org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.queues=default\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.capacity=100\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.user-limit-factor=1\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.maximum-capacity=100\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.state=RUNNING\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.acl_submit_applications=*\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.acl_administer_queue=*\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.node-locality-delay=40\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.queue-mappings=\n     CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.queue-mappings-override.enable=false\n     ```\n\n     > 这里面没有指定`HADOOP_HOME`的值，部署的时候会有一个警告，但也不影响使用，后来我就在这个文件中，这个变量使用前，添加了一行`HADOOP_HOME=/opt/hadoop`\n\n3. 检查所需文件\n\n   ```shell\n   [centos@maodaoming-1 hadoop]$ ll\n   total 8\n   -rw-rw-r--. 1 centos centos 1789 May 17 09:21 config\n   -rw-rw-r--. 1 centos centos  984 May 17 11:04 docker-compose.yaml\n   ```\n\n# spark 集群单机部署\n\n因为是搭建FATE 2.1.0 版本的spark环境，所以使用的是使用FATE-Builder打包出来的spark镜像，包含：\n\n```shell\nyunpcds/spark-master        2.1.0-release   115b928c3b3d   21 hours ago    4.68GB\nyunpcds/spark-worker        2.1.0-release   371c1de5aabe   21 hours ago    4.68GB\n```\n\n1. 创建`docker-compose.yaml`文件\n\n```yaml\nversion: \"3\"\n\nservices:\n  spark-master:\n    hostname: spark-master\n    image: ${IMAGE_PREFIX}/spark-master:${IMAGE_TAG}\n    container_name: spark-master\n    restart: always\n    ports:\n      - \"8080:8080\"\n      - \"7077:7077\"\n      - \"6066:6066\"\n\n  spark-slave:\n    hostname: spark-slave\n    image: ${IMAGE_PREFIX}/spark-worker:${IMAGE_TAG}\n    container_name: spark-slave\n    restart: always\n    ports:\n      - \"8781:8081\"\n    volumes:\n      - /data/projects/:/data/projects/\n    environment:\n      SERVICE_PRECONDITION: \"spark-master:7077\"\n      EGGROLL_HOME: \"/data/projects/fate/eggroll\"\n      FATE_PROJECT_BASE: \"/data/projects/fate\"\n      VIRTUAL_ENV: \"/data/projects/python/venv\"\n      PYTHONPATH: \"/data/projects/fate/:/data/projects/fate/eggroll/python:/data/projects/fate/fate/python:/data/projects/fate/fateflow/python:/data/projects/fate/python\"\n      PATH: \"/data/projects/python/venv/bin:/opt/hadoop-3.2.3/bin:/opt/hive/bin:/opt/spark-3.1.3-bin-hadoop3.2/bin:/opt/hadoop-3.2.3/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\nnetworks:\n  spark_network:\n    name: spark-net\n```\n\n2. 变量设置文件:<font size=5>`.env`</font>文件\n\n```shell\nIMAGE_PREFIX=yunpcds\nIMAGE_TAG=2.1.0-release\n```\n\n> 这里面的变量会被传入到`docker-compose.yaml`中去,上面的PYTHONPATH, PATH根据实际情况再调整；还有<font size=5>volumes</font>的映射，需要把fate的代码拷贝到宿主机的对应目录`/data/projects/`\n\n3. 查看所需文件\n\n   ```shell\n   [centos@maodaoming-2 spark]$ ll -a\n   total 8\n   drwxrwxr-x. 2 centos centos   45 May 17 15:33 .\n   drwxrwxr-x. 4 centos centos   33 May 17 14:38 ..\n   -rw-rw-r--. 1 centos centos 1103 May 17 14:56 docker-compose.yaml\n   -rw-rw-r--. 1 centos centos   45 May 17 14:39 .env\n   ```\n\n# 一键部署\n\n把`docker-compose.yaml`合并成一份，使用docker stack部署：\n\n```yaml\nversion: \"3\"\nservices:\n  namenode:\n    image: apache/hadoop:3\n    hostname: namenode\n    command: [\"hdfs\", \"namenode\"]\n    networks:\n      - bigdata-network\n    ports:\n      - target: 9870\n        published: 9870\n        protocol: tcp\n        mode: host\n      - target: 9000\n        published: 9000\n        protocol: tcp\n        mode: host\n    env_file:\n      - ./config\n    environment:\n      ENSURE_NAMENODE_DIR: \"/tmp/hadoop-root/dfs/name\"\n    deploy:\n      endpoint_mode: dnsrr\n      placement:\n        constraints:\n          - 'node.labels.nodename == node55'\n  datanode:\n    image: apache/hadoop:3\n    command: [\"hdfs\", \"datanode\"]\n    networks:\n      - bigdata-network\n    env_file:\n      - ./config\n    ports:\n      - target: 1004\n        published: 1004\n        protocol: tcp\n        mode: host\n      - target: 1006\n        published: 1006\n        protocol: tcp\n        mode: host\n      - target: 9866\n        published: 9864\n        protocol: tcp\n        mode: host\n    deploy:\n      endpoint_mode: dnsrr\n      placement:\n        constraints:\n          - 'node.labels.nodename == node55'\n  resourcemanager:\n    image: apache/hadoop:3\n    hostname: resourcemanager\n    command: [\"yarn\", \"resourcemanager\"]\n    networks:\n      - bigdata-network\n    ports:\n      - 8088:8088\n    env_file:\n      - ./config\n    deploy:\n      placement:\n        constraints:\n          - 'node.labels.nodename == node55'\n  nodemanager:\n    image: apache/hadoop:3\n    command: [\"yarn\", \"nodemanager\"]\n    networks:\n      - bigdata-network\n    env_file:\n      - ./config\n    deploy:\n      placement:\n        constraints:\n          - 'node.labels.nodename == node55'\n\n  spark-master:\n    hostname: spark-master\n    image: ${IMAGE_PREFIX}/spark-master:${IMAGE_TAG}\n    container_name: spark-master\n    restart: always\n    networks:\n      - bigdata-network\n    ports:\n      - \"8080:8080\"\n      - \"7077:7077\"\n      - \"6066:6066\"\n    deploy:\n      placement:\n        constraints:\n          - 'node.role == manager'\n          - 'node.labels.nodename == node91'\n  spark-slave:\n    hostname: spark-worker\n    image: ${IMAGE_PREFIX}/spark-worker:${IMAGE_TAG}\n    container_name: spark-worker\n    restart: always\n    networks:\n      - bigdata-network\n    ports:\n      - \"8781:8081\"\n    volumes:\n      - /data/projects/:/data/projects/\n    environment:\n      SERVICE_PRECONDITION: \"spark-master:7077\"\n      EGGROLL_HOME: \"/data/projects/fate/eggroll\"\n      FATE_PROJECT_BASE: \"/data/projects/fate\"\n      VIRTUAL_ENV: \"/data/projects/python/venv\"\n      PYTHONPATH: \"/data/projects/fate/:/data/projects/fate/eggroll/python:/data/projects/fate/fate/python:/data/projects/fate/fateflow/python:/data/projects/fate/python\"\n      PATH: \"/data/projects/python/venv/bin:/opt/hadoop-3.2.3/bin:/opt/hive/bin:/opt/spark-3.1.3-bin-hadoop3.2/bin:/opt/hadoop-3.2.3/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n    deploy:\n      placement:\n        constraints:\n          - 'node.role == manager'\n          - 'node.labels.nodename == node91'\nvolumes:\n  hadoop_namenode:\n  hadoop_datanode1:\n  hadoop_datanode2:\n  hadoop_datanode3:\n  hadoop_historyserver:\n  kerberos_db:\n  kerberos_keytab:\n    driver_opts:\n      type: nfs\n      o: addr=192.168.11.74,nfsvers=4,minorversion=0,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport\n      device: :/home/centos/nfs_share/volume/bigdata/keytab\n  hive_metastore:\n  mysql_data:\n  linkis_log:\n  linkis_runtime:\nnetworks:\n  bigdata-network:\n    external: true\n    name: bigdata-network\n\n```\n\n> 注意：有volumes映射的一定要注意，如果路径不存在就启动失败\n\n启动脚本编写：\n\n```shell\ndocker stack rm bigdata\n\nsleep 1s\n\necho \"请注意清理nodedata的volume!!!\"\n\n[ -f .env ] && export $(sed '/^#/d' .env)\ndocker stack deploy -c docker-stack-deploy.yaml bigdata\n```\n\n启动后检查是否成功：\n\n```shell\n[centos@maodaoming-2 flow-spark-v2-env]$ docker service ls\n\ngzpqsvib86y6   bigdata_datanode          replicated   1/1        apache/hadoop:3\nproujh710xqf   bigdata_namenode          replicated   1/1        apache/hadoop:3\nfyok561q2qiv   bigdata_nodemanager       replicated   1/1        apache/hadoop:3\n72gzt56c9yrp   bigdata_resourcemanager   replicated   0/1        apache/hadoop:3                      *:8088->8088/tcp\nopo2n1jaa0bj   bigdata_spark-master      replicated   1/1        yunpcds/spark-master:2.1.0-release   *:6066->6066/tcp, *:7077->7077/tcp, *:8080->8080/tcp\nrsxhqoanjd3y   bigdata_spark-worker      replicated   1/1        yunpcds/spark-worker:2.1.0-release   *:8781->8081/tcp\nchwttx82rp8u   busybox                   replicated   1/1        busybox:latest\n```\n\n可以查看到`bigdata_resourcemanager`是启动失败的。可以用以下命令查看日志：\n\n```shell\n[centos@maodaoming-2 flow-spark-v2-env]$ docker service ps  --no-trunc bigdata_resourcemanager\n\nz8i8jbqpzz8zbmkh0w9k8i91o   bigdata_resourcemanager.1       apache/hadoop:3@sha256:af361b20bec0dfb13f03279328572ba764926e918c4fe716e197b8be2b08e37f   maodaoming-1.novalocal   Ready           Rejected 1 second ago     \"invalid mount config for type \"bind\": bind source path does not exist: /home/centos/flow-spark-v2-env/test.sh\"\nspmxmabdm0gikj33y4bxoot51    \\_ bigdata_resourcemanager.1   apache/hadoop:3@sha256:af361b20bec0dfb13f03279328572ba764926e918c4fe716e197b8be2b08e37f   maodaoming-1.novalocal   Shutdown        Rejected 6 seconds ago    \"invalid mount config for type \"bind\": bind source path does not exist: /home/centos/flow-spark-v2-env/test.sh\"\nzo68mawn5flwwejynq54iwus0    \\_ bigdata_resourcemanager.1   apache/hadoop:3@sha256:af361b20bec0dfb13f03279328572ba764926e918c4fe716e197b8be2b08e37f   maodaoming-1.novalocal   Shutdown        Rejected 11 seconds ago   \"invalid mount config for type \"bind\": bind source path does not exist: /home/centos/flow-spark-v2-env/test.sh\"\n60ew6r1iqf9wppbc3dojq0566    \\_ bigdata_resourcemanager.1   apache/hadoop:3@sha256:af361b20bec0dfb13f03279328572ba764926e918c4fe716e197b8be2b08e37f   maodaoming-1.novalocal   Shutdown        Rejected 17 seconds ago   \"invalid mount config for type \"bind\": bind source path does not exist: /home/centos/flow-spark-v2-env/test.sh\"\nnk9rzlaqqw2e1rr4ali2634mp    \\_ bigdata_resourcemanager.1   apache/hadoop:3@sha256:af361b20bec0dfb13f03279328572ba764926e918c4fe716e197b8be2b08e37f   maodaoming-1.novalocal   Shutdown        Rejected 21 seconds ago   \"invalid mount config for type \"bind\": bind source path does not exist: /home/centos/flow-spark-v2-env/test.sh\"\n```\n\n","tags":["swarm","overlay","docker stack","hadoop","spark"]},{"title":"vcpkg的使用记录","url":"/2024/04/24/vcpkg的使用记录/","content":"\n# 安装vcpkg\n\n## clone vcpkg\n```shell\ngit clone https://github.com/microsoft/vcpkg\n```\n\n## install vcpkg\n\n```shell\ncd vcpkg\n./bootstrap-vcpkg.sh\n```\n\n## 设置环境变量\n\n```shell\n# vcpkg\nexport VCPKG_ROOT=~/vcpkg\nexport PATH=$PATH:$VCPKG_ROOT\nexport VCPKG_DEFAULT_TRIPLET=arm64-osx\n```\n\n> VCPKG_DEFAULT_TRIPLET 设置了默认的TRIPLET，vcpkg install 时就无需指定triplet\n\n# vcpkg install\n\n## 安装boost\n\n```shell\nvcpkg install boost\n```\n\n在最后会出错，有警告信息如下：\n\n```shell\nCMake Warning at ports/python3/portfile.cmake:7 (message):\n  python3 currently requires the following programs from the system package\n  manager:\n\n      autoconf automake autoconf-archive\n\n  On Debian and Ubuntu derivatives:\n\n      sudo apt-get install autoconf automake autoconf-archive\n\n  On recent Red Hat and Fedora derivatives:\n\n      sudo dnf install autoconf automake autoconf-archive\n\n  On Arch Linux and derivatives:\n\n      sudo pacman -S autoconf automake autoconf-archive\n\n  On Alpine:\n\n      apk add autoconf automake autoconf-archive\n\n  On macOS:\n\n      brew install autoconf automake autoconf-archive\n```\n\n> 按照上述警告信息操作后再重新执行vcpkg install boost，成功\n\n## 安装nlohmann-json\n\n```shell\nvcpkg install nlohmann-json\n```\n\n# 创建c++项目\n\n### vcpkg 创建项目\n\n```shell\nmkdir helloworld && cd helloworld\nvcpkg new --application\n```\n\n> 会生成vcpkg.json文件，项目中的依赖库信息会保存在里面\n\n### 添加依赖\n\n```shell\nvcpkg add port nlohmann-json\n```\n\n执行后在`vcpkg.json`文件中会添加这个依赖：\n\n```json\n{\n  \"dependencies\": [\n    \"nlohmann-json\"\n  ]\n}\n```\n\n## 创建`CMakeLists.txt`文件\n\n```shell\ncmake_minimum_required(VERSION 3.10)\nproject(HelloWorld)\nadd_executable(HelloWorld helloworld.cpp)\nfind_package(nlohmann_json CONFIG REQUIRED)\ntarget_link_libraries(HelloWorld PRIVATE nlohmann_json::nlohmann_json)\n```\n\n> `CMakeLists.txt`中并没有指定nlohmann_json包的路径，那CMake怎么找到这些依赖包呢？那就要用到`CMakePresets.json`文件\n\n## 创建`CMakePresets.json`文件\n\n```json\n{\n  \"version\": 2,\n  \"configurePresets\": [\n    {\n      \"name\": \"default\",\n      \"generator\": \"Ninja\",\n      \"binaryDir\": \"${sourceDir}/build\",\n      \"cacheVariables\": {\n        \"CMAKE_TOOLCHAIN_FILE\": \"$env{VCPKG_ROOT}/scripts/buildsystems/vcpkg.cmake\"\n      }\n    }\n  ]\n}\n```\n\n> 这里就需要在环境变量中设置`VCPKG_ROOT`\n\n有了`CMakePresets.json`后，使用以下命令，会对cmake build 做一下一些前置的设置操作：\n\n```shell\ncmake --preset=default\n```\n\n## 编译\n\n```shell\ncmake --build build\n```\n\n","tags":["boost","vcpkg","CMake"],"categories":["C++","开发环境"]},{"title":"源码编译安装nasm","url":"/2024/03/05/源码编译安装nasm/","content":"\n# 从源代码编译安装 Nasm\n\n## 下载 Nasm 源代码\n\n```shell\nwget https://www.nasm.us/pub/nasm/releasebuilds/nasm-2.15.05.tar.gz\n```\n\n## 解压源代码\n\n```shell\ntar -xvzf nasm-2.15.05.tar.gz\n```\n\n## 进入源代码目录\n\n```shell\ncd nasm-2.15.05\n```\n\n## 配置编译环境\n\n```shell\n./configure\n```\n\n## 编译安装\n\n```shell\nmake && sudo make install\n```\n\n## 验证 Nasm 版本\n\n```shell\nnasm --version\n```\n","tags":["nasm"],"categories":["汇编"]},{"title":"Docker知识点01","url":"/2024/02/19/Docker知识点01/","content":"\n# 名词\n\n| 名词         | 说明                                                                                                                                                                                                                                            |\n|:-----------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Bridge 网络  | 1. Bridge 网络是 Docker 默认创建的网络模式。当您在 Docker 中创建一个新的容器时，默认会将容器连接到名为 bridge 的网络中 <br> 2. Bridge 网络允许容器与宿主机以及同一主机上的其他容器进行通信，但默认情况下不允许容器之间跨主机通信 <br> 3. Bridge 网络使用 Linux 系统上的桥接技术，在宿主机上创建一个虚拟的网桥设备，用于连接容器和主机的物理网络接口 <br> 4. Bridge 网络适用于单个主机上的容器通信 |\n| Overlay 网络 | 1. Overlay 网络用于跨多个 Docker 主机构建容器集群，并允许集群中的容器之间进行跨主机通信 <br> 2. Overlay 网络使用了 VxLAN 技术，在不同主机上创建虚拟的 Overlay 网络，容器可以通过该网络进行通信 <br> 3. Overlay 网络通常用于 Docker Swarm 集群或 Kubernetes 集群中，用于构建分布式应用和微服务架构 <br> 4. Overlay 网络适用于跨多个主机的容器通信              |\n| MTU        | 最大传输单元MTU（Maximum Transmission Unit，MTU），是指网络能够传输的最大数据包大小，以字节为单位。MTU的大小决定了发送端一次能够发送报文的最大字节数。如果MTU超过了接收端所能够承受的最大值，或者是超过了发送路径上途经的某台设备所能够承受的最大值，就会造成报文分片甚至丢弃，加重网络传输的负担。如果太小，那实际传送的数据量就会过小，影响传输效率。                                                |\n\n# Overlay网络\n\ndocker swarm在启动的过程中会创建两个默认的网络：docker_gwbridge和ingress.\n- **docker_gwbridge**：通过这个网络，容器可以连接到宿主机。（它的driver就是bridge)\n- **ingress**：由docker swarm创建的overlay网络，这个网络用于将服务暴露给外部访问，docker swarm就是通过它实现的routing mesh（将外部请求路由到不同主机的容器）。\n\n例子如下：\n```Shell\n[centos@bd-2 ~]$ docker network ls\nNETWORK ID     NAME                           DRIVER    SCOPE\n69477a3560e9   bridge                         bridge    local\n320cd9ae8475   centos_default                 bridge    local\nd344065cc4cc   docker_gwbridge                bridge    local\nda5d24e5d251   flow-admin-backend_admin-net   bridge    local\n4d5b92424942   flow-admin-front_admin-net     bridge    local\nqqfrntz0lrex   hadoop-com                     overlay   swarm\n5cd8e1bc97a5   host                           host      local\nmtysig457puz   ingress                        overlay   swarm\n7ad98d08bd3c   none                           null      local  \n```\n\n# docker0的mtu\nmtu查看\n```Shell\nifconfig | grep mtu\n```\n如果宿主机的mtu比docker0的mtu还小，网络会存在问题，所以是需要修改docker0的mtu\n\n我直接通过修改/etc/docker/daemon.json文件：\n```JSON\n{\n    \"log-driver\":\"json-file\",\n    \"log-opts\": {\"max-size\":\"200m\", \"max-file\":\"3\"},\n    \"live-restore\": false,\n    \"mtu\": 1450,\n    \"insecure-registries\":[\"192.168.10.166:88\",\"192.168.9.68\",\"192.168.11.149:8888\",\"192.168.11.168:8888\"]\n}\n```\n\n重启docker\n\n```Shell\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n重新查看mtu，如果docker中此时没有容器在运行，那会发现docker0的mtu还是原先的值。这里有坑：当docker中有容器在运行时，再去查看docker0的mtu就生效了。\n强迫症可以修改daemon.json配置，重启docker服务后，再使用命令临时修改docker0的mtu：\n```Shell\nsudo ip link set docker0 mtu 1450\n```\n\n# Swarm集群搭建\n初始化manager节点\n```Shell\ndocker swarm init --advertise-addr 192.168.10.91:2377\n```\n正常情况输出类似以下的提示：\n```Shell\nSwarm initialized: current node (tg66scjfm2kgw5z7pb7vpnrye) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-4e22sso1h4dofwqzq25a6crgc9fzk4it6237jdd6ezuzqknsw5-79qgv3b9sc88wa8jk5etylpty 192.168.10.91:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n```\n\n后续想要查看怎么加入到swarm集群，使用以下命令:\n```Shell\n# 获取Manager节点加入命令\ndocker swarm join-token manager\n\n# 获取Worker节点加入命令\ndocker swarm join-token worker\n```\n\n可以到work节点上执行：\n```Shell\ndocker swarm join --token SWMTKN-1-4e22sso1h4dofwqzq25a6crgc9fzk4it6237jdd6ezuzqknsw5-79qgv3b9sc88wa8jk5etylpty 192.168.10.91:2377\n\n```\n\n如果是多manager的话，可以在其它manager节点执行：\n```Shell\ndocker swarm join --token SWMTKN-1-4e22sso1h4dofwqzq25a6crgc9fzk4it6237jdd6ezuzqknsw5-2ccx8qd17rc0ydci0kcw9qfy2 192.168.10.91:2377\n```\n\n> 这里有坑，就是docker的daemon.json中配置的mtu，对于swarm的overlay网络是不起作用的。\n\n修改overlay网络的mtu和eth0,docker0的mtu保持一致\n1. 在manager节点中先获取子网信息\n    ```Shell\n    docker network inspect -f '{{json .IPAM}}' docker_gwbridge\n    ```\n   返回：\n    ```Shell\n    {\"Driver\":\"default\",\"Options\":null,\"Config\":[{\"Subnet\":\"172.18.0.0/16\",\"Gateway\":\"172.18.0.1\"}]} \n   ```\n2. manager节点退出swarm集群(自定义docker_gwbridge网络，则必须在将 Docker 主机加入 swarm 之前或暂时从 swarm 中移除后进行)\n    ```Shell\n    docker swarm leave --force\n    ```\n3. manager节点停掉docker服务\n    ```Shell\n    sudo systemctl stop docker.service\n    ```\n4. manager节点中删掉虚拟网卡docker_gwbridge\n    ```Shell\n    sudo ip link set docker_gwbridge down\n    sudo ip link del dev docker_gwbridge\n    ```\n5. manager节点中启动docker\n    ```Shell\n    sudo systemctl start docker.service\n    ```\n6. manager节点中重建docker_gwbridge（这一步用到了第1步获取的子网信息以及设置我们要的mtu值）\n    ```Shell\n    docker network rm docker_gwbridge\n    docker network create \\\n      --subnet 172.18.0.0/16 \\\n      --gateway 172.18.0.1 \\\n      --opt com.docker.network.bridge.name=docker_gwbridge \\\n      --opt com.docker.network.bridge.enable_icc=false \\\n      --opt com.docker.network.bridge.enable_ip_masquerade=true \\\n      --opt com.docker.network.driver.mtu=1450 \\\n      docker_gwbridge\n    ```\n   **再到work节点上执行相同的命令执行1~6步骤**完成docker_gwbridge网络的自定义创建\n\n7. manager节点中查看ingress网络信息\n   ```Shell\n   docker network inspect -f '{{json .IPAM}}' ingress\n   ```\n   返回\n   ```Shell\n   {\"Driver\":\"default\",\"Options\":null,\"Config\":[{\"Subnet\":\"10.0.0.0/24\",\"Gateway\":\"10.0.0.1\"}]}\n   ```\n8. manager节点中删除ingress network\n   ```Shell\n   docker network rm ingress\n   ```\n   > 这一步会有个警告\n\n   ```Shell\n   WARNING! Before removing the routing-mesh network, make sure all the nodes in your swarm run the same docker engine version. Otherwise, removal may not be effective and functionality of newly create ingress networks will be impaired.\n   ```\n   > 所以swarm中的节点的docker版本最好保持一致\n\n9. manager节点中重建ingress(记得使用之前查看的ingress网络中的子网以及网关，mtu自定义修改)\n   ```Shell\n   docker network create \\\n     --driver overlay \\\n     --ingress \\\n     --subnet=10.0.0.0/24 \\\n     --gateway=10.0.0.1 \\\n     --opt com.docker.network.driver.mtu=1450 \\\n     ingress\n   ```\n\n10. 然后就是其它的manager节点/worker节点的加入了\n   > **注意：新机器在join到swarm之前，得先重建docker_gwbridge(mtu得保持一致）**\n\n11. 验证mtu是否都按我们定义的修改了\n   启动一个swarm service\n   ```Shell\n   docker service create -td --name busybox busybox\n   ```\n   查看mtu\n   ```Shell\n   ifconfig | grep mtu\n   ```\n   返回\n   ```Shell\n   docker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n   docker_gwbridge: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n   eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n   lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n   veth21384b6: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n   veth41d39c5: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n   ```\n\n\n","tags":["swarm","docker","mtu","bridge","overlay","network"]},{"title":"nfs共享目录","url":"/2024/02/18/nfs共享目录/","content":"\n# nfs 服务\n\n1. 安装 NFS 服务器软件包：首先，在 Fedora 系统上安装 NFS 服务器软件包。NFS 服务器软件包通常是`nfs-utils`，你可以使用以下命令安装：\n    ```Shell\n    sudo dnf install nfs-utils\n    \n    ```\n\n2. 配置`NFS`服务器：`NFS` 服务器的配置文件是`/etc/exports`，你需要编辑这个文件来指定要共享的目录和相关的共享选项。比如，你可以使用`vi`或者其他文本编辑器来编辑`/etc/exports`文件：\n\n    ```Shell\n    sudo vi /etc/exports\n    ```\n\n   在打开的文件中，你可以添加类似如下的行来指定共享的目录和相关选项：\n    ```Shell\n    /home/maodaoming/nfs_share/volume *(rw,sync,no_root_squash,no_subtree_check,insecure)\n    ```\n   这行表示将 /home/maodaoming/nfs_share/volume 目录共享给所有客户端,还定义了相应的权限\n\n3. 重载 NFS 服务器配置：编辑完成 /etc/exports 文件后，你需要重新加载 NFS 服务器配置使之生效。你可以使用以下命令来重新加载：\n    ```Shell\n    sudo exportfs -r\n    ```\n   这个命令会重新加载 /etc/exports 文件中的配置，并使新的共享目录生效。\n\n4. 启动 NFS 服务器：使用以下命令启动 NFS 服务器：\n    ```Shell\n    sudo systemctl start nfs-server\n    ```\n5. 设置开机启动\n    ```Shell\n    sudo systemctl enable nfs-server\n    ```\n\n# 客户端\n\n1. 创建本地挂载点：在 macOS 上创建一个本地目录，用于挂载 NFS 共享。例如，你可以在 macOS 上创建一个名为 /mnt/nfs_share 的目录：\n    ```Shell\n    sudo mkdir -p /mnt/nfs_share\n    ```\n2. 挂载 NFS 共享：使用 mount 命令挂载 NFS 共享。你需要指定 NFS 服务器的 IP 地址（或主机名）以及共享的远程目录和本地挂载点。例如：\n    ```Shell\n    sudo mount -t nfs <NFS服务器IP>:/home/maodaoming/nfs_share/volume /mnt/nfs_share\n    ```\n\n3. ~~卸载挂载点~~\n    ```Shell\n    sudo umount /mnt/nfs_share\n    ```\n\n","tags":["nfs"],"categories":["Linux"]},{"title":"Flink原理与实现:Window机制","url":"/2023/12/14/Flink-原理与实现-Window-机制/","content":"\n# 简介\n\nFlink 认为 Batch 是 Streaming 的一个特例，所以 Flink 底层引擎是一个流式引擎，在上面实现了流处理和批处理。而窗口（window）就是从 Streaming 到 Batch 的一个桥梁。Flink 提供了非常完善的窗口机制，这是我认为的 Flink 最大的亮点之一（其他的亮点包括消息乱序处理，和 checkpoint 机制）。本文我们将介绍流式处理中的窗口概念，介绍 Flink 内建的一些窗口和 Window API，最后讨论下窗口在底层是如何实现的。\n\n\n# 什么是 Window\n\n在流处理应用中，数据是连续不断的，因此我们不可能等到所有数据都到了才开始处理。当然我们可以每来一个消息就处理一次，但是有时我们需要做一些聚合类的处理，例如：在过去的1分钟内有多少用户点击了我们的网页。在这种情况下，我们必须定义一个窗口，用来收集最近一分钟内的数据，并对这个窗口内的数据进行计算。\n\n窗口可以是时间驱动的（Time Window，例如：每30秒钟），也可以是数据驱动的（Count Window，例如：每一百个元素）。一种经典的窗口分类可以分成：翻滚窗口（Tumbling Window，无重叠），滚动窗口（Sliding Window，有重叠），和会话窗口（Session Window，活动间隙）。\n\n我们举个具体的场景来形象地理解不同窗口的概念。假设，淘宝网会记录每个用户每次购买的商品个数，我们要做的是统计不同窗口中用户购买商品的总数。下图给出了几种经典的窗口切分概述图：\n\n![窗口切分概述图](./Flink-原理与实现-Window-机制/Snipaste_2023-12-14_11-17-27.png)\n\n上图中，raw data stream 代表用户的购买行为流，圈中的数字代表该用户本次购买的商品个数，事件是按时间分布的，所以可以看出事件之间是有time gap的。Flink 提供了上图中所有的窗口类型，下面我们会逐一进行介绍。\n\n\n# Time Window\n\n就如名字所说的，Time Window 是根据时间对数据流进行分组的。这里我们涉及到了流处理中的时间问题，时间问题和消息乱序问题是紧密关联的，这是流处理中现存的难题之一，我们将在后续的 EventTime 和消息乱序处理 中对这部分问题进行深入探讨。这里我们只需要知道 Flink 提出了三种时间的概念，分别是event time（事件时间：事件发生时的时间），ingestion time（摄取时间：事件进入流处理系统的时间），processing time（处理时间：消息被计算处理的时间）。Flink 中窗口机制和时间类型是完全解耦的，也就是说当需要改变时间类型时不需要更改窗口逻辑相关的代码。\n\n## Tumbling Time Window\n\n如上图，我们需要统计每一分钟中用户购买的商品的总数，需要将用户的行为事件按每一分钟进行切分，这种切分被成为翻滚时间窗口（Tumbling Time Window）。翻滚窗口能将数据流切分成不重叠的窗口，每一个事件只能属于一个窗口。通过使用 DataStream API，我们可以这样实现：\n\n```scala\n// Stream of (userId, buyCnt)\nval buyCnts: DataStream[(Int, Int)] = ...\n\nval tumblingCnts: DataStream[(Int, Int)] = buyCnts\n  // key stream by userId\n  .keyBy(0) \n  // tumbling time window of 1 minute length\n  .timeWindow(Time.minutes(1))\n  // compute sum over buyCnt\n  .sum(1)\n```\n\n## Sliding Time Window\n\n但是对于某些应用，它们需要的窗口是不间断的，需要平滑地进行窗口聚合。比如，我们可以每30秒计算一次最近一分钟用户购买的商品总数。这种窗口我们称为滑动时间窗口（Sliding Time Window）。在滑窗中，一个元素可以对应多个窗口。通过使用 DataStream API，我们可以这样实现：\n\n```scala\nval slidingCnts: DataStream[(Int, Int)] = buyCnts\n  .keyBy(0) \n  // sliding time window of 1 minute length and 30 secs trigger interval\n  .timeWindow(Time.minutes(1), Time.seconds(30))\n  .sum(1)\n```\n\n# Count Window\n\nCount Window 是根据元素个数对数据流进行分组的。\n\n## Tumbling Count Window\n\n当我们想要每100个用户购买行为事件统计购买总数，那么每当窗口中填满100个元素了，就会对窗口进行计算，这种窗口我们称之为翻滚计数窗口（Tumbling Count Window），上图所示窗口大小为3个。通过使用 DataStream API，我们可以这样实现：\n\n```scala\n// Stream of (userId, buyCnts)\nval buyCnts: DataStream[(Int, Int)] = ...\n\nval tumblingCnts: DataStream[(Int, Int)] = buyCnts\n  // key stream by sensorId\n  .keyBy(0)\n  // tumbling count window of 100 elements size\n  .countWindow(100)\n  // compute the buyCnt sum \n  .sum(1)\n```\n\n## Sliding Count Window\n\n当然Count Window 也支持 Sliding Window，虽在上图中未描述出来，但和Sliding Time Window含义是类似的，例如每10个元素计算一次最近100个元素的总和，代码示例如下。\n\n```scala\nval slidingCnts: DataStream[(Int, Int)] = vehicleCnts\n  .keyBy(0)\n  // sliding count window of 100 elements size and 10 elements trigger interval\n  .countWindow(100, 10)\n  .sum(1)\n```\n\n# Session Window\n\n在这种用户交互事件流中，我们首先想到的是将事件聚合到会话窗口中（一段用户持续活跃的周期），由非活跃的间隙分隔开。如上图所示，就是需要计算每个用户在活跃期间总共购买的商品数量，如果用户30秒没有活动则视为会话断开（假设raw data stream是单个用户的购买行为流）。Session Window 的示例代码如下：\n\n```scala\n// Stream of (userId, buyCnts)\nval buyCnts: DataStream[(Int, Int)] = ...\n    \nval sessionCnts: DataStream[(Int, Int)] = vehicleCnts\n    .keyBy(0)\n    // session window based on a 30 seconds session gap interval \n    .window(ProcessingTimeSessionWindows.withGap(Time.seconds(30)))\n    .sum(1)\n```\n\n一般而言，window 是在无限的流上定义了一个有限的元素集合。这个集合可以是基于时间的，元素个数的，时间和个数结合的，会话间隙的，或者是自定义的。Flink 的 DataStream API 提供了简洁的算子来满足常用的窗口操作，同时提供了通用的窗口机制来允许用户自己定义窗口分配逻辑。下面我们会对 Flink 窗口相关的 API 进行剖析。\n\n# 剖析 Window API\n\n得益于 Flink Window API 松耦合设计，我们可以非常灵活地定义符合特定业务的窗口。Flink 中定义一个窗口主要需要以下三个组件。\n\n- Window Assigner：用来决定某个元素被分配到哪个/哪些窗口中去。\n\n  如下类图展示了目前内置实现的 Window Assigners：\n\n  ![WindowAssigners](./Flink-原理与实现-Window-机制/WindowAssigners.png)\n\n- Trigger：触发器。决定了一个窗口何时能够被计算或清除，每个窗口都会拥有一个自己的Trigger。\n\n  如下类图展示了目前内置实现的 Triggers：\n  ![Triggers](./Flink-原理与实现-Window-机制/Triggers.png)\n\n- Evictor：可以译为“驱逐者”。在Trigger触发之后，在窗口被处理之前，Evictor（如果有Evictor的话）会用来剔除窗口中不需要的元素，相当于一个filter。\n\n  如下类图展示了目前内置实现的 Evictors：\n  ![Evictors](./Flink-原理与实现-Window-机制/Evictors.png)\n\n上述三个组件的不同实现的不同组合，可以定义出非常复杂的窗口。Flink 中内置的窗口也都是基于这三个组件构成的，当然内置窗口有时候无法解决用户特殊的需求，所以 Flink 也暴露了这些窗口机制的内部接口供用户实现自定义的窗口。下面我们将基于这三者探讨窗口的实现机制。\n\n\n# Window 的实现\n\n下图描述了 Flink 的窗口机制以及各组件之间是如何相互工作的。\n\n![组件交互](./Flink-原理与实现-Window-机制/组件交互.png)\n\n首先上图中的组件都位于一个算子（window operator）中，数据流源源不断地进入算子，每一个到达的元素都会被交给 WindowAssigner。WindowAssigner 会决定元素被放到哪个或哪些窗口（window），可能会创建新窗口。因为一个元素可以被放入多个窗口中，所以同时存在多个窗口是可能的。注意，Window本身只是一个ID标识符，其内部可能存储了一些元数据，如TimeWindow中有开始和结束时间，但是并不会存储窗口中的元素。窗口中的元素实际存储在 Key/Value State 中，key为Window，value为元素集合（或聚合值）。为了保证窗口的容错性，该实现依赖了 Flink 的 State 机制（参见 [state 文档](https://ci.apache.org/projects/flink/flink-docs-master/apis/streaming/state.html?spm=a2c6h.12873639.article-detail.8.571d3dd5xKjhTf)）。\n\n\n每一个窗口都拥有一个属于自己的 Trigger，Trigger上会有定时器，用来决定一个窗口何时能够被计算或清除。每当有元素加入到该窗口，或者之前注册的定时器超时了，那么Trigger都会被调用。Trigger的返回结果可以是 continue（不做任何操作），fire（处理窗口数据），purge（移除窗口和窗口中的数据），或者 fire + purge。一个Trigger的调用结果只是fire的话，那么会计算窗口并保留窗口原样，也就是说窗口中的数据仍然保留不变，等待下次Trigger fire的时候再次执行计算。一个窗口可以被重复计算多次直到它被 purge 了。在purge之前，窗口会一直占用着内存。\n\n当Trigger fire了，窗口中的元素集合就会交给Evictor（如果指定了的话）。Evictor 主要用来遍历窗口中的元素列表，并决定最先进入窗口的多少个元素需要被移除。剩余的元素会交给用户指定的函数进行窗口的计算。如果没有 Evictor 的话，窗口中的所有元素会一起交给函数进行计算。\n\n计算函数收到了窗口的元素（可能经过了 Evictor 的过滤），并计算出窗口的结果值，并发送给下游。窗口的结果值可以是一个也可以是多个。DataStream API 上可以接收不同类型的计算函数，包括预定义的sum(),min(),max()，还有 ReduceFunction，FoldFunction，还有WindowFunction。WindowFunction 是最通用的计算函数，其他的预定义的函数基本都是基于该函数实现的。\n\nFlink 对于一些聚合类的窗口计算（如sum,min）做了优化，因为聚合类的计算不需要将窗口中的所有数据都保存下来，只需要保存一个result值就可以了。每个进入窗口的元素都会执行一次聚合函数并修改result值。这样可以大大降低内存的消耗并提升性能。但是如果用户定义了 Evictor，则不会启用对聚合窗口的优化，因为 Evictor 需要遍历窗口中的所有元素，必须要将窗口中所有元素都存下来。\n\n# 源码分析\n\n上述的三个组件构成了 Flink 的窗口机制。为了更清楚地描述窗口机制，以及解开一些疑惑（比如 purge 和 Evictor 的区别和用途），我们将一步步地解释 Flink 内置的一些窗口（Time Window，Count Window，Session Window）是如何实现的。\n\n## Count Window 实现\n\nCount Window 是使用三组件的典范，我们可以在 KeyedStream 上创建 Count Window，其源码如下所示：\n\n```java\n// tumbling count window\npublic WindowedStream<T, KEY, GlobalWindow> countWindow(long size) {\n    return window(GlobalWindows.create())  // create window stream using GlobalWindows\n        .trigger(PurgingTrigger.of(CountTrigger.of(size))); // trigger is window size\n}\n// sliding count window\npublic WindowedStream<T, KEY, GlobalWindow> countWindow(long size, long slide) {\n    return window(GlobalWindows.create())\n        .evictor(CountEvictor.of(size))  // evictor is window size\n        .trigger(CountTrigger.of(slide)); // trigger is slide size\n}\n```\n\n第一个函数是申请翻滚计数窗口，参数为窗口大小。第二个函数是申请滑动计数窗口，参数分别为窗口大小和滑动大小。它们都是基于 GlobalWindows 这个 WindowAssigner 来创建的窗口，该assigner会将所有元素都分配到同一个global window中，所有GlobalWindows的返回值一直是 GlobalWindow 单例。基本上自定义的窗口都会基于该assigner实现。\n\n翻滚计数窗口并不带evictor，只注册了一个trigger。该trigger是带purge功能的 CountTrigger。也就是说每当窗口中的元素数量达到了 window-size，trigger就会返回fire+purge，窗口就会执行计算并清空窗口中的所有元素，再接着储备新的元素。从而实现了tumbling的窗口之间无重叠。\n\n滑动计数窗口的各窗口之间是有重叠的，但我们用的 GlobalWindows assinger 从始至终只有一个窗口，不像 sliding time assigner 可以同时存在多个窗口。所以trigger结果不能带purge，也就是说计算完窗口后窗口中的数据要保留下来（供下个滑窗使用）。另外，trigger的间隔是slide-size，evictor的保留的元素个数是window-size。也就是说，每个滑动间隔就触发一次窗口计算，并保留下最新进入窗口的window-size个元素，剔除旧元素。\n\n假设有一个滑动计数窗口，每2个元素计算一次最近4个元素的总和，那么窗口工作示意图如下所示：\n\n![窗口工作示意图](./Flink-原理与实现-Window-机制/窗口工作示意图.png)\n\n图中所示的各个窗口逻辑上是不同的窗口，但在物理上是同一个窗口。该滑动计数窗口，trigger的触发条件是元素个数达到2个（每进入2个元素就会触发一次），evictor保留的元素个数是4个，每次计算完窗口总和后会保留剩余的元素。所以第一次触发trigger是当元素5进入，第三次触发trigger是当元素2进入，并驱逐5和2，计算剩余的4个元素的总和（22）并发送出去，保留下2,4,9,7元素供下个逻辑窗口使用。\n\n## Time Window 实现\n\n同样的，我们也可以在 KeyedStream 上申请 Time Window，其源码如下所示：\n\n```java\n// tumbling time window\npublic WindowedStream<T, KEY, TimeWindow> timeWindow(Time size) {\n    if (environment.getStreamTimeCharacteristic() == TimeCharacteristic.ProcessingTime) {\n        return window(TumblingProcessingTimeWindows.of(size));\n    } else {\n        return window(TumblingEventTimeWindows.of(size));\n    }\n}\n// sliding time window\npublic WindowedStream<T, KEY, TimeWindow> timeWindow(Time size, Time slide) {\n    if (environment.getStreamTimeCharacteristic() == TimeCharacteristic.ProcessingTime) {\n        return window(SlidingProcessingTimeWindows.of(size, slide));\n    } else {\n        return window(SlidingEventTimeWindows.of(size, slide));\n    }\n}\n```\n\n在方法体内部会根据当前环境注册的时间类型，使用不同的WindowAssigner创建window。可以看到，EventTime和IngestTime都使用了XXXEventTimeWindows这个assigner，因为EventTime和IngestTime在底层的实现上只是在Source处为Record打时间戳的实现不同，在window operator中的处理逻辑是一样的。\n\n这里我们主要分析sliding process time window，如下是相关源码：\n\n```java\npublic class SlidingProcessingTimeWindows extends WindowAssigner<Object, TimeWindow> {\n    private static final long serialVersionUID = 1L;\n\n    private final long size;\n\n    private final long slide;\n\n    private SlidingProcessingTimeWindows(long size, long slide) {\n        this.size = size;\n        this.slide = slide;\n    }\n\n    @Override\n    public Collection<TimeWindow> assignWindows(Object element, long timestamp) {\n        timestamp = System.currentTimeMillis();\n        List<TimeWindow> windows = new ArrayList<>((int) (size / slide));\n        // 对齐时间戳\n        long lastStart = timestamp - timestamp % slide;\n        for (long start = lastStart;\n            start > timestamp - size;\n            start -= slide) {\n            // 当前时间戳对应了多个window\n            windows.add(new TimeWindow(start, start + size));\n        }\n        return windows;\n    }\n    ...\n}\npublic class ProcessingTimeTrigger extends Trigger<Object, TimeWindow> {\n    @Override\n    // 每个元素进入窗口都会调用该方法\n    public TriggerResult onElement(Object element, long timestamp, TimeWindow window, TriggerContext ctx) {\n        // 注册定时器，当系统时间到达window end timestamp时会回调该trigger的onProcessingTime方法\n        ctx.registerProcessingTimeTimer(window.getEnd());\n        return TriggerResult.CONTINUE;\n    }\n\n    @Override\n    // 返回结果表示执行窗口计算并清空窗口\n    public TriggerResult onProcessingTime(long time, TimeWindow window, TriggerContext ctx) {\n        return TriggerResult.FIRE_AND_PURGE;\n    }\n    ...\n}\n```\n\n首先，SlidingProcessingTimeWindows会对每个进入窗口的元素根据系统时间分配到(size / slide)个不同的窗口，并会在每个窗口上根据窗口结束时间注册一个定时器（相同窗口只会注册一份），当定时器超时时意味着该窗口完成了，这时会回调对应窗口的Trigger的onProcessingTime方法，返回FIRE_AND_PURGE，也就是会执行窗口计算并清空窗口。整个过程示意图如下：\n\n![示意图](./Flink-原理与实现-Window-机制/202312141604.png)\n\n\n如上图所示横轴代表时间戳（为简化问题，时间戳从0开始），第一条record会被分配到[-5,5)和[0,10)两个窗口中，当系统时间到5时，就会计算[-5,5)窗口中的数据，并将结果发送出去，最后清空窗口中的数据，释放该窗口资源。\n\n","tags":["Flink","window"],"categories":["大数据","Flink"]},{"title":"Storm、Spark与Flink对比","url":"/2023/12/06/Storm、Spark与Flink对比/","content":"\n# 引言\n\nApache Flink(以下简称flink) 是一个旨在提供‘一站式’ 的分布式开源数据处理框架。和Spark的目标一样，都希望提供一个统一功能的计算平台给用户。虽然目标非常类似，但是flink在实现上和spark存在着很大的区别，flink是一个面向流的处理框架，输入在flink中是无界的，流数据是flink中的头等公民。这方面flink和storm有几分相似。那么有spark和storm这样成熟的计算框架存在，为什么flink还能占有一席之地呢？今天我们就从流处理的角度将flink和这两个框架进行一些分析和比较。\n\n# 名词解析\n\n| 名词     | 说明 | 举例    |\n|----------|-----|---------------|\n| 无边界数据    | 无边界数据通常指的是无限持续生成的数据流，没有明确定义的终点。这样的数据流可能是实时生成的事件、传感器数据、日志记录等，它们源源不断地产生，没有固定的结束点。  | 实时传感器数据，如温度传感器、网络日志，用户点击事件流等。这些数据是持续不断生成的，流式处理系统需要实时处理并适应新的数据产生。      |\n| 有边界数据      | 有边界数据是有明确定义的开始和结束点的数据集。这样的数据集在某一时刻是完整的，不再发生变化。传统的批处理任务就是对有边界数据进行处理的典型例子。  | 关系数据库中的表、存储在文件中的数据集等。这些数据集在某一时刻是完整的，可以通过一次性加载到内存中进行批处理分析。 |\n| Exactly-Once 语义  |  精确一次（Exactly-Once）处理语义，确保在出现故障或恢复时不会丢失或重复处理事件。这是保证数据处理的一致性的重要特性。 |       |\n| 有状态计算 | 有状态的计算指能够处理具有记忆和上下文关联的计算任务。这对于处理事件序列、实时聚合和复杂的模式匹配非常有用。 |\n| Sink | Sink是Flink中一种用于将数据从流处理应用程序发送到外部系统的组件，用于定义数据的最终目的地 | File Sink（文件输出）; Kafka Sink; Elasticsearch Sink; JDBC Sink; Custom Sink; |\n\n# 流框架基于的实现方式\n\n本文涉及的流框架基于的实现方式分为两大类。\n\n- 第一类是Native Streaming，这类引擎中所有的data在到来的时候就会被立即处理，一条接着一条（HINT： 狭隘的来说是一条接着一条，但流引擎有时会为提高性能缓存一小部分data然后一次性处理），其中的代表就是storm和flink。\n\n- 第二类则是基于Micro-batch，数据流被切分为一个一个小的批次， 然后再逐个被引擎处理。这些batch一般是以时间为单位进行切分，单位一般是‘秒‘，其中的典型代表则是spark了，不论是老的spark DStream还是2.0以后推出的spark structured streaming都是这样的处理机制；另外一个基于Micro-batch实现的就是storm trident，它是对storm的更高层的抽象，因为以batch为单位，所以storm trident的一些处理变得简单且高效。\n\n![分类](./Storm、Spark与Flink对比/Snipaste_2023-12-06_17-54-25.png)\n\n\n# 流框架比较的关键指标\n\n从流处理的角度将flink与spark和storm这两个框架进行比较，会主要关注以下几点，后续的对比也主要基于这几点展开：\n\n- 功能性（Functionality）- 是否能很好解决流处理功能上的痛点 , 比如event time和out of order data。\n\n- 容错性（Fault Tolerance） - 在failure之后能否恢复到故障之前的状态，并输出一致的结果；此外容错的代价也是越低越好，因为其直接影响性能。\n\n- 吞吐量(throughputs)& 延时(latency) - 性能相关的指标，高吞吐和低延迟某种意义上是不可兼得的，但好的流引擎应能兼顾高吞吐&低延时。\n\n\n# 功能性\n\n## 各类时间的定义\n[flink文档中关于各种时间的定义](https://nightlies.apache.org/flink/flink-docs-release-1.2/dev/event_time.html)\n- Event time: 指数据或事件真正发生时间，比如用户点击网页时产生一条点击事件的数据，点击时间就是这条数据固有的Event time。理解为每个单独事件在其产生设备上发生的时间。\n- Processing time: 指计算框架处理这条数据的时间\n- Ingestion Time: 摄入时间是事件进入 Flink 的时间。\n\n    ![时钟](./Storm、Spark与Flink对比/times_clocks.svg)\n\n    spark DStream和storm 1.0以前版本往往都折中地使用processing time来近似地实现event time相关的业务。显然，使用processing time模拟event time必然会产生一些误差， 特别是在产生数据堆积的时候，误差则更明显，甚至导致计算结果不可用。\n\n    在使用event time时，自然而然需要解决由网络延迟等因素导致的迟到或者乱序数据的问题。为了解决这个问题， spark、storm及flink都参考[streaming 102](https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/)引入了watermark和lateness的概念。\n\n- watermark: 是引擎处理事件的时间进度，代表一种状态，一般随着数据中的event time的增长而增长。比如 watermark(t)代表整个流的event time处理进度已经到达t， 时间是有序的，那么streaming不应该会再收到timestamp t’ < t的数据，而只会接受到timestamp t’ >= t的数据。 如果收到一条timestamp t’ < t的数据， 那么就说明这条数据是迟到的。\n\n- lateness: 表示可以容忍迟到的程度，在lateness可容忍范围内的数据还会参与计算，超过的会被丢弃。\n\n## 窗口操作\n\n### spark structured streaming 和flink对event time处理机制的比较\n\n- Flink\n  \n  首先，我们结合图来看flink， 时间轴从左往右增大。当watermark WM处于时 间窗口区间内时，即WM ∈ [start, end] , event time落在窗口范围内的任何乱序数据都会被接受；随着WM的增长并超过了窗口的结束时间，但还未超过可容忍的lateness时间范围，即WM ∈ (window_end,window_end+ lateness]， 这时乱序数据仍然可以被接受； 只有当WM超过 window_end+lateness, 即WM ∈ (window_end+ lateness, ∞)， 迟到的数据将会被丢弃。\n\n  ![handle-late-records](./Storm、Spark与Flink对比/handle-late-records.jpg)\n\n  fiink中watermark的计算也比较灵活，可以选择build-in的（如最大时间戳），也可以通过继承接口自定义实现。此外，用户可以选择周期性更新或者事件触发更新watermark。\n\n- Spark\n  \n  首先,spark中watermark是通过上一个batch最大的timestamp再减去lateness得到的，即watermark = Max(last batch timestamps) - lateness。当数据的event time大于watermark时，数据会被接受，否则不论这条数据属于哪个窗口都会被丢弃。细节请参考[Window Operations on Event Time](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#window-operations-on-event-time)\n\n下面来比较一下两者实现细节上的不同：\n\n- lateness定义: 在spark中，迟到被定义为data的event time和watermark的比较结果，当data的event time < watermark时，data被丢弃；flink中只有在watermark > window_end + lateness的时候，data才会被丢弃。\n\n- watermark更新: spark中watermark是上个batch中的max event time，存在延迟；而在flink中是可以做到每条数据同步更新watermark。\n\n- window触发: flink中window计算会触发一次或多次，第一次在watermark >= window_end后立刻触发（main fire），接着会在迟到数据到来后进行增量触发。spark只会在watermark（包含lateness）过了window_end之后才会触发，虽然计算结果一次性正确，但触发比flink起码多了一个lateness的延迟。\n\n上面三点可见flink在设计event time处理模型还是较优的：watermark的计算实时性高，输出延迟低，而且接受迟到数据没有spark那么受限。\n\n### SQL API方面的对比\n\n待续，网上资料都是较老版本的比对，不太准确，等自己实践过再来总结吧\n\n### Kafka 集成\n\n待续\n\n### 静态数据操作\n\n待续\n\n# 吞吐量\n\n待续\n\n# 总结\n\n待续","tags":["Flink","Spark","Storm"],"categories":["大数据","Flink"]},{"title":"机器学习基础-概率和发生比以及Logit","url":"/2023/10/31/机器学习基础-概率和发生比以及Logit/","content":"\n\n---\n\n概率是机器学习中最常见的概念，在分类算法(Classification)中经常出现，而Logit也是逻辑回归（Logistic Regression）中的重要概念，本文将总结概率（Probability），发生比（Odds）和Logit（log(odds)）之间的关系。\n\n## 概率，发生比与Logit的定义\n\n### 概率\n\n概率是指一个事件发生的可能性，假设一个袋子里有若干红球和蓝球，用P来表示概率。\n\n$P_{抽到红球}=\\frac{红球数}{总个数}$\n\n### 发生比\n\n发生比指一件事发生与其不发生的概率之比，同样以红球和篮球为例，用Odds来表示概率，则：\n\n$Odds_{抽到红球}=\\frac {P_{抽到红球}}{1-P_{抽到红球}}$\n\n### Logit\n\nLogit是给发生比取对数，即log(Odds)，其中log是自然对数，以红球篮球为例，其公式为:\n\n$Logit=log(\\frac {P_{抽到红球}}{1-P_{抽到红球}})$\n\n## 概率发生比与Logit的关系\n\n概率与发生比的关系较为简单， 概率是指事件发生的可能性，而发生比是指该事件发生与不发生的概率之比。但发生比与Logit的关系就并没有那么直观了，从公式上我们确实可以知道Logit就是log(发生比),**但我们该如何理解这一定义呢？**\n\n通过下面的图表不难发现，概率与发生比有以下关系：\n\n1. 概率取值为(0,1)，发生比取值为(0,Inf)\n2. 当概率为0.5时，发生比为1，即事件发生与不发生的概率相同。\n3. 当概率小于0.5时，发生比取值范围为(0,1)，当概率大于0.5时，发生比取值范围为(1,Inf)\n4. 当概率大于或小于0.5时，发生比的取值范围并不对称。\n\n发生比的不对称性，时常会带来一些困扰，比如：\n\n- 概率为0.3和0.7时，这两个概率的均值是0.5，他们是“对称”的；但这两个概率的发生比却分别是0.429和2.333,这使我们很难直观地感受到他们的对称关系。\n- 当概率从0.1增加到0.2，时，发生比增加了0.139；当概率从0.8增加到0.9时，发生比却增加了5，虽然概率的增量相同，但发生比的增量却大大的不同。\n\n而Logit就能有效地解决发生比带来的困惑：\n\n- 概率为0.3和0.7时，Logit分别为-0.847和0.847，这两个值关于0对称,因此我们知道这两Logit值对应的发生比是对称的。\n- 当概率从0.2减少至0.1时，Logit的增量是-0.811；当概率从0.8增加到0.9时，Logit的增量也是0.811，我们可以直观地感受到发生比增量也是对称的。\n- 当发生比为1时，Logit为0；当发生比小于或大于1时，Logit取值范围为(-Inf,0)和(0,Inf).取值范围对称。\n\n下表列出了当概率取不同值时，发生比和Logit之间的关系：\n\n| | Probability | Odds | Logit |\n| -- | -- | -- | -- |\n| 0 | 0.0001 | 0.00010001 | -9.21024 |\n| 1 | 0.001 | 0.001001 | -6.90675 |\n| 2 | 0.01 | 0.010101 | -4.59512 |\n| 3 | 0.1 | 0.111111 | -2.19722 |\n| 4 | 0.2 | 0.25 | -1.38629 |\n| 5 | 0.3 | 0.428571 | -0.847298 |\n| 6 | 0.4 | 0.666667 | -0.405465 |\n| 7 | 0.5 | 1 | 0 |\n| 8 | 0.6 | 1.5 | 0.405465 |\n| 9 | 0.7 | 2.33333 | 0.847298 |\n| 10| 0.8 | 4 | 1.38629 |\n| 11| 0.9 | 9 | 2.19722 |\n| 12| 0.99 | 9 | 4.59512 |\n| 13| 0.999 | 999 | 6.90675 |\n| 14| 0.9999 | 9999 | 9.21024 |\n\n用图形表示，三者关系如下，其中x轴为概率，两条曲线分别为发生比和Logit，为了让图形更加好看，概率只取了[0.1, 0.9]这一部分：\n\n![概率和发生比以及Logit](./机器学习基础-概率和发生比以及Logit/概率-发生比-Logit.jpg)\n\n## 小结\n\n由于逻辑回归模型的需求，我们引入了发生比这一概念，但发生比本身的不对称性让我们难以直观地比较发生比，因此我们引入了Logit这一概念。**Logit赋予了发生比更强的”对称“性**，让我们更容易比较不同发生比之间的关系。\n","tags":["机器学习","发生比","Logit"],"categories":["联邦学习","机器学习基础"]},{"title":"PySpark基础","url":"/2023/10/26/PySpark基础001/","content":"\n# 简介\nPySpark是Python调用Spark的接口，可以通过调用Python API的方式来编写Spark程序，它支持了大多数的Spark功能，比如SparkDataFrame、Spark SQL、Streaming、MLlib等等。\n\n# 基础概念\n## RDD\nRDD的全称是Resilient Distributed Datasets，这是Spark的一种数据抽象集合，它可以被执行在分布式的集群上进行各种操作，而且有较强的容错机制。RDD可以被分为若干个分区，每一个分区就是一个数据集片段，从而可以支持分布式计算。\n\n## RDD运行时相关的关键名词\n简单来说可以有Client、Job、Master、Worker、Driver、Stage、Task以及Executor，这几个东西在调优的时候也会经常遇到的。\n\n- Client: 指的是客户端进程，主要负责提交job到Master；\n- Job: Job来自于我们编写的程序，Application包含一个或多个job，job包含各种RDD操作；\n- Master: 指的是Standalone模式中的主控节点，负责接收来自Client的job，并管理着worker，可以给worker分配任务和资源（主要是dirver和executor资源）；\n- Worker: 指的是Standalone模式中的slave节点，负责管理本节点的资源，同时受Master管理，需要定期给Master回报heartbeat（心跳），启动Driver和Executor；\n- Driver: 指的是job（作业）的主进程，一般每个Spark作业都会有一个Driver进程，负责整个作业的运行，包括job的解析、Stage的生成、调度Task到Executor上去执行；\n- Stage: 中文名是：阶段，是Job的基本调度单位，因为每个Job会分成若干组Task，每组task就被称为Stage；\n- Task: 任务，指的是直接运行在executor上的东西，是executor上的一个线程；\n- Executor: 指的是执行器，顾名思义就是真正执行任务的地方了，一个集群可以被配置若干个Executor，每个Executor接收来自Driver的Task，并执行它（可同时执行多个Task）。\n\n## DAG\n全称是Directed Acyclic Graph, 中文名是：有向无环图。Spark就是借用了DAG对RDD之间的关系进行了建模，用来描述RDD之间的因果依赖关系。因为在一个Spark作业调度中，多个作业任务之间也是相互依赖的，有些任务需要在一些任务执行完成了才可以执行的。在Spark调度中就是有DAGscheduler，它负责将job分成若干组Task组成的Stage。\n![DAG](./PySpark基础001/dag.jpg)\n\n## Spark运行模式\n主要有local模式、Standalone模式、Mesos模式、YARN模式。\n- Standalone:  独立模式，Spark 原生的简单集群管理器， 自带完整的服务， 可单独部署到一个集群中，无需依赖任何其他资源管理系统， 使用 Standalone 可以很方便地搭建一个集群，一般在公司内部没有搭建其他资源管理框架的时候才会使用。\n- Mesos: 一个强大的分布式资源管理框架，它允许多种不同的框架部署在其上，包括 yarn，由于mesos这种方式目前应用的比较少。\n- YARN: 统一的资源管理机制， 在上面可以运行多套计算框架， 如map reduce、storm 等， 根据 driver 在集群中的位置不同，分为 yarn client 和 yarn cluster。\n实际上Spark内部为了方便用户测试，自身也提供了一些部署模式。由于在实际工厂环境下使用的绝大多数的集群管理器是 Hadoop YARN，因此我们关注的重点是 Hadoop YARN 模式下的 Spark 集群部署。\n\nSpark 的运行模式取决于传递给 SparkContext 的 MASTER 环境变量的值， 个别模式还需要辅助的程序接口来配合使用，目前支持的 Master 字符串及 URL 包括：\n\n| Master URL | Meaning |\n| -- | -- |\n| local | 在本地运行，只有一个工作进程，无并行计算能力 |\n| local[K] | 在本地运行，只有K个工作进程，通常设置K为机器的CPU核心数量 |\n| local[*] | 在本地运行，工作进程数量等于机器的CPU核心数量 |\n| spark://host:port | 以 Standalone 模式运行，这是 Spark 自身提供的集群运行模式，默认端口号: 7077 |\n| mesos://host:port | 在 Mesos 集群上运行，Driver 进程和 Worker 进程运行在 Mesos 集群上，部署模式必须使用固定值:--deploy-mode cluster |\n| yarn-client | 在 Yarn 集群上运行，Driver 进程在本地， Work 进程在 Yarn 集群上， 部署模式必须使用固定值:--deploy-modeclient。Yarn 集群地址必须在HADOOP_CONF_DIRorYARN_CONF_DIR 变量里定义。|\n| yarn-cluster | yarn-cluster 效率比yarn-client高。在 Yarn 集群上运行，Driver 进程在 Yarn 集群上，Work 进程也在 Yarn 集群上，部署模式必须使用固定值:--deploy-mode cluster。Yarn 集群地址必须在HADOOP_CONF_DIR or YARN_CONF_DIR 变量里定义。|\n\n**用户在提交任务给 Spark 处理时，以下两个参数共同决定了 Spark 的运行方式。**\n\n- master MASTER_URL: 决定了 Spark 任务提交给哪种集群处理。\n- deploy-mode DEPLOY_MODE: 决定了 Driver 的运行方式，可选值为 Client\n或者 Cluster。\n\n### Standalone模式运行机制\n\nStandalone 集群有四个重要组成部分，分别是：\n\n1. Driver： 是一个进程，我们编写的 Spark 应用程序就运行在 Driver 上， 由Driver 进程执行；\n2. Master：是一个进程，主要负责资源的调度和分配，并进行集群的监控等职责；\n3. Worker：是一个进程，一个 Worker 运行在集群中的一台服务器上，主要负责两个职责，一个是用自己的内存存储 RDD 的某个或某些 partition；另一个是启动其他进程和线程（Executor） ，对 RDD 上的 partition 进行并行的处理和计算。\n4. Executor：是一个进程， 一个 Worker 上可以运行多个 Executor， Executor 通过启动多个线程（task）来执行对 RDD 的 partition 进行并行计算，也就是执行我们对 RDD 定义的例如 map、flatMap、reduce 等算子操作。\n\n#### Standalone Client模式\n\n在 Standalone Client 模式下，Driver 在任务提交的本地机器上运行，Driver 启动后向 Master 注册应用程序，Master 根据 submit 脚本的资源需求找到内部资源至少可以启动一个 Executor 的所有 Worker，然后在这些 Worker 之间分配 Executor，Worker 上的 Executor 启动后会向 Driver 反向注册，所有的 Executor 注册完成后，Driver 开始执行 main 函数，之后执行到 Action 算子时，开始划分 stage，每个 stage 生成对应的 taskSet，之后将 task 分发到各个 Executor 上执行。\n\n#### Standalone Cluster模式\n\n在 Standalone Cluster 模式下，任务提交后，Master 会找到一个 Worker 启动 Driver进程， Driver 启动后向 Master 注册应用程序， Master 根据 submit 脚本的资源需求找到内部资源至少可以启动一个 Executor 的所有 Worker，然后在这些 Worker 之间分配 Executor，Worker 上的 Executor 启动后会向 Driver 反向注册，所有的 Executor 注册完成后，Driver 开始执行 main 函数，之后执行到 Action 算子时，开始划分 stage，每个 stage 生成对应的 taskSet，之后将 task 分发到各个 Executor 上执行。\n\n> 注意， Standalone 的两种模式下（ client/cluster）， Master 在接到 Driver 注册\nSpark 应用程序的请求后，会获取其所管理的剩余资源能够启动一个 Executor 的所有 Worker， 然后在这些 Worker 之间分发 Executor，此时的分发只考虑 Worker 上的资源是否足够使用，直到当前应用程序所需的所有 Executor 都分配完毕， Executor 反向注册完毕后，Driver 开始执行 main 程序。\n\n### YARN模式运行机制\n\n#### YARN Client模式\n\n1. Driver在任务提交的本地机器上运行，Driver启动后会和ResourceManager通讯申请启动ApplicationMaster；\n2. 随后ResourceManager分配Container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster的功能相当于一个ExecutorLaucher，只负责向ResourceManager申 请Executor内存；\n3. ResourceManager接到ApplicationMaster的资源申请后会分配Container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程；\n4. Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数；\n5. 之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分Stage，每个Stage生成对应的TaskSet，之后将Task分发到各个Executor上执行。\n\n![yarn-client模式](./PySpark基础001/yarn-client.png)\n\n#### YARN Cluster 模式\n\n1. 任务提交后会和ResourceManager通讯申请启动ApplicationMaster;\n2. 随后ResourceManager分配Container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster就是Driver；\n3. Driver启动后向ResourceManager申请Executor内存，ResourceManager接到ApplicationMaster的资源申请后会分配Container,然后在合适的NodeManager上启动Executor进程;\n4. Executor进程启动后会向Driver反向注册;\n5. Executor全部注册完成后Driver开始执行main函数，之后执行到Action算子时，触发一个job，并根据宽依赖开始划分stage，每个stage生成对应的taskSet，之后将task分发到各个Executor上执行;\n\n![yarn-cluster模式](./PySpark基础001/yarn-cluster.jpg)\n\n\n## Shuffle操作是什么\n\nShuffle指的是数据从Map端到Reduce端的数据传输过程，Shuffle性能的高低会直接影响程序的性能。因为Reduce task需要跨节点去拉分布在不同节点上的Map task计算结果，这一个过程是需要有磁盘IO消耗以及数据网络传输的消耗的，所以需要根据实际数据情况进行适当调整。另外，Shuffle可以分为两部分，分别是Map阶段的数据准备与Reduce阶段的数据拷贝处理，在Map端我们叫Shuffle Write，在Reduce端我们叫Shuffle Read。\n\n## 什么是惰性执行\n\n这是RDD的一个特性，在RDD中的算子可以分为Transform算子和Action算子，其中Transform算子的操作都不会真正执行，只会记录一下依赖关系，直到遇见了Action算子，在这之前的所有Transform操作才会被触发计算，这就是所谓的惰性执行。具体哪些是Transform和Action算子，可以看下一节。\n\n## 常用函数\n\n常用的算子大概可以分为以下几种：\n\n### Transformations\n\n- map\n- flatmap\n- filter\n- distinct\n- reduceByKey\n- mapPartitions\n- sortBy\n\n### Actions\n\n- collect\n- collectAsMap\n- reduce\n- countByKey/countByValue\n- take\n- first\n\n### 代码示例\n\n```python\nimport os\nimport pyspark\nfrom pyspark import SparkContext, SparkConf\n\nconf = SparkConf().setAppName(\"test_spark_app\").setMaster(\"local[4]\")\nsc = SparkContext(conf=conf)\n\n# 使用 parallelize方法直接实例化一个RDD\nrdd = sc.parallelize(range(1,11),4) # 这里的 4 指的是分区数量\nrdd.take(100)\n# [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\"\"\"\n----------------------------------------------\n                Transform算子解析\n----------------------------------------------\n\"\"\"\n# 以下的操作由于是Transform操作，因为我们需要在最后加上一个collect算子用来触发计算。\n# 1. map: 和python差不多，map转换就是对每一个元素进行一个映射\nrdd = sc.parallelize(range(1, 11), 4)\nrdd_map = rdd.map(lambda x: x*2)\nprint(\"原始数据：\", rdd.collect())\nprint(\"扩大2倍：\", rdd_map.collect())\n# 原始数据： [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n# 扩大2倍： [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n\n# 2. flatMap: 这个相比于map多一个flat（压平）操作，顾名思义就是要把高维的数组变成一维\nrdd2 = sc.parallelize([\"hello SamShare\", \"hello PySpark\"])\nprint(\"原始数据：\", rdd2.collect())\nprint(\"直接split之后的map结果：\", rdd2.map(lambda x: x.split(\" \")).collect())\nprint(\"直接split之后的flatMap结果：\", rdd2.flatMap(lambda x: x.split(\" \")).collect())\n# 直接split之后的map结果： [['hello', 'SamShare'], ['hello', 'PySpark']]\n# 直接split之后的flatMap结果： ['hello', 'SamShare', 'hello', 'PySpark']\n\n# 3. filter: 过滤数据\nrdd = sc.parallelize(range(1, 11), 4)\nprint(\"原始数据：\", rdd.collect())\nprint(\"过滤奇数：\", rdd.filter(lambda x: x % 2 == 0).collect())\n# 原始数据： [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n# 过滤奇数： [2, 4, 6, 8, 10]\n\n# 4. distinct: 去重元素\nrdd = sc.parallelize([2, 2, 4, 8, 8, 8, 8, 16, 32, 32])\nprint(\"原始数据：\", rdd.collect())\nprint(\"去重数据：\", rdd.distinct().collect())\n# 原始数据： [2, 2, 4, 8, 8, 8, 8, 16, 32, 32]\n# 去重数据： [4, 8, 16, 32, 2]\n\n# 5. reduceByKey: 根据key来映射数据\nfrom operator import add\nrdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\nprint(\"原始数据：\", rdd.collect())\nprint(\"原始数据：\", rdd.reduceByKey(add).collect())\n# 原始数据： [('a', 1), ('b', 1), ('a', 1)]\n# 原始数据： [('b', 1), ('a', 2)]\n\n# 6. mapPartitions: 根据分区内的数据进行映射操作\n# 把数据集发成两个分区，在分区内进行求和操作\nrdd = sc.parallelize([1, 2, 3, 4], 2)\ndef f(iterator):\n    yield sum(iterator)\nprint(rdd.collect())\nprint(rdd.mapPartitions(f).collect())\n# [1, 2, 3, 4]\n# [3, 7]\n\n# 7. sortBy: 根据规则进行排序\ntmp = [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\nprint(sc.parallelize(tmp).sortBy(lambda x: x[0]).collect())\nprint(sc.parallelize(tmp).sortBy(lambda x: x[1]).collect())\n# [('1', 3), ('2', 5), ('a', 1), ('b', 2), ('d', 4)]\n# [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\n\n# 8. subtract: 数据集相减, Return each value in self that is not contained in other.\nx = sc.parallelize([(\"a\", 1), (\"b\", 4), (\"b\", 5), (\"a\", 3)])\ny = sc.parallelize([(\"a\", 3), (\"c\", None)])\nprint(sorted(x.subtract(y).collect()))\n# [('a', 1), ('b', 4), ('b', 5)]\n\n# 9. union: 合并两个RDD\nrdd = sc.parallelize([1, 1, 2, 3])\nprint(rdd.union(rdd).collect())\n# [1, 1, 2, 3, 1, 1, 2, 3]\n\n# 10. intersection: 取两个RDD的交集，同时有去重的功效\nrdd1 = sc.parallelize([1, 10, 2, 3, 4, 5, 2, 3])\nrdd2 = sc.parallelize([1, 6, 2, 3, 7, 8])\nprint(rdd1.intersection(rdd2).collect())\n# [1, 2, 3]\n\n# 11. cartesian: 生成笛卡尔积\nrdd = sc.parallelize([1, 2])\nprint(sorted(rdd.cartesian(rdd).collect()))\n# [(1, 1), (1, 2), (2, 1), (2, 2)]\n\n# 12. zip: 拉链合并，需要两个RDD具有相同的长度以及分区数量\nx = sc.parallelize(range(0, 5))\ny = sc.parallelize(range(1000, 1005))\nprint(x.collect())\nprint(y.collect())\nprint(x.zip(y).collect())\n# [0, 1, 2, 3, 4]\n# [1000, 1001, 1002, 1003, 1004]\n# [(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)]\n\n# 13. zipWithIndex: 将RDD和一个从0开始的递增序列按照拉链方式连接。\nrdd_name = sc.parallelize([\"LiLei\", \"Hanmeimei\", \"Lily\", \"Lucy\", \"Ann\", \"Dachui\", \"RuHua\"])\nrdd_index = rdd_name.zipWithIndex()\nprint(rdd_index.collect())\n# [('LiLei', 0), ('Hanmeimei', 1), ('Lily', 2), ('Lucy', 3), ('Ann', 4), ('Dachui', 5), ('RuHua', 6)]\n\n# 14. groupByKey: 按照key来聚合数据\nrdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\nprint(rdd.collect())\nprint(sorted(rdd.groupByKey().mapValues(len).collect()))\nprint(sorted(rdd.groupByKey().mapValues(list).collect()))\n# [('a', 1), ('b', 1), ('a', 1)]\n# [('a', 2), ('b', 1)]\n# [('a', [1, 1]), ('b', [1])]\n\n# 15. sortByKey:\ntmp = [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\nprint(sc.parallelize(tmp).sortByKey(True, 1).collect())\n# [('1', 3), ('2', 5), ('a', 1), ('b', 2), ('d', 4)]\n\n# 16. join:\nx = sc.parallelize([(\"a\", 1), (\"b\", 4)])\ny = sc.parallelize([(\"a\", 2), (\"a\", 3)])\nprint(sorted(x.join(y).collect()))\n# [('a', (1, 2)), ('a', (1, 3))]\n\n# 17. leftOuterJoin/rightOuterJoin\nx = sc.parallelize([(\"a\", 1), (\"b\", 4)])\ny = sc.parallelize([(\"a\", 2)])\nprint(sorted(x.leftOuterJoin(y).collect()))\n# [('a', (1, 2)), ('b', (4, None))]\n\n\"\"\"\n----------------------------------------------\n                Action算子解析\n----------------------------------------------\n\"\"\"\n# 1. collect: 指的是把数据都汇集到driver端，便于后续的操作\nrdd = sc.parallelize(range(0, 5))\nrdd_collect = rdd.collect()\nprint(rdd_collect)\n# [0, 1, 2, 3, 4]\n\n# 2. first: 取第一个元素\nsc.parallelize([2, 3, 4]).first()\n# 2\n\n# 3. collectAsMap: 转换为dict，使用这个要注意了，不要对大数据用，不然全部载入到driver端会爆内存\nm = sc.parallelize([(1, 2), (3, 4)]).collectAsMap()\nm\n# {1: 2, 3: 4}\n\n# 4. reduce: 逐步对两个元素进行操作\nrdd = sc.parallelize(range(10),5)\nprint(rdd.reduce(lambda x,y:x+y))\n# 45\n\n# 5. countByKey/countByValue:\nrdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\nprint(sorted(rdd.countByKey().items()))\nprint(sorted(rdd.countByValue().items()))\n# [('a', 2), ('b', 1)]\n# [(('a', 1), 2), (('b', 1), 1)]\n\n# 6. take: 相当于取几个数据到driver端\nrdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\nprint(rdd.take(5))\n# [('a', 1), ('b', 1), ('a', 1)]\n\n# 7. saveAsTextFile: 保存rdd成text文件到本地\ntext_file_path = \"./data/rdd\"\nshutil.rmtree(text_file_path, True)\nrdd = sc.parallelize(range(5))\nrdd.saveAsTextFile(text_file_path)\n\n# 8. takeSample: 随机取数\nrdd = sc.textFile(\"./samples/zipcodes.csv\", 4)  # 这里的 4 指的是分区数量\nrdd_sample = rdd.takeSample(True, 2, 0)  # withReplacement 参数1：代表是否是有放回抽样\nprint(rdd_sample)\n\n# 9. foreach: 对每一个元素执行某种操作，不生成新的RDD\nrdd = sc.parallelize(range(10), 5)\naccum = sc.accumulator(0)\nrdd.foreach(lambda x: accum.add(x))\nprint(accum.value)\n\n```\n\n## Spark SQL使用\n\n在讲Spark SQL前，先解释下这个模块。这个模块是Spark中用来处理结构化数据的，提供一个叫SparkDataFrame的东西并且自动解析为分布式SQL查询数据。用过Python的Pandas库，也大致了解了DataFrame，这个其实和它没有太大的区别，只是调用的API可能有些不同罢了。\n\n我们通过使用Spark SQL来处理数据，会让我们更加熟悉，比如可以用SQL语句、用SparkDataFrame的API或者Datasets API，我们可以按照需求随心转换，通过SparkDataFrame API 和 SQL 写的逻辑，会被Spark优化器Catalyst自动优化成RDD。\n\n## 创建SparkDataFrame\n\n开始讲SparkDataFrame，我们先学习下几种创建的方法，分别是使用RDD来创建、使用pandas的DataFrame来创建、使用List来创建、读取数据文件来创建、通过读取数据库来创建。\n\n### 使用RDD来创建\n\n主要使用RDD的toDF方法\n\n```python\nrdd = sc.parallelize([(\"Sam\", 28, 88), (\"Flora\", 28, 90), (\"Run\", 1, 60)])\ndf = rdd.toDF([\"name\", \"age\", \"score\"])\ndf.show()\ndf.printSchema()\n\n# +-----+---+-----+\n# | name|age|score|\n# +-----+---+-----+\n# |  Sam| 28|   88|\n# |Flora| 28|   90|\n# |  Run|  1|   60|\n# +-----+---+-----+\n# root\n#  |-- name: string (nullable = true)\n#  |-- age: long (nullable = true)\n#  |-- score: long (nullable = true)\n```\n\n### 使用pandas的DataFrame来创建\n\n```python\ndf = pd.DataFrame([['Sam', 28, 88], ['Flora', 28, 90], ['Run', 1, 60]],\n                  columns=['name', 'age', 'score'])\nprint(\">> 打印DataFrame:\")\nprint(df)\nprint(\"\\n\")\nSpark_df = spark.createDataFrame(df)\nprint(\">> 打印SparkDataFrame:\")\nSpark_df.show()\n# >> 打印DataFrame:\n#     name  age  score\n# 0    Sam   28     88\n# 1  Flora   28     90\n# 2    Run    1     60\n# >> 打印SparkDataFrame:\n# +-----+---+-----+\n# | name|age|score|\n# +-----+---+-----+\n# |  Sam| 28|   88|\n# |Flora| 28|   90|\n# |  Run|  1|   60|\n# +-----+---+-----+\n```\n\n### 使用List来创建\n\n```python\nlist_values = [['Sam', 28, 88], ['Flora', 28, 90], ['Run', 1, 60]]\nSpark_df = spark.createDataFrame(list_values, ['name', 'age', 'score'])\nSpark_df.show()\n# +-----+---+-----+\n# | name|age|score|\n# +-----+---+-----+\n# |  Sam| 28|   88|\n# |Flora| 28|   90|\n# |  Run|  1|   60|\n# +-----+---+-----+\n```\n\n### 读取数据文件来创建\n\n```python\n# CSV文件\ndf = spark.read.option(\"header\", \"true\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .option(\"delimiter\", \",\") \\\n    .csv(\"./samples/breast_homo_test.csv\")\ndf.show(5)\ndf.printSchema()\n\n# json文件\ndf = spark.read.json(\"./samples/zipcodes.json\")\ndf.show(5)\ndf.printSchema()\n\ndf = spark.read.option(\"multiline\", \"true\").json(\"./samples/multiline-zipcode.json\")\ndf.show(5)\ndf.printSchema()\n```\n\n### 通过读取数据库来创建\n\n```python\n# 读取hive数据\nspark.sql(\"CREATE TABLE IF NOT EXISTS src (key INT, value STRING) USING hive\")\nspark.sql(\"LOAD DATA LOCAL INPATH 'data/kv1.txt' INTO TABLE src\")\ndf = spark.sql(\"SELECT key, value FROM src WHERE key < 10 ORDER BY key\")\ndf.show(5)\n\n# 读取mysql数据\nurl = \"jdbc:mysql://localhost:3306/test\"\ndf = spark.read.format(\"jdbc\") \\\n .option(\"url\", url) \\\n .option(\"dbtable\", \"runoob_tbl\") \\\n .option(\"user\", \"root\") \\\n .option(\"password\", \"8888\") \\\n .load()\\\ndf.show()\n```\n\n## 常用的SparkDataFrame API\n\n这里我大概是分成了几部分来看这些APIs，分别是查看DataFrame的APIs、简单处理DataFrame的APIs、DataFrame的列操作APIs、DataFrame的一些思路变换操作APIs、DataFrame的一些统计操作APIs，这样子也有助于我们了解这些API的功能，以后遇见实际问题的时候可以解决。\n\n首先我们这小节全局用到的数据集如下：\n\n```python\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import SparkSession\n# SparkSQL的许多功能封装在SparkSession的方法接口中, SparkContext则不行的。\nspark = SparkSession.builder \\\n    .appName(\"test_spark_app\") \\\n    .config(\"master\", \"local[4]\") \\\n    .enableHiveSupport() \\\n    .getOrCreate()\nsc = spark.sparkContext\n\n# 创建一个SparkDataFrame\nrdd = sc.parallelize([(\"Sam\", 28, 88, \"M\"),\n                      (\"Flora\", 28, 90, \"F\"),\n                      (\"Run\", 1, 60, None),\n                      (\"Peter\", 55, 100, \"M\"),\n                      (\"Mei\", 54, 95, \"F\")])\ndf = rdd.toDF([\"name\", \"age\", \"score\", \"sex\"])\ndf.show()\ndf.printSchema()\n\n# +-----+---+-----+----+\n# | name|age|score| sex|\n# +-----+---+-----+----+\n# |  Sam| 28|   88|   M|\n# |Flora| 28|   90|   F|\n# |  Run|  1|   60|null|\n# |Peter| 55|  100|   M|\n# |  Mei| 54|   95|   F|\n# +-----+---+-----+----+\n# root\n#  |-- name: string (nullable = true)\n#  |-- age: long (nullable = true)\n#  |-- score: long (nullable = true)\n#  |-- sex: string (nullable = true)\n```\n\n### 查看DataFrame的APIs\n\n```python\n# DataFrame.collect\n# 以列表形式返回行\ndf.collect()\n# [Row(name='Sam', age=28, score=88, sex='M'),\n# Row(name='Flora', age=28, score=90, sex='F'),\n# Row(name='Run', age=1, score=60, sex=None),\n# Row(name='Peter', age=55, score=100, sex='M'),\n# Row(name='Mei', age=54, score=95, sex='F')]\n\n# DataFrame.count\ndf.count()\n# 5\n\n# DataFrame.columns\ndf.columns\n# ['name', 'age', 'score', 'sex']\n\n# DataFrame.dtypes\ndf.dtypes\n# [('name', 'string'), ('age', 'bigint'), ('score', 'bigint'), ('sex', 'string')]\n\n# DataFrame.describe\n# 返回列的基础统计信息\ndf.describe(['age']).show()\n# +-------+------------------+\n# |summary|               age|\n# +-------+------------------+\n# |  count|                 5|\n# |   mean|              33.2|\n# | stddev|22.353970564532826|\n# |    min|                 1|\n# |    max|                55|\n# +-------+------------------+\ndf.describe().show()\n# +-------+-----+------------------+------------------+----+\n# |summary| name|               age|             score| sex|\n# +-------+-----+------------------+------------------+----+\n# |  count|    5|                 5|                 5|   4|\n# |   mean| null|              33.2|              86.6|null|\n# | stddev| null|22.353970564532826|15.582040944625966|null|\n# |    min|Flora|                 1|                60|   F|\n# |    max|  Sam|                55|               100|   M|\n# +-------+-----+------------------+------------------+----+\n\n# DataFrame.select\n# 选定指定列并按照一定顺序呈现\ndf.select(\"sex\", \"score\").show()\n\n# DataFrame.first\n# DataFrame.head\n# 查看第1条数据\ndf.first()\n# Row(name='Sam', age=28, score=88, sex='M')\ndf.head(1)\n# [Row(name='Sam', age=28, score=88, sex='M')]\n\n\n# DataFrame.freqItems\n# 查看指定列的枚举值\ndf.freqItems([\"age\",\"sex\"]).show()\n# +---------------+-------------+\n# |  age_freqItems|sex_freqItems|\n# +---------------+-------------+\n# |[55, 1, 28, 54]|      [M, F,]|\n# +---------------+-------------+\n\n# DataFrame.summary\ndf.summary().show()\n# +-------+-----+------------------+------------------+----+\n# |summary| name|               age|             score| sex|\n# +-------+-----+------------------+------------------+----+\n# |  count|    5|                 5|                 5|   4|\n# |   mean| null|              33.2|              86.6|null|\n# | stddev| null|22.353970564532826|15.582040944625966|null|\n# |    min|Flora|                 1|                60|   F|\n# |    25%| null|                28|                88|null|\n# |    50%| null|                28|                90|null|\n# |    75%| null|                54|                95|null|\n# |    max|  Sam|                55|               100|   M|\n# +-------+-----+------------------+------------------+----+\n\n# DataFrame.sample\n# 按照一定规则从df随机抽样数据\ndf.sample(0.5).show()\n# +-----+---+-----+----+\n# | name|age|score| sex|\n# +-----+---+-----+----+\n# |  Sam| 28|   88|   M|\n# |  Run|  1|   60|null|\n# |Peter| 55|  100|   M|\n# +-----+---+-----+----+\n```\n\n### 简单处理DataFrame的APIs\n\n```python\n# DataFrame.distinct\n# 对数据集进行去重\ndf.distinct().show()\n\n# DataFrame.dropDuplicates\n# 对指定列去重\ndf.dropDuplicates([\"sex\"]).show()\n# +-----+---+-----+----+\n# | name|age|score| sex|\n# +-----+---+-----+----+\n# |Flora| 28|   90|   F|\n# |  Run|  1|   60|null|\n# |  Sam| 28|   88|   M|\n# +-----+---+-----+----+\n\n# DataFrame.exceptAll\n# DataFrame.subtract\n# 根据指定的df对df进行去重\ndf1 = spark.createDataFrame(\n        [(\"a\", 1), (\"a\", 1), (\"b\",  3), (\"c\", 4)], [\"C1\", \"C2\"])\ndf2 = spark.createDataFrame([(\"a\", 1), (\"b\", 3)], [\"C1\", \"C2\"])\ndf3 = df1.exceptAll(df2)  # 没有去重的功效\ndf4 = df1.subtract(df2)  # 有去重的奇效\ndf1.show()\ndf2.show()\ndf3.show()\ndf4.show()\n# +---+---+\n# | C1| C2|\n# +---+---+\n# |  a|  1|\n# |  a|  1|\n# |  b|  3|\n# |  c|  4|\n# +---+---+\n# +---+---+\n# | C1| C2|\n# +---+---+\n# |  a|  1|\n# |  b|  3|\n# +---+---+\n# +---+---+\n# | C1| C2|\n# +---+---+\n# |  a|  1|\n# |  c|  4|\n# +---+---+\n# +---+---+\n# | C1| C2|\n# +---+---+\n# |  c|  4|\n# +---+---+\n\n# DataFrame.intersectAll\n# 返回两个DataFrame的交集\ndf1 = spark.createDataFrame(\n        [(\"a\", 1), (\"a\", 1), (\"b\",  3), (\"c\", 4)], [\"C1\", \"C2\"])\ndf2 = spark.createDataFrame([(\"a\", 1), (\"b\", 4)], [\"C1\", \"C2\"])\ndf1.intersectAll(df2).show()\n# +---+---+\n# | C1| C2|\n# +---+---+\n# |  a|  1|\n# +---+---+\n\n# DataFrame.drop\n# 丢弃指定列\ndf.drop('age').show()\n\n# DataFrame.withColumn\n# 新增列\ndf1 = df.withColumn(\"birth_year\", 2021 - df.age)\ndf1.show()\n# +-----+---+-----+----+----------+\n# | name|age|score| sex|birth_year|\n# +-----+---+-----+----+----------+\n# |  Sam| 28|   88|   M|      1993|\n# |Flora| 28|   90|   F|      1993|\n# |  Run|  1|   60|null|      2020|\n# |Peter| 55|  100|   M|      1966|\n# |  Mei| 54|   95|   F|      1967|\n# +-----+---+-----+----+----------+\n\n# DataFrame.withColumnRenamed\n# 重命名列名\ndf1 = df.withColumnRenamed(\"sex\", \"gender\")\ndf1.show()\n# +-----+---+-----+------+\n# | name|age|score|gender|\n# +-----+---+-----+------+\n# |  Sam| 28|   88|     M|\n# |Flora| 28|   90|     F|\n# |  Run|  1|   60|  null|\n# |Peter| 55|  100|     M|\n# |  Mei| 54|   95|     F|\n# +-----+---+-----+------+\n\n\n# DataFrame.dropna\n# 丢弃空值，DataFrame.dropna(how='any', thresh=None, subset=None)\ndf.dropna(how='all', subset=['sex']).show()\n# +-----+---+-----+---+\n# | name|age|score|sex|\n# +-----+---+-----+---+\n# |  Sam| 28|   88|  M|\n# |Flora| 28|   90|  F|\n# |Peter| 55|  100|  M|\n# |  Mei| 54|   95|  F|\n# +-----+---+-----+---+\n\n# DataFrame.fillna\n# 空值填充操作\ndf1 = spark.createDataFrame(\n        [(\"a\", None), (\"a\", 1), (None,  3), (\"c\", 4)], [\"C1\", \"C2\"])\n# df2 = df1.na.fill({\"C1\": \"d\", \"C2\": 99})\ndf2 = df1.fillna({\"C1\": \"d\", \"C2\": 99})\ndf1.show()\ndf2.show()\n\n# DataFrame.filter\n# 根据条件过滤\ndf.filter(df.age>50).show()\n# +-----+---+-----+---+\n# | name|age|score|sex|\n# +-----+---+-----+---+\n# |Peter| 55|  100|  M|\n# |  Mei| 54|   95|  F|\n# +-----+---+-----+---+\ndf.where(df.age==28).show()\n# +-----+---+-----+---+\n# | name|age|score|sex|\n# +-----+---+-----+---+\n# |  Sam| 28|   88|  M|\n# |Flora| 28|   90|  F|\n# +-----+---+-----+---+\ndf.filter(\"age<18\").show()\n# +----+---+-----+----+\n# |name|age|score| sex|\n# +----+---+-----+----+\n# | Run|  1|   60|null|\n# +----+---+-----+----+\n\n\n# DataFrame.join\n# 这个不用多解释了，直接上案例来看看具体的语法即可，DataFrame.join(other, on=None, how=None)\ndf1 = spark.createDataFrame(\n        [(\"a\", 1), (\"d\", 1), (\"b\",  3), (\"c\", 4)], [\"id\", \"num1\"])\ndf2 = spark.createDataFrame([(\"a\", 1), (\"b\", 3)], [\"id\", \"num2\"])\ndf1.join(df2, df1.id == df2.id, 'left').select(df1.id.alias(\"df1_id\"),\n                                               df1.num1.alias(\"df1_num\"),\n                                               df2.num2.alias(\"df2_num\")\n                                               ).sort([\"df1_id\"], ascending=False)\\\n    .show()\n\n\n# DataFrame.agg(*exprs)\n# 聚合数据，可以写多个聚合方法，如果不写groupBy的话就是对整个DF进行聚合\n# DataFrame.alias\n# 设置列或者DataFrame别名\n# DataFrame.groupBy\n# 根据某几列进行聚合，如有多列用列表写在一起，如 df.groupBy([\"sex\", \"age\"])\ndf.groupBy(\"sex\").agg(F.min(df.age).alias(\"最小年龄\"),\n                      F.expr(\"avg(age)\").alias(\"平均年龄\"),\n                      F.expr(\"collect_list(name)\").alias(\"姓名集合\")\n                      ).show()\n# +----+--------+--------+------------+\n# | sex|最小年龄|平均年龄|    姓名集合|\n# +----+--------+--------+------------+\n# |   F|      28|    41.0|[Flora, Mei]|\n# |null|       1|     1.0|       [Run]|\n# |   M|      28|    41.5|[Sam, Peter]|\n# +----+--------+--------+------------+\n\n\n# DataFrame.foreach\n# 对每一行进行函数方法的应用\ndef f(person):\n    print(person.name)\ndf.foreach(f)\n# Peter\n# Run\n# Sam\n# Flora\n# Mei\n\n# DataFrame.replace\n# 修改df里的某些值\ndf1 = df.na.replace({\"M\": \"Male\", \"F\": \"Female\"})\ndf1.show()\n\n# DataFrame.union\n# 相当于SQL里的union all操作\ndf1 = spark.createDataFrame(\n        [(\"a\", 1), (\"d\", 1), (\"b\",  3), (\"c\", 4)], [\"id\", \"num\"])\ndf2 = spark.createDataFrame([(\"a\", 1), (\"b\", 3)], [\"id\", \"num\"])\ndf1.union(df2).show()\ndf1.unionAll(df2).show()\n# 这里union没有去重，不知道为啥，有知道的朋友麻烦解释下，谢谢了。\n# +---+---+\n# | id|num|\n# +---+---+\n# |  a|  1|\n# |  d|  1|\n# |  b|  3|\n# |  c|  4|\n# |  a|  1|\n# |  b|  3|\n# +---+---+\n\n# DataFrame.unionByName\n# 根据列名来进行合并数据集\ndf1 = spark.createDataFrame([[1, 2, 3]], [\"col0\", \"col1\", \"col2\"])\ndf2 = spark.createDataFrame([[4, 5, 6]], [\"col1\", \"col2\", \"col0\"])\ndf1.unionByName(df2).show()\n# +----+----+----+\n# |col0|col1|col2|\n# +----+----+----+\n# |   1|   2|   3|\n# |   6|   4|   5|\n# +----+----+----+\n```\n\n### DataFrame的列操作APIs\n\n这里主要针对的是列进行操作，比如说重命名、排序、空值判断、类型判断等\n\n```python\nColumn.alias(*alias, **kwargs)  # 重命名列名\nColumn.asc()  # 按照列进行升序排序\nColumn.desc()  # 按照列进行降序排序\nColumn.astype(dataType)  # 类型转换\nColumn.cast(dataType)  # 强制转换类型\nColumn.between(lowerBound, upperBound)  # 返回布尔值，是否在指定区间范围内\nColumn.contains(other)  # 是否包含某个关键词\nColumn.endswith(other)  # 以什么结束的值，如 df.filter(df.name.endswith('ice')).collect()\nColumn.isNotNull()  # 筛选非空的行\nColumn.isNull()\nColumn.isin(*cols)  # 返回包含某些值的行 df[df.name.isin(\"Bob\", \"Mike\")].collect()\nColumn.like(other)  # 返回含有关键词的行\nColumn.when(condition, value)  # 给True的赋值\nColumn.otherwise(value)  # 与when搭配使用，df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()\nColumn.rlike(other)  # 可以使用正则的匹配 df.filter(df.name.rlike('ice$')).collect()\nColumn.startswith(other)  # df.filter(df.name.startswith('Al')).collect()\nColumn.substr(startPos, length)  # df.select(df.name.substr(1, 3).alias(\"col\")).collect()\n```\n\n### DataFrame的一些思路变换操作APIs\n\n```python\n# DataFrame.createOrReplaceGlobalTempView\n# DataFrame.dropGlobalTempView\n# 创建全局的试图，注册后可以使用sql语句来进行操作，生命周期取决于Spark application本身\ndf.createOrReplaceGlobalTempView(\"people\")\nspark.sql(\"select * from global_temp.people where sex = 'M' \").show()\n# +-----+---+-----+---+\n# | name|age|score|sex|\n# +-----+---+-----+---+\n# |  Sam| 28|   88|  M|\n# |Peter| 55|  100|  M|\n# +-----+---+-----+---+\n\n# DataFrame.createOrReplaceTempView\n# DataFrame.dropTempView\n# 创建本地临时试图，生命周期取决于用来创建此数据集的SparkSession\ndf.createOrReplaceTempView(\"tmp_people\")\nspark.sql(\"select * from tmp_people where sex = 'F' \").show()\n# +-----+---+-----+---+\n# | name|age|score|sex|\n# +-----+---+-----+---+\n# |Flora| 28|   90|  F|\n# |  Mei| 54|   95|  F|\n# +-----+---+-----+---+\n\n# DataFrame.cache\\DataFrame.persist\n# 可以把一些数据放入缓存中，default storage level (MEMORY_AND_DISK).\ndf.cache()\ndf.persist()\ndf.unpersist()\n\n# DataFrame.crossJoin\n# 返回两个DataFrame的笛卡尔积关联的DataFrame\ndf1 = df.select(\"name\", \"sex\")\ndf2 = df.select(\"name\", \"sex\")\ndf3 = df1.crossJoin(df2)\nprint(\"表1的记录数\", df1.count())\nprint(\"表2的记录数\", df2.count())\nprint(\"笛卡尔积后的记录数\", df3.count())\n# 表1的记录数 5\n# 表2的记录数 5\n# 笛卡尔积后的记录数 25\n\n# DataFrame.toPandas\n# 把SparkDataFrame转为 Pandas的DataFrame\ndf.toPandas()\n\n# DataFrame.rdd\n# 把SparkDataFrame转为rdd，这样子可以用rdd的语法来操作数据\ndf.rdd\n```\n\n### DataFrame的一些统计操作APIs\n\n```python\n# DataFrame.cov\n# 计算指定两列的样本协方差\ndf.cov(\"age\", \"score\")\n# 324.59999999999997\n\n# DataFrame.corr\n# 计算指定两列的相关系数，DataFrame.corr(col1, col2, method=None)，目前method只支持Pearson相关系数\ndf.corr(\"age\", \"score\", method=\"pearson\")\n# 0.9319004030498815\n\n# DataFrame.cube\n# 创建多维度聚合的结果，通常用于分析数据，比如我们指定两个列进行聚合，比如name和age，那么这个函数返回的聚合结果会\n# groupby(\"name\", \"age\")\n# groupby(\"name\")\n# groupby(\"age\")\n# groupby(all)\n# 四个聚合结果的union all 的结果\n\ndf1 = df.filter(df.name != \"Run\")\nprint(df1.show())\ndf1.cube(\"name\", \"sex\").count().show()\n# +-----+---+-----+---+\n# | name|age|score|sex|\n# +-----+---+-----+---+\n# |  Sam| 28|   88|  M|\n# |Flora| 28|   90|  F|\n# |Peter| 55|  100|  M|\n# |  Mei| 54|   95|  F|\n# +-----+---+-----+---+\n# cube 聚合之后的结果\n# +-----+----+-----+\n# | name| sex|count|\n# +-----+----+-----+\n# | null|   F|    2|\n# | null|null|    4|\n# |Flora|null|    1|\n# |Peter|null|    1|\n# | null|   M|    2|\n# |Peter|   M|    1|\n# |  Sam|   M|    1|\n# |  Sam|null|    1|\n# |  Mei|   F|    1|\n# |  Mei|null|    1|\n# |Flora|   F|    1|\n# +-----+----+-----+\n```\n\n## 保存数据/写入数据库\n\n这里的保存数据主要是保存到Hive中的栗子，主要包括了overwrite、append等方式。\n\n### 当结果集为SparkDataFrame的时候\n\n```python\nimport pandas as pd\nfrom datetime import datetime\nfrom pyspark import SparkConf\nfrom pyspark import SparkContext\nfrom pyspark.sql import HiveContext\n\nconf = SparkConf()\\\n      .setAppName(\"test\")\\\n      .set(\"hive.exec.dynamic.partition.mode\", \"nonstrict\") # 动态写入hive分区表\nsc = SparkContext(conf=conf)\nhc = HiveContext(sc)\nsc.setLogLevel(\"ERROR\")\n    \nlist_values = [['Sam', 28, 88], ['Flora', 28, 90], ['Run', 1, 60]]\nSpark_df = spark.createDataFrame(list_values, ['name', 'age', 'score'])\nprint(Spark_df.show())\nsave_table = \"tmp.samshare_pyspark_savedata\"\n\n# 方式1:直接写入到Hive\nSpark_df.write.format(\"hive\").mode(\"overwrite\").saveAsTable(save_table) # 或者改成append模式\nprint(datetime.now().strftime(\"%y/%m/%d %H:%M:%S\"), \"测试数据写入到表\" + save_table)\n\n# 方式2:注册为临时表，使用SparkSQL来写入分区表\nSpark_df.createOrReplaceTempView(\"tmp_table\")\nwrite_sql = \"\"\"\ninsert overwrite table {0} partitions (pt_date='{1}')\nselect * from tmp_table\n\"\"\".format(save_table, \"20210520\")\nhc.sql(write_sql)\nprint(datetime.now().strftime(\"%y/%m/%d %H:%M:%S\"), \"测试数据写入到表\" + save_table)\n```\n\n### 当结果集为Python的DataFrame的时候\n\n如果是Python的DataFrame，我们就需要多做一步把它转换为SparkDataFrame，其余操作就一样了。\n\n```python\nimport pandas as pd\nfrom datetime import datetime\nfrom pyspark import SparkConf\nfrom pyspark import SparkContext\nfrom pyspark.sql import HiveContext\n\nconf = SparkConf()\\\n      .setAppName(\"test\")\\\n      .set(\"hive.exec.dynamic.partition.mode\", \"nonstrict\") # 动态写入hive分区表\nsc = SparkContext(conf=conf)\nhc = HiveContext(sc)\nsc.setLogLevel(\"ERROR\")\n    \nresult_df = pd.DataFrame([1,2,3], columns=['a'])\nsave_table = \"tmp.samshare_pyspark_savedata\"\n\n# 获取DataFrame的schema\nc1 = list(result_df.columns)\n# 转为SparkDataFrame\nresult = hc.createDataFrame(result_df.astype(str), c1)\nresult.write.format(\"hive\").mode(\"overwrite\").saveAsTable(save_table) # 或者改成append模式\nprint(datetime.now().strftime(\"%y/%m/%d %H:%M:%S\"), \"测试数据写入到表\" + save_table)\n```\n\n## Spark 调优思路\n\n![调优](./PySpark基础001/调优思维导图.jpg)\n\n### 开发习惯优化\n\n#### 尽可能使用同一RDD，避免重复创建，并且适当持久化数据\n\n这种开发习惯是需要我们对于即将要开发的应用逻辑有比较深刻的思考，并且可以通过code review来发现的，讲白了就是要记得我们创建过啥数据集，可以复用的尽量广播（broadcast）下，能很好提升性能。\n\n```python\n# 最低级写法，相同数据集重复创建。\nrdd1 = sc.textFile(\"./test/data/hello_samshare.txt\", 4) # 这里的 4 指的是分区数量\nrdd2 = sc.textFile(\"./test/data/hello_samshare.txt\", 4) # 这里的 4 指的是分区数量\nprint(rdd1.take(10))\nprint(rdd2.map(lambda x:x[0:1]).take(10))\n\n# 稍微进阶一些，复用相同数据集，但因中间结果没有缓存，数据会重复计算\nrdd1 = sc.textFile(\"./test/data/hello_samshare.txt\", 4) # 这里的 4 指的是分区数量\nprint(rdd1.take(10))\nprint(rdd1.map(lambda x:x[0:1]).take(10))\n\n# 相对比较高效，使用缓存来持久化数据\nrdd = sc.parallelize(range(1, 11), 4).cache()  # 或者persist()\nrdd_map = rdd.map(lambda x: x*2)\nrdd_reduce = rdd.reduce(lambda x, y: x+y)\nprint(rdd_map.take(10))\nprint(rdd_reduce)\n```\n\n下面我们就来对比一下使用缓存能给我们的Spark程序带来多大的效率提升吧，我们先构造一个程序运行时长测量器。\n\n```python\nimport time\n# 统计程序运行时间\ndef time_me(info=\"used\"):\n    def _time_me(fn):\n        @functools.wraps(fn)\n        def _wrapper(*args, **kwargs):\n            start = time.time()\n            fn(*args, **kwargs)\n            print(\"%s %s %s\" % (fn.__name__, info, time.time() - start), \"second\")\n        return _wrapper\n    return _time_me\n```\n\n下面我们运行下面的代码，看下使用了cache带来的效率提升：\n\n```python\n@time_me()\ndef test(types=0):\n    if types == 1:\n        print(\"使用持久化缓存\")\n        rdd = sc.parallelize(range(1, 10000000), 4)\n        rdd1 = rdd.map(lambda x: x*x + 2*x + 1).cache()  # 或者 persist(StorageLevel.MEMORY_AND_DISK_SER)\n        print(rdd1.take(10))\n        rdd2 = rdd1.reduce(lambda x, y: x+y)\n        rdd3 = rdd1.reduce(lambda x, y: x + y)\n        rdd4 = rdd1.reduce(lambda x, y: x + y)\n        rdd5 = rdd1.reduce(lambda x, y: x + y)\n        print(rdd5)\n    else:\n        print(\"不使用持久化缓存\")\n        rdd = sc.parallelize(range(1, 10000000), 4)\n        rdd1 = rdd.map(lambda x: x * x + 2 * x + 1)\n        print(rdd1.take(10))\n        rdd2 = rdd1.reduce(lambda x, y: x + y)\n        rdd3 = rdd1.reduce(lambda x, y: x + y)\n        rdd4 = rdd1.reduce(lambda x, y: x + y)\n        rdd5 = rdd1.reduce(lambda x, y: x + y)\n        print(rdd5)\n\n        \ntest()   # 不使用持久化缓存\ntime.sleep(10)\ntest(1)  # 使用持久化缓存\n# output:\n# 使用持久化缓存\n# [4, 9, 16, 25, 36, 49, 64, 81, 100, 121]\n# 333333383333334999999\n# test used 26.36529278755188 second\n# 使用持久化缓存\n# [4, 9, 16, 25, 36, 49, 64, 81, 100, 121]\n# 333333383333334999999\n# test used 17.49532413482666 second\n```\n\n因为我们的代码是需要重复调用RDD1的，当没有对RDD1进行持久化的时候，每次当它被action算子消费了之后，就释放了，等下一个算子计算的时候要用，就从头开始计算一下RDD1。代码中需要重复调用RDD1 五次，所以没有缓存的话，差不多每次都要6秒，总共需要耗时26秒左右，但是，做了缓存，每次就只需要3s不到，总共需要耗时17秒左右。\n\n另外，这里需要提及一下一个知识点，那就是持久化的级别，一般cache的话就是放入内存中，就没有什么好说的，需要讲一下的就是另外一个 persist()，它的持久化级别是可以被我们所配置的：\n| 存储级别 | 说明 |\n| -- | -- |\n| MEMORY_ONLY | 使用未序列化的Java对象格式，将数据保存在内存中。如果内存不够存放所有的数据，则数据可能就不会进行持久化。那么下次对这个RDD执行算子操作时，那些没有被持久化的数据，需要从源头处重新计算一遍。这是默认的持久化策略，使用cache()方法时，实际就是使用的这种持久化策略。 |\n| MEMORY_AND_DISK | 使用未序列化的Java对象格式，优先尝试将数据保存在内存中。如果内存不够存放所有的数据，会将数据写入磁盘文件中，下次对这个RDD执行算子时，持久化在磁盘文件中的数据会被读取出来使用。 |\n| MEMORY_ONLY_SER | 基本含义同MEMORY_ONLY。唯一的区别是，会将RDD中的数据进行序列化，RDD的每个partition会被序列化成一个字节数组。这种方式更加节省内存，从而可以避免持久化的数据占用过多内存导致频繁GC。 |\n| MEMORY_AND_DISK_SER | 基本含义同MEMORY_AND_DISK。唯一的区别是，会将RDD中的数据进行序列化，RDD的每个partition会被序列化成一个字节数组。这种方式更加节省内存，从而可以避免持久化的数据占用过多内存导致频繁GC。|\n| DISK_ONLY | 使用未序列化的Java对象格式，将数据全部写入磁盘文件中。 |\n| MEMORY_ONLY_2，MEMORY_AND_DISK_2，等等 | 对于上述任意一种持久化策略，如果加上后缀_2，代表的是将每个持久化的数据，都复制一份副本，并将副本保存到其他节点上。这种基于副本的持久化机制主要用于进行容错。假如某个节点挂掉，节点的内存或磁盘中的持久化数据丢失了，那么后续对RDD计算时还可以使用该数据在其他节点上的副本。如果没有副本的话，就只能将这些数据从源头处重新计算一遍了。 |\n\n#### 尽量避免使用低性能算子\n\nshuffle类算子算是低性能算子的一种代表，如果有可能的话，要尽量避免使用shuffle类算子。因为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。shuffle过程，简单来说，就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作。比如reduceByKey、join等算子，都会触发shuffle操作。\n\nshuffle过程中，各个节点上的相同key都会先写入本地磁盘文件中，然后其他节点需要通过网络传输拉取各个节点上的磁盘文件中的相同key。而且相同key都拉取到同一个节点进行聚合操作时，还有可能会因为一个节点上处理的key过多，导致内存不够存放，进而溢写到磁盘文件中。因此在shuffle过程中，可能会发生大量的磁盘文件读写的IO操作，以及数据的网络传输操作。磁盘IO和网络数据传输也是shuffle性能较差的主要原因。\n\n因此在我们的开发过程中，能避免则尽可能避免使用reduceByKey、join、distinct、repartition等会进行shuffle的算子，尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。\n\n###### Broadcast与map进行join代码示例\n\n```scala\n// 传统的join操作会导致shuffle操作。\n// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。\nval rdd3 = rdd1.join(rdd2)\n\n// Broadcast+map的join操作，不会导致shuffle操作。\n// 使用Broadcast将一个数据量较小的RDD作为广播变量。\nval rdd2Data = rdd2.collect()\nval rdd2DataBroadcast = sc.broadcast(rdd2Data)\n\n// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。\n// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。\n// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。\nval rdd3 = rdd1.map(rdd2DataBroadcast...)\n\n// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。\n// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。\n\n```\n\n```python\n# 原则2：尽量避免使用低性能算子\nrdd1 = sc.parallelize([('A1', 211), ('A1', 212), ('A2', 22), ('A4', 24), ('A5', 25)])\nrdd2 = sc.parallelize([('A1', 11), ('A2', 12), ('A3', 13), ('A4', 14)])\n# 低效的写法，也是传统的写法，直接join\nrdd_join = rdd1.join(rdd2)\nprint(rdd_join.collect())\n# [('A4', (24, 14)), ('A2', (22, 12)), ('A1', (211, 11)), ('A1', (212, 11))]\nrdd_left_join = rdd1.leftOuterJoin(rdd2)\nprint(rdd_left_join.collect())\n# [('A4', (24, 14)), ('A2', (22, 12)), ('A5', (25, None)), ('A1', (211, 11)), ('A1', (212, 11))]\nrdd_full_join = rdd1.fullOuterJoin(rdd2)\nprint(rdd_full_join.collect())\n# [('A4', (24, 14)), ('A3', (None, 13)), ('A2', (22, 12)), ('A5', (25, None)), ('A1', (211, 11)), ('A1', (212, 11))]\n\n# 高效的写法，使用广播+map来实现相同效果\n# tips1: 这里需要注意的是，用来broadcast的RDD不可以太大，最好不要超过1G\n# tips2: 这里需要注意的是，用来broadcast的RDD不可以有重复的key的\nrdd1 = sc.parallelize([('A1', 11), ('A2', 12), ('A3', 13), ('A4', 14)])\nrdd2 = sc.parallelize([('A1', 211), ('A1', 212), ('A2', 22), ('A4', 24), ('A5', 25)])\n\n# step1： 先将小表进行广播，也就是collect到driver端，然后广播到每个Executor中去。\nrdd_small_bc = sc.broadcast(rdd1.collect())\n\n# step2：从Executor中获取存入字典便于后续map操作\nrdd_small_dict = dict(rdd_small_bc.value)\n\n# step3：定义join方法\ndef broadcast_join(line, rdd_small_dict, join_type):\n    k = line[0]\n    v = line[1]\n    small_table_v = rdd_small_dict[k] if k in rdd_small_dict else None\n    if join_type == 'join':\n        return (k, (v, small_table_v)) if k in rdd_small_dict else None\n    elif join_type == 'left_join':\n        return (k, (v, small_table_v if small_table_v is not None else None))\n    else:\n        print(\"not support join type!\")\n\n# step4：使用 map 实现 两个表join的功能\nrdd_join = rdd2.map(lambda line: broadcast_join(line, rdd_small_dict, \"join\")).filter(lambda line: line is not None)\nrdd_left_join = rdd2.map(lambda line: broadcast_join(line, rdd_small_dict, \"left_join\")).filter(lambda line: line is not None)\nprint(rdd_join.collect())\nprint(rdd_left_join.collect())\n# [('A1', (211, 11)), ('A1', (212, 11)), ('A2', (22, 12)), ('A4', (24, 14))]\n# [('A1', (211, 11)), ('A1', (212, 11)), ('A2', (22, 12)), ('A4', (24, 14)), ('A5', (25, None))]\n```\n\n上面的RDD join被改写为 broadcast+map的PySpark版本实现，不过里面有两个点需要注意：\n\n- tips1: 用来broadcast的RDD不可以太大，最好不要超过1G\n- tips2: 用来broadcast的RDD不可以有重复的key的\n\n#### 使用map-side预聚合的shuffle操作\n\n如果因为业务需要，一定要使用shuffle操作，无法用map类的算子来替代，那么尽量使用可以map-side预聚合的算子。\n\n所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。\n\n比如下两幅图，就是典型的例子，分别基于reduceByKey和groupByKey进行单词计数。其中第一张图是groupByKey的原理图，可以看到，没有进行任何本地聚合时，所有数据都会在集群节点之间传输；第二张图是reduceByKey的原理图，可以看到，每个节点本地的相同key数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。\n\n![groupByKey原理](./PySpark基础001/map-side-shuffle0.png)\n![reduceByKey原理](./PySpark基础001/map-side-shuffle1.png)\n\n#### 尽量使用高性能算子\n\n除了shuffle相关的算子有优化原则之外，其他的算子也都有着相应的优化原则。\n\n##### 使用reduceByKey/aggregateByKey替代groupByKey\n\n详情见：使用map-side预聚合的shuffle操作。\n\n##### 使用mapPartitions替代普通map\n\nmapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！\n\n##### 使用foreachPartitions替代foreach\n\n原理类似于“使用mapPartitions替代map”，也是一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据。在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；但是如果用foreachPartitions算子一次性处理一个partition的数据，那么对于每个partition，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于1万条左右的数据量写MySQL，性能可以提升30%以上。\n\n##### 使用filter之后进行coalesce操作\n\n通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去。因为filter之后，RDD的每个partition中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。因此用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。\n\n##### 使用repartitionAndSortWithinPartitions替代repartition与sort类操作\n\nrepartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。\n\n#### 广播大变量\n\n有时在开发过程中，会遇到需要在算子函数中使用外部变量的场景（尤其是大变量，比如100M以上的大集合），那么此时就应该使用Spark的广播（Broadcast）功能来提升性能。\n\n在算子函数中使用到外部变量时，默认情况下，Spark会将该变量复制多个副本，通过网络传输到task中，此时每个task都有一个变量副本。如果变量本身比较大的话（比如100M，甚至1G），那么大量的变量副本在网络中传输的性能开销，以及在各个节点的Executor中占用过多内存导致的频繁GC，都会极大地影响性能。\n\n因此对于上述情况，如果使用的外部变量比较大，建议使用Spark的广播功能，对该变量进行广播。广播后的变量，会保证每个Executor的内存中，只驻留一份变量副本，而Executor中的task执行时共享该Executor中的那份变量副本。这样的话，可以大大减少变量副本的数量，从而减少网络传输的性能开销，并减少对Executor内存的占用开销，降低GC的频率。\n\n##### python示例\n\n```python\n# 原则4：广播大变量\nrdd1 = sc.parallelize([('A1', 11), ('A2', 12), ('A3', 13), ('A4', 14)])\nrdd1_broadcast = sc.broadcast(rdd1.collect())\nprint(rdd1.collect())\nprint(rdd1_broadcast.value)\n# [('A1', 11), ('A2', 12), ('A3', 13), ('A4', 14)]\n# [('A1', 11), ('A2', 12), ('A3', 13), ('A4', 14)]\n```\n\n##### scala示例\n\n```scala\n// 以下代码在算子函数中，使用了外部的变量。\n// 此时没有做任何特殊操作，每个task都会有一份list1的副本。\nval list1 = ...\nrdd1.map(list1...)\n\n// 以下代码将list1封装成了Broadcast类型的广播变量。\n// 在算子函数中，使用广播变量时，首先会判断当前task所在Executor内存中，是否有变量副本。\n// 如果有则直接使用；如果没有则从Driver或者其他Executor节点上远程拉取一份放到本地Executor内存中。\n// 每个Executor内存中，就只会驻留一份广播变量副本。\nval list1 = ...\nval list1Broadcast = sc.broadcast(list1)\nrdd1.map(list1Broadcast...)\n```\n\n#### 使用Kryo优化序列化性能\n\n在Spark中，主要有三个地方涉及到了序列化：\n\n- 在算子函数中使用到外部变量时，该变量会被序列化后进行网络传输（见：广播大变量”中的讲解）。\n- 将自定义的类型作为RDD的泛型类型时（比如JavaRDD，Student是自定义类型），所有自定义类型对象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现Serializable接口。\n- 使用可序列化的持久化策略时（比如MEMORY_ONLY_SER），Spark会将RDD中的每个partition都序列化成一个大的字节数组。\n\n对于这三种出现序列化的地方，我们都可以通过使用Kryo序列化类库，来优化序列化和反序列化的性能。Spark默认使用的是Java的序列化机制，也就是ObjectOutputStream/ObjectInputStream API来进行序列化和反序列化。但是Spark同时支持使用Kryo序列化库，Kryo序列化类库的性能比Java序列化类库的性能要高很多。官方介绍，Kryo序列化机制比Java序列化机制，性能高10倍左右。Spark之所以默认没有使用Kryo作为序列化类库，是因为Kryo要求最好要注册所有需要进行序列化的自定义类型，因此对于开发者来说，这种方式比较麻烦。\n\n以下是使用Kryo的代码示例，我们只要设置序列化类，再注册要序列化的自定义类型即可（比如算子函数中使用到的外部变量类型、作为RDD泛型类型的自定义类型等）：\n\n```scala\n// 创建SparkConf对象。\nval conf = new SparkConf().setMaster(...).setAppName(...)\n// 设置序列化器为KryoSerializer。\nconf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n// 注册要序列化的自定义类型。\nconf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))\n```\n\n#### Spark作业基本原理\n\n如果要进行资源调优，我们就必须先知道Spark运行的机制与流程。\n\n![Spark作业基本运行原理](./PySpark基础001/Spark作业基本原理.png)\n\n详细原理见上图。我们使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。根据你使用的部署模式（deploy-mode）不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。Driver进程本身会根据我们设置的参数，占有一定数量的内存和CPU core。而Driver进程要做的第一件事情，就是向集群管理器（可以是Spark Standalone集群，也可以是其他的资源管理集群）申请运行Spark作业需要使用的资源，这里的资源指的就是Executor进程。YARN集群管理器会根据我们为Spark作业设置的资源参数，在各个工作节点上，启动一定数量的Executor进程，每个Executor进程都占有一定数量的内存和CPU core。\n\n在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver进程会将我们编写的Spark作业代码分拆为多个stage，每个stage执行一部分代码片段，并为每个stage创建一批task，然后将这些task分配到各个Executor进程中执行。**task是最小的计算单元，负责执行一模一样的计算逻辑（也就是我们自己编写的某个代码片段），只是每个task处理的数据不同而已。**一个stage的所有task都执行完毕之后，会在各个节点本地的磁盘文件中写入计算中间结果，然后Driver就会调度运行下一个stage。下一个stage的task的输入数据就是上一个stage输出的中间结果。如此循环往复，直到将我们自己编写的代码逻辑全部执行完，并且计算完所有的数据，得到我们想要的结果为止。\n\n**Spark是根据shuffle类算子来进行stage的划分。**如果我们的代码中执行了某个shuffle类算子（比如reduceByKey、join等），那么就会在该算子处，划分出一个stage界限来。可以大致理解为，shuffle算子执行之前的代码会被划分为一个stage，shuffle算子执行以及之后的代码会被划分为下一个stage。因此一个stage刚开始执行的时候，**它的每个task可能都会从上一个stage的task所在的节点，去通过网络传输拉取需要自己处理的所有key，然后对拉取到的所有相同的key使用我们自己编写的算子函数执行聚合操作（比如reduceByKey()算子接收的函数）。这个过程就是shuffle。**\n\n当我们在代码中执行了cache/persist等持久化操作时，根据我们选择的持久化级别的不同，每个task计算出来的数据也会保存到Executor进程的内存或者所在节点的磁盘文件中。\n\n因此Executor的内存主要分为三块：\n\n- 第一块是让task执行我们自己编写的代码时使用，默认是占Executor总内存的20%；\n- 第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用，默认也是占Executor总内存的20%；\n- 第三块是让RDD持久化时使用，默认占Executor总内存的60%。\n\ntask的执行速度是跟每个Executor进程的CPU core数量有直接关系的。一个CPU core同一时间只能执行一个线程。而每个Executor进程上分配到的多个task，都是以每个task一条线程的方式，多线程并发运行的。如果CPU core数量比较充足，而且分配到的task数量比较合理，那么通常来说，可以比较快速和高效地执行完这些task线程。\n\n以上就是Spark作业的基本运行原理的说明，大家可以结合上图来理解。理解作业基本原理，是我们进行资源参数调优的基本前提。\n\n#### 资源参数调优\n\n了解完了Spark作业运行的基本原理之后，对资源相关的参数就容易理解了。所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分，我们同时也给出了一个调优的参考值。\n\n##### num-executors\n\n- 参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。\n- 参数调优建议：每个Spark作业的运行一般设置`50~100`个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。\n\n##### executor-memory\n\n- 参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。\n- 参数调优建议：每个Executor进程的内存设置`4G~8G`较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的`1/3~1/2`，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。\n\n##### executor-cores\n\n- 参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。\n- 参数调优建议：Executor的CPU core数量设置为`2~4`个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的`1/3~1/2`左右比较合适，也是避免影响其它业务的作业运行。\n\n##### driver-memory\n\n- 参数说明：该参数用于设置Driver进程的内存。\n- 参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。\n\n##### spark.default.parallelism\n\n- 参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。\n- 参数调优建议：Spark作业的默认task数量为`500~1000`个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的`2~3`倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。\n\n##### spark.storage.memoryFraction\n\n- 参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。\n- 参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。\n\n##### spark.shuffle.memoryFraction\n\n- 参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。\n- 参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。\n\n>资源参数的调优，没有一个固定的值，需要同学们根据自己的实际情况（包括Spark作业中的shuffle操作数量、RDD持久化操作数量以及spark web ui中显示的作业gc情况），同时参考本篇文章中给出的原理以及调优建议，合理地设置上述参数。\n\n#### 资源参数参考示例\n\n以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节：\n\n```shell\n./bin/spark-submit \\\n  --master yarn-cluster \\\n  --num-executors 100 \\\n  --executor-memory 6G \\\n  --executor-cores 4 \\\n  --driver-memory 1G \\\n  --conf spark.default.parallelism=1000 \\\n  --conf spark.storage.memoryFraction=0.5 \\\n  --conf spark.shuffle.memoryFraction=0.3 \\\n```\n\n","tags":["Spark","大数据"],"categories":["大数据","Spark"]},{"title":"Spark部署模式","url":"/2023/10/19/Spark部署模式/","content":"\n# 简介\n\n`Spark Application`提交运行时的部署模式`Deploy Mode`，表示的是`Driver Program`运行的地方。\n- `client`:Driver Program 运行在`提交应用的Client`上\n- `cluster`:要么就是集群中从节点`(Standalone：Worker，YARN：NodeManager)`。\n\n默认值为`client`，当在实际的开发环境中，尤其是生产环境，使用`cluster`部署模式提交应用运行。\n\n# Client 模式\n\n以`Spark Application`运行到`Standalone`集群上为例，前面提交运行圆周率PI或者词频统计`WordCount程序`时，默认 `DeployMode`为`Client`，表示应用`Driver Program`运行在提交应用的`Client 主机`上（启动 JVM Process 进程），示意图如下：\n![Client模式](./Spark部署模式/Deploy-Mode-Client.jpg)\n\n# Cluster 模式\n\n如果采用cluster模式运行应用，应用Driver Program运行在集群从节点Worker某台机器上，示意图如下：\n![Cluster模式](./Spark部署模式/Deploy-Mode-Cluster.jpg)\n\n\n```scala\npackage cn.kaizi.spark\n\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.{SparkConf, SparkContext}\n\n\n/**\n * 基于Scala语言使用SparkCore编程实现词频统计：WordCount\n * 从HDFS上读取数据，统计WordCount，将结果保存到HDFS上\n **/\n\nobject SparkWordCount {\n\n  // TODO: 当应用运行在集群上的时候，MAIN函数就是Driver Program，必须创建SparkContext对象\n  def main(args: Array[String]): Unit = {\n    // 创建SparkConf对象，设置应用的配置信息，比如应用名称和应用运行模式\n    val sparkConf: SparkConf = new SparkConf()\n      .setMaster(\"local[2]\")  // 设置运行本地模式\n      .setAppName(\"SparkWordCount\")\n    // 构建SparkContext上下文实例对象，读取数据和调度Job执行\n    val sc: SparkContext = new SparkContext(sparkConf)\n\n    // ************第一步、读取数据:在Spark的Executor中执行***************\n    // 封装到RDD集合，认为列表List\n    val inputRDD: RDD[String] = sc.textFile(\"/datas/wordcount.data\")\n    // ***************************************************************\n\n    // ************第二步、处理数据:在Spark的Executor中执行***************\n    // 调用RDD中函数，认为调用列表中的函数\n    // a. 每行数据分割为单词\n    val wordsRDD = inputRDD.flatMap(line => line.split(\"\\\\s+\"))\n    // b. 转换为二元组，表示每个单词出现一次\n    val tuplesRDD: RDD[(String, Int)] = wordsRDD.map(word => (word, 1))\n    // c. 按照Key分组聚合\n    val wordCountsRDD: RDD[(String, Int)] = tuplesRDD.reduceByKey((tmp, item) => tmp + item)\n    // ***************************************************************\n\n    // ************第三步、输出数据:在Spark的Executor中执行****************\n    wordCountsRDD.foreach(println)\n    // 保存到为存储系统，比如HDFS\n    wordCountsRDD.saveAsTextFile(s\"/datas/swc-output-${System.currentTimeMillis()}\")\n    // ***************************************************************\n\n    // 为了测试，线程休眠，查看WEB UI界面\n    Thread.sleep(10000000)\n    // TODO：应用程序运行接收，关闭资源\n    sc.stop()\n  }\n}\n\n```\n\n> main方法中一开始的创建SparkContext对象和最后的关闭SparkContext资源，都是在Driver Program中执行的，代码中的第一步加载数据、第二步处理数据、第三步输出数据都是在Executor上执行。\n\n综上所述Spark Application中Job执行有两个主要点：\n- RDD输出函数分类两类\n    - 第一类：返回值给`Driver Progam`，比如`count`、`first`、`take`、`collect`等\n    - 第二类：没有返回值，比如直接打印结果、保存至外部存储系统（HDFS文件）等\n- 在`Job`中从读取数据封装为`RDD`和一切`RDD调用方法`都是在`Executor`中执行，其他代码都是在`Driver Program`中执行\n    - `SparkContext`创建与关闭、其他变量创建等在`Driver Program`中执行\n    - `RDD调用函数`都是在Executors中执行\n\n\n# Client模式和Cluster模式的区别\n\nCluster和Client模式最本质的区别是：Driver程序运行在哪里。\n- cluster模式：生产环境中使用该模式\n  - Driver程序在YARN集群当中\n  - 应用的运行结果不能在客户端显示\n- client模式：学习测试时使用（也不一定，个人觉得生产环境也可以用）\n  - Driver运行在Client上的SparkSubmit进程中\n  - 应用程序运行结果会在客户端显示\n\n\n","tags":["Spark","大数据"],"categories":["大数据","Spark"]},{"title":"Linux系统中Pycharm界面显示问题","url":"/2023/08/06/Linux系统中Pycharm界面显示问题/","content":"\n# 前言\n打开`Pycharm`，激活界面中的中文显示不了，因为缺少了字体，`文泉驿正黑`，我用的是`Fedora`，记录一下`Fedora`下安装`文泉驿正黑`这个字体\n\n# 安装`文泉驿正黑`\n## 安装\n```shell\nsudo dnf install -y wqy-zenhei-fonts\n```\n> 也可以使用`Fedora`的软件包管理器安装`ttf-wqy-zenhei`字体包\n\n## 刷新字体\n```shell\nfc-cache -f -v\n```\n\n## 验证\n```shell\nfc-list | grep \"文泉驿正黑\"\n```\n\n","categories":["Linux"]},{"title":"Python中的args和kwargs参数","url":"/2023/07/14/Python中的args和kwargs参数/","content":"# *args && **kwargs\n在Python项目的代码中经常会见到这两个词 args 和 kwargs，前面通常还会加上一个或者两个星号。其实这只是编程人员约定的变量名字，args 是 arguments 的缩写，表示位置参数；kwargs 是 keyword arguments 的缩写，表示关键字参数。这其实就是 Python 中可变参数的两种形式，并且 *args 必须放在 **kwargs 的前面，因为位置参数在关键字参数的前面。\n\n# 在函数定义中的用法\n\n## *args的用法\n*args就是就是传递一个可变参数列表给函数实参，这个参数列表的数目未知，甚至长度可以为0。下面这段代码演示了如何使用args\n```python\ndef test_args(first, *args):\n    print('Required argument: ', first)\n    print(type(args))\n    for v in args:\n        print ('Optional argument: ', v)\n\ntest_args(1, 2, 3, 4)\n```\n第一个参数是必须要传入的参数，所以使用了第一个形参，而后面三个参数则作为可变参数列表传入了实参，并且是作为元组tuple来使用的。代码的运行结果如下:\n```\nRequired argument:  1\n<class 'tuple'>\nOptional argument:  2\nOptional argument:  3\nOptional argument:  4\n```\n\n## **kwargs用法\n**kwargs则是将一个可变的关键字参数的字典传给函数实参，同样参数列表长度可以为0或为其他值。下面这段代码演示了如何使用kwargs：\n```python\ndef test_kwargs(first, *args, **kwargs):\n   print('Required argument: ', first)\n   print(type(kwargs))\n   for v in args:\n      print ('Optional argument (args): ', v)\n   for k, v in kwargs.items():\n      print ('Optional argument %s (kwargs): %s' % (k, v))\n\ntest_kwargs(1, 2, 3, 4, k1=5, k2=6)\n```\n正如前面所说的，args类型是一个tuple，而kwargs则是一个字典dict，并且args只能位于kwargs的前面。代码的运行结果如下:\n```\nRequired argument:  1\n<class 'dict'>\nOptional argument (args):  2\nOptional argument (args):  3\nOptional argument (args):  4\nOptional argument k2 (kwargs): 6\nOptional argument k1 (kwargs): 5\n```\n\n# 调用函数中的用法\nargs和kwargs不仅可以在函数定义中使用，还可以在函数调用中使用。在调用时使用就相当于pack（打包）和unpack（解包），类似于元组的打包和解包。\n\n首先来看一下使用args来解包调用函数的代码：\n```python\ndef test_args_kwargs(arg1, arg2, arg3):\n    print(\"arg1:\", arg1)\n    print(\"arg2:\", arg2)\n    print(\"arg3:\", arg3)\n\nargs = (\"two\", 3, 5)\ntest_args_kwargs(*args)\n\n```\n输出：\n```\narg1: two\narg2: 3\narg3: 5\n```\n> 将元组解包后传给对应的实参，kwargs的用法与其类似。\n\n```python\nkwargs = {\"arg3\": 3, \"arg2\": \"two\", \"arg1\": 5}\ntest_args_kwargs(**kwargs)\n```\n输出：\n```\narg1: 5\narg2: two\narg3: 3\n```\n\n# 总结\nargs和kwargs组合起来可以传入任意的参数，这在参数未知的情况下是很有效的，同时加强了函数的可拓展性。","tags":["args","kwargs"],"categories":["Python","基础"]},{"title":"Python中装饰器的wraps的作用","url":"/2023/07/14/Python中装饰器的wraps的作用/","content":"\n# 装饰器\n`Python`装饰器`decorator`在实现的时候，被装饰后的函数其实已经是另外一个函数了（函数名等函数属性会发生改变），就相当于产生了`副作用`，`Python`的`functools`包中提供了一个叫`wraps`的`decorator`来消除这样的`副作用`。写一个`decorator`的时候，最好在实现之前加上`functools`的`wrap`，它能保留原有函数的`__name__`和`__doc__`。\n\n# 示例1（副作用）\n```python\ndef my_decorator(func):\n    def wrapper(*args, **kwargs):\n        \"\"\"decorator\"\"\"\n        print('Calling decorated function...')\n        return func(*args, **kwargs)\n\n    return wrapper\n\n\n@my_decorator\ndef example():\n    \"\"\"DocString\"\"\"\n    print('Called example function.')\n\n\nprint(example.__name__, example.__doc__)\n\nif __name__ == '__main__':\n    example()\n\n```\n> 打印现来的是：wrapper decorator 而不是 example DocString\n\n# 示例2（消除副作用）\n```python\nfrom functools import wraps\n\n\ndef my_decorator(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        \"\"\"Decorator\"\"\"\n        print('Calling decorated function...')\n        return func(*args, **kwargs)\n\n    return wrapper\n\n\n@my_decorator\ndef example():\n    \"\"\"DocString\"\"\"\n    print('Called example function')\n\n\nif __name__ == '__main__':\n    example()\n\n```\n\n> 无毒副作用, 这就是`@wraps`的作用","categories":["Python","基础"]},{"title":"怎么把K8S中部署的服务端口映射出来","url":"/2023/06/30/怎么把K8S中部署的服务端口映射出来/","content":"1. 修改fate-10001命名空间下的mysql的端口映射模式\n   - 先查看fate-10001下有哪些服务\n   ```shell\n   kubectl get svc -n fate-10001\n   ```\n    ```\n    NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)                               AGE\n    spark-master         ClusterIP      None            <none>          8080/TCP,7077/TCP,6066/TCP            16d\n    fateflow             ClusterIP      None            <none>          9360/TCP,9380/TCP                     16d\n    spark-worker-1       ClusterIP      None            <none>          8081/TCP                              16d\n    fateflow-client      ClusterIP      10.43.80.240    <none>          9360/TCP,9380/TCP                     16d\n    datanode             ClusterIP      10.43.247.69    <none>          9000/TCP,9864/TCP                     16d\n    frontend             NodePort       10.43.24.110    <none>          8080:31925/TCP,8443:31194/TCP         16d\n    notebook             ClusterIP      10.43.41.5      <none>          20000/TCP                             16d\n    fateboard            ClusterIP      10.43.3.44      <none>          8080/TCP                              16d\n    namenode             ClusterIP      10.43.146.160   <none>          9000/TCP,9870/TCP                     16d\n    pulsar               ClusterIP      10.43.42.170    <none>          6650/TCP,6651/TCP,8080/TCP,8081/TCP   16d\n    postgres             ClusterIP      10.43.182.72    <none>          5432/TCP                              16d\n    mysql                ClusterIP      10.43.42.233    <none>          3306/TCP                              16d\n    nginx                NodePort       10.43.101.234   <none>          9300:31960/TCP,9310:32603/TCP         16d\n    spark-client         ClusterIP      10.43.69.60     <none>          8080/TCP,7077/TCP,6066/TCP            16d\n    site-portal-server   ClusterIP      10.43.237.196   <none>          8080/TCP,8443/TCP                     16d\n    pulsar-public-tls    LoadBalancer   10.43.144.61    192.168.11.71   6651:32593/TCP                        16d\n    ```\n    > 注意msyql 的type 是 ClusterIP，这样就只能被k8s集群内部访问而不能被外部访问到，所以这里要把它改为NodePort模式\n\n    - 修改mysql的type\n    ```shell\n    kubectl edit svc mysql -n fate-10001\n    ```\n\n    ```yaml\n    apiVersion: v1\n    kind: Service\n    metadata:\n    annotations:\n        meta.helm.sh/release-name: party10001\n        meta.helm.sh/release-namespace: fate-10001\n    creationTimestamp: \"2023-06-13T05:46:12Z\"\n    labels:\n        app.kubernetes.io/managed-by: Helm\n        chart: fate\n        cluster: fate\n        fateMoudle: mysql\n        heritage: Helm\n        name: party10001\n        owner: kubefate\n        partyId: \"10001\"\n        release: party10001\n    name: mysql\n    namespace: fate-10001\n    resourceVersion: \"33441\"\n    uid: 08d5e8fe-7853-4f85-b17c-9315afdd6055\n    spec:\n    clusterIP: 10.43.42.233\n    clusterIPs:\n    - 10.43.42.233\n    internalTrafficPolicy: Cluster\n    ipFamilies:\n    - IPv4\n    ipFamilyPolicy: SingleStack\n    ports:\n    - name: tcp-mysql\n        port: 3306\n        protocol: TCP\n        targetPort: 3306\n    selector:\n        fateMoudle: mysql\n        name: party10001\n        partyId: \"10001\"\n    sessionAffinity: None\n    type: ClusterIP\n    status:\n    loadBalancer: {}\n    ```\n    修改后的内容为：\n    ```yaml\n    apiVersion: v1\n    kind: Service\n    metadata:\n    annotations:\n        meta.helm.sh/release-name: party10001\n        meta.helm.sh/release-namespace: fate-10001\n    creationTimestamp: \"2023-06-13T05:46:12Z\"\n    labels:\n        app.kubernetes.io/managed-by: Helm\n        chart: fate\n        cluster: fate\n        fateMoudle: mysql\n        heritage: Helm\n        name: party10001\n        owner: kubefate\n        partyId: \"10001\"\n        release: party10001\n    name: mysql\n    namespace: fate-10001\n    resourceVersion: \"33441\"\n    uid: 08d5e8fe-7853-4f85-b17c-9315afdd6055\n    spec:\n    clusterIP: 10.43.42.233\n    clusterIPs:\n    - 10.43.42.233\n    internalTrafficPolicy: Cluster\n    externalTrafficPolicy: Cluster\n    ipFamilies:\n    - IPv4\n    ipFamilyPolicy: SingleStack\n    ports:\n    - name: tcp-mysql\n        port: 3306\n        protocol: TCP\n        targetPort: 3306\n        nodePort: 31306\n    selector:\n        fateMoudle: mysql\n        name: party10001\n        partyId: \"10001\"\n    sessionAffinity: None\n    type: NodePort\n    status:\n    loadBalancer: {}\n    ```","tags":["k8s","端口映射"],"categories":["云原生","基础设施"]},{"title":"vim常用插件的使用备忘录","url":"/2023/06/16/vim常用插件的使用备忘录/","content":"\n\n# `vim-surround` 的用法\n- `cs'\"`用双引号替换单引号\n- `cs\"'`用单引号替换双引号\n- `ysiw<q>`给当前单词加上标签`<q>`\n- `cst\"`用双引号替换当前的标签\n- `ds'`删除单引号\n- `ysiw]`在当前单词外加上方括号\n- `yss]`在当前句子处加上方括号  \n\n# vim编辑`markdown`在浏览器中预览效果\n- 安装`coc-nvim`插件\n- 使用`coc-nvim`插件安装`coc-markdown`插件\n- 使用`:CocCommand markdown-preview-enhanced.openPreview`命令在浏览器中打开预览\n\n# `coc-vim`的使用\n- 可以先安装一个`coc-marketplace`插件:`:CocInstall coc-marketplace`\n- `CocList marketplace`列出所有可用的插件\n- 在选中的插件上可以使用`tab`来进行`install`,`uninstall`,`homepage`等动作\n\n# `vim-easy-align`的使用\n\n```\n  Lorem   = ipsum\n  dolor   = sit\n   amet  += consectetur == adipiscing\n   elit  -= sed           != do\neiusmod   = tempor        = incididunt\n     ut &&= labore\n```\n- normal模式下：`gaip`\n  - `=`Around the 1st occurrentces\n  - `2=`Around the 2nd occurrences\n  - `*=`Around all occurrences\n  - `**=`Left/Right alternating alignment around all occurrences\n  - `<Enter>`Switching between left/right/center alignment modes\n\n- `visual line` 模式: `vip`\n  - `ga`进入`easyalign`模式\n  - `<Enter>` 切换对齐模式\n  - 输入`对齐目标字符`, 再`<Space>` 完成对齐操作\n\n# `nerdtree`的使用\n- `j`, `k` 在目录下上移动\n- `o`展开目录或打开文件，焦点会跑到右侧文件视图中\n- `ctrl + w + h`可以让焦点从文件中回到左侧目录视图中\n- `:NERDTreeToggle`命令是`NERDTree`打开或关闭的开关,在`.vimrc`中设置快捷键把它用`F3`来控制\n    ```shell\n    \" 设置NerdTree\n    map <F3> :NERDTreeMirror<CR>\n    map <F3> :NERDTreeToggle<CR>\n    ```\n# `TagBar`的使用\n- `:TagbarToggle`\n","tags":["vim","plugin"],"categories":["Linux"]},{"title":"k8s中configMap编辑示例","url":"/2023/06/14/k8s中configMap编辑示例/","content":"\n# 背景\n部署在k3s中的一个应用，在前端页面中上传文件，出现报错，提示是文件太大。需要修改nginx配置来解决这个问题。这个应用部署在fate-10000命名空间下\n\n# 解决\n- 查看一下fate-10000这个命名空间\n  ```shell\n  kubectl get all  -n fate-10000\n  ```\n  ![查看命名空间](k8s中configMap编辑示例/fate-10000.jpg)\n\n- 先查看一下`site-portal`前端`pod`的描述信息：例子中为`fate-10000`命名空间下的`frontend-85b6fdffc4-4lkpc`\n  ```shell\n  kubectl describe pod frontend-85b6fdffc4-4lkpc -n fate-10000\n  ```\n  ![frontend描述信息](k8s中configMap编辑示例/frontend.jpg)\n> 注意图中nginx的配置文件会从nginx-conf-https中获取一些运维自定义的配置，nginx-conf-http是一个configMap, configMap的作用我理解的就是给运维人员后期动态去修改配置，pod从configMap中获取这些自定义的值后就达到了动态修改配置的目的，当然configMap修改后，相关的pod需要重启\n\n- 查看命名空间下的configMap\n  ```shell\n  kubectl get cm -n fate-10000\n  ```\n  ![configMap](k8s中configMap编辑示例/get-cm.jpg)\n\n- 编辑configMap中的内容\n  ```shell\n  kubectl edit cm nginx-conf-https -n fate-10000\n  ```\n  ![编辑configMap](k8s中configMap编辑示例/edit-cm.jpg)\n\n- 获取deployment\n  ```shell\n  kubectl get deploy -n fate-10000\n  ```\n  ![deployment](k8s中configMap编辑示例/deployment.jpg)\n\n- 用另外一种方式确认某个pod是否和某个configMap有关联\n  ```shell\n  kubectl get deploy frontend -n fate-10000 -o yaml\n  ```\n  返回如下：\n   ```yaml\n   apiVersion: apps/v1\n   kind: Deployment\n   metadata:\n   annotations:\n      deployment.kubernetes.io/revision: \"2\"\n      meta.helm.sh/release-name: party10000\n      meta.helm.sh/release-namespace: fate-10000\n   creationTimestamp: \"2023-06-14T01:09:35Z\"\n   generation: 2\n   labels:\n      app.kubernetes.io/managed-by: Helm\n      chart: fate\n      cluster: fate\n      fateMoudle: frontend\n      heritage: Helm\n      name: party10000\n      owner: kubefate\n      partyId: \"10000\"\n      release: party10000\n   name: frontend\n   namespace: fate-10000\n   resourceVersion: \"319024\"\n   uid: e62cf903-86b2-4799-96e1-f366ed4e3395\n   spec:\n   progressDeadlineSeconds: 600\n   replicas: 1\n   revisionHistoryLimit: 10\n   selector:\n      matchLabels:\n         fateMoudle: frontend\n         name: party10000\n         partyId: \"10000\"\n   strategy:\n      type: Recreate\n   template:\n      metadata:\n         annotations:\n         kubectl.kubernetes.io/restartedAt: \"2023-06-14T10:41:20+08:00\"\n         creationTimestamp: null\n         labels:\n         chart: fate\n         cluster: fate\n         fateMoudle: frontend\n         heritage: Helm\n         name: party10000\n         owner: kubefate\n         partyId: \"10000\"\n         release: party10000\n      spec:\n         containers:\n         - env:\n         - name: SITEPORTAL_SERVER_HOST\n            value: site-portal-server\n         image: federatedai/site-portal-frontend:v0.3.0\n         imagePullPolicy: IfNotPresent\n         name: frontend\n         ports:\n         - containerPort: 8443\n            protocol: TCP\n         resources: {}\n         terminationMessagePath: /dev/termination-log\n         terminationMessagePolicy: File\n         volumeMounts:\n         - mountPath: /var/lib/site-portal/cert\n            name: site-portal-cert\n         - mountPath: /etc/nginx/conf.d/nginx.conf.template\n            name: nginx-conf-https\n            subPath: nginx.conf.template\n         dnsPolicy: ClusterFirst\n         restartPolicy: Always\n         schedulerName: default-scheduler\n         securityContext: {}\n         serviceAccount: default\n         serviceAccountName: default\n         terminationGracePeriodSeconds: 30\n         volumes:\n         - name: site-portal-cert\n         secret:\n            defaultMode: 420\n            secretName: site-portal-cert\n         - configMap:\n            defaultMode: 420\n            name: nginx-conf-https\n         name: nginx-conf-https\n   status:\n   availableReplicas: 1\n   conditions:\n   - lastTransitionTime: \"2023-06-14T02:41:23Z\"\n      lastUpdateTime: \"2023-06-14T02:41:23Z\"\n      message: Deployment has minimum availability.\n      reason: MinimumReplicasAvailable\n      status: \"True\"\n      type: Available\n   - lastTransitionTime: \"2023-06-14T01:09:35Z\"\n      lastUpdateTime: \"2023-06-14T02:41:23Z\"\n      message: ReplicaSet \"frontend-85b6fdffc4\" has successfully progressed.\n      reason: NewReplicaSetAvailable\n      status: \"True\"\n      type: Progressing\n   observedGeneration: 2\n   readyReplicas: 1\n   replicas: 1\n   updatedReplicas: 1\n   ```\n  > 注意看其中的 configMap, 就是: nginx-conf-https，所以说明我们可以去改nginx-config-https这个configMap中的值，修改会作用于frontend\n\n- 编辑configMap\n```shell\nkubectl edit cm nginx-conf-https -n fate-10000\n```\n上述命令会使用nano打开configMap,可以对configMap进行编辑\n![编辑configMap](k8s中configMap编辑示例/edit-cm.jpg)\n\n- 重启frontend\n```shell\nkubectl rollout restart deployment/frontend -n fate-10000\n```\n> 注意这个命令中的 `deployment/frontend`, 命令中需要有`deployment/`加在前面","tags":["configMap"],"categories":["云原生","基础设施"]},{"title":"ABY开源框架编译","url":"/2023/06/11/ABY开源框架编译/","content":"\n# ABY开源框架\n[ABY开源框架](https://github.com/encryptogroup/ABY)\n\n# 编译准备\n\n- cmake\n\n  ```shell\n  sudo dnf install cmake\n  ```\n  \n- C Development Tools and Libraries\n\n  ```shell\n  sudo dnf group install \"C Development Tools and Libraries\" \"Development Tools\"\n  ```\n- boost\n\n  ```shell\n  sudo dnf install boost-devel\n  ```\n  \n- libgmp\n\n  ```shell\n  sudo dnf install gmp-devel\n  ```\n  \n- libssl\n\n  ```shell\n  sudo dnf install openssl-devel\n  ```\n\n# 编译\n\n- git clone\n\n  ```shell\n  git clone https://github.com/encryptogroup/ABY.git\n  ```\n  \n- cd\n\n  ```shell\n  cd ABY/\n  ```\n- mkdir\n\n  ```shell\n  mkdir build && cd build\n  ```\n  \n- cmake && make && make install\n\n  ```shell\n  cmake .. -DCMAKE_INSTALL_PREFIX=\"\"\n  make\n  make DESTDIR=~/path/to/aby/prefix install\n  ```\n  \n  or\n\n  ```shell\n  cmake .. -DCMAKE_INSTALL_PREFIX=~/path/to/aby/prefix\n  make\n  make install\n  ```\n  \n> 这一步我出错了。编译报错文件：`ABY/extern/ENCRYPTO_utils/src/ENCRYPTO_utils/channel.cpp`\n> 错误原因就是缺少了`#include <cstdlib>`,引入头文件后就好了\n\n# 编译选项\n\n```shell\ncmake .. -DCMAKE_BUILD_TYPE=Release\n# or\ncmake .. -DCMAKE_BUILD_TYPE=Debug\n```\n\n","tags":["cmake","fedora","boost"]},{"title":"手动部署KubeFate","url":"/2023/06/09/手动部署KubeFate/","content":"\n# 依赖的软件环境\n- k8s：我使用的是k3s\n- ingress-nginx\n- 拉取KubeFate的代码并编译生成kubefate可执行文件：\n```shell\ngit clone https://github.com/FederatedAI/KubeFATE.git\ncd kubefate\nmake\n```\n> 官方文档有推荐版本，我没去管它\n\n# 创建k8s服务的帐号以及namespace等\n在`KubeFATE/k8s-deploy`目录下，有个`rbac-config.yaml`文件，里面有定义了帐号，命名空间等内容：\n```yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: kube-fate\n  labels:\n    name: kube-fate\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: kubefate-admin\n  namespace: kube-fate\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: kubefate\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: kubefate-role\nsubjects:\n  - kind: ServiceAccount\n    name: kubefate-admin\n    namespace: kube-fate\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: kubefate-secret\n  namespace: kube-fate\ntype: Opaque\nstringData:\n  kubefateUsername: admin\n  kubefatePassword: admin\n  mariadbUsername: kubefate\n  mariadbPassword: kubefate\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: kubefate-role\n  namespace: kube-fate\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - namespaces\n  - configmaps\n  - services\n  - secrets\n  - persistentvolumeclaims\n  - serviceaccounts\n  verbs:\n  - get\n  - list\n  - create\n  - delete\n  - update\n  - patch\n- apiGroups:\n  - \"\"\n  resources:\n  - pods\n  - pods/log\n  - nodes\n  verbs:\n  - get\n  - list\n- apiGroups:\n  - apps\n  resources:\n  - deployments\n  - statefulsets\n  - deployments/status\n  - statefulsets/status\n  verbs:\n  - get\n  - list\n  - create\n  - delete\n  - update\n  - patch\n- apiGroups:\n  - networking.k8s.io\n  resources:\n  - ingresses\n  verbs:\n  - get\n  - list\n  - create\n  - delete\n  - update\n  - patch\n- apiGroups:\n  - networking.istio.io\n  resources:\n  - gateways\n  - virtualservices\n  verbs:\n  - get\n  - create\n  - delete\n  - update\n  - patch\n- apiGroups:\n  - rbac.authorization.k8s.io\n  resources:\n  - roles\n  - rolebindings\n  verbs:\n  - get\n  - create\n  - delete\n  - update\n  - patch\n- apiGroups:\n    - batch\n  resources:\n    - jobs\n  verbs:\n    - get\n    - list\n    - create\n    - delete\n    - update\n    - patch\n```\n> 如果需要修改用户名密码之类的，可以查看上述yaml中的配置自行修改\n\n在`KubeFATE/k8s-deploy`目录下执行：\n```shell\nsudo kubectl apply -f ./rbac-config.yaml\n```\n\n# 准备域名及部署KubeFATE服务\n因为KubeFATE服务向外暴露RESTful APIs，所以系统管理员需要为此准备域名的DNS解析。在我们的配置样例里，使用`example.com`作为域名（需要修改成真实域名，但是为了学习搭建就无所谓了）。同时，系统管理员需要为每个FATE集群创建一个`namespace`，譬如`party_id`为`9999`的FATE集群，创建一个`fate-9999`的`namespace`，然后进行配额控制。\n\n```shell\nkubectl apply -f ./kubefate.yaml\nkubectl create namespace fate-9999\n```\n\n后续再执行：\n```shell\nsudo kubectl get ingress -A\n```\n可以看到返回类似于以下信息：\n```shell\nNAMESPACE   NAME       CLASS   HOSTS         ADDRESS       PORTS   AGE\nkube-fate   kubefate   nginx   example.com   10.43.62.61   80      12m\n```\n> ADDRESS 10.43.62.61 添加至/etc/hosts中\n```shell\nsudo vim /etc/hosts\n```\n```\n10.43.62.61 example.com\n```\n\n查看ingress-nginx命名空间下的服务：\n```shell\nsudo kubectl get svc -n ingress-nginx\n```\n\n可以看到返回类似于以下信息：\n```shell\nNAME                                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\ningress-nginx-controller-admission   ClusterIP   10.43.169.125   <none>        443/TCP                      4d\ningress-nginx-controller             NodePort    10.43.62.61     <none>        80:31683/TCP,443:31292/TCP   4d\n```\n\n```shell\nsudo kubectl get svc -n kube-fate\n```\n返回类似以下信息：\n```shell\nNAME       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE\nmariadb    ClusterIP   10.43.128.75   <none>        3306/TCP   33m\nkubefate   ClusterIP   10.43.235.20   <none>        8080/TCP   33m\n```\n\n完成以上步骤后，docker容器的启动情况查看一下：\n```shell\nsudo docker ps \n```\n返回类似于以下信息：\n```shell\nCONTAINER ID   IMAGE                        COMMAND                   CREATED          STATUS          PORTS     NAMES\n5ece9858fd52   93aad7121ec0                 \"/kubefate service\"       11 minutes ago   Up 11 minutes             k8s_kubefate_kubefate-74897fc6d7-zrcqf_kube-fate_d221b8f5-b6f1-4861-9281-5561f01875f3_2\n116bb9217b97   9a79847e85fb                 \"docker-entrypoint.s…\"   12 minutes ago   Up 12 minutes             k8s_mariadb_mariadb-7456b6c968-b9zlx_kube-fate_2b1ac004-4155-4b11-bb3f-afd91e0563d2_0\n5d13492b8755   rancher/mirrored-pause:3.6   \"/pause\"                  12 minutes ago   Up 12 minutes             k8s_POD_mariadb-7456b6c968-b9zlx_kube-fate_2b1ac004-4155-4b11-bb3f-afd91e0563d2_0\n05635a80430c   rancher/mirrored-pause:3.6   \"/pause\"                  12 minutes ago   Up 12 minutes             k8s_POD_kubefate-74897fc6d7-zrcqf_kube-fate_d221b8f5-b6f1-4861-9281-5561f01875f3_0\n```\n> 至此，FATE的后台服务已经部署完成\n\n# 准备FATE的安装配置文件并部署FATE\n当系统管理员成功部署了`KubeFATE`服务，并准备好新的FATE集群`namespace`，接下来就可以根据这些信息开始部署FATE集群。`config.yaml`是使用`KubeFATE`命令行的配置文件，包含`KubeFATE`服务的访问用户名密码，以及`log`配置，`域名`。\n\n```yaml\nlog:\n  level: info\nuser:\n  username: admin\n  password: admin\n\nserviceurl: example.com\nsafeconnect: false\n```\n\n| 名字 | 种类 | 描述 |\n| -- | -- | -- |\n| log | scalars | 命令行的日志级别。设置成debug级别可以看到REST通信信息 |\n| user | mappings | KubeFATE的认证用户名，密码 |\n| serviceurl | scalars | KubeFATE服务使用的域名 |\n| safeconnect | scalars | 是否使用https访问KubeFATE服务使用的域名;[参考](https://github.com/FederatedAI/KubeFATE/blob/master/docs/configurations/kubefate_service_tls_enable.md) |\n\n样例里面包含了`cluster.yaml`, 是FATE的部署计划，更多自定义内容参考：[FATE Cluster Configuration Guild](https://github.com/FederatedAI/KubeFATE/blob/master/docs/configurations/FATE_cluster_configuration.md)\n\n因为我是要部署`Spark`作为计算引擎；`Pulsar`作为通讯组件的架构；所以选择的是样例里面的`cluster-spark-pulsar.yaml`\n> 为了避免由于网络原因拉取docker镜像失败，需要设置一下`cluster-spark-pulsar.yaml'中的`registry`\n\n```\nregistry: \"hub.c.163.com/federatedai\"\n```\n\n使用`kubefate`来安装集群, 在`k8s-deploy`目录下的`bin`目录下（之前`make`编译生成）：\n```shell\nkubefate cluster install -f ./cluster-spark-pulsar.yaml\n```\n```\ncreate job Success, job id=0f82371a-442c-4a50-aeb5-528e5a896d52\n```\n> 这一步需要保证/etc/hosts中已添加了example.com，我在这一步卡了很久，一直不成功。\n\n根据出错信息尝试了一些，最终解决掉了，但具体是哪个操作解决了目前没去深究，以下是我做的处理：\n- 关闭科学上网软件（在终端内关闭科学上网，clash我忘了有没关，最好也关一下，之前遇到过在/etc/hosts添加了域名，但是clash开着导致hosts中的域名无法解析的坑，具体原因也不明）\n- 移除了docker的代理（在 /etc/systemd/system/docker.service.d/proxy.conf中我原先设置了代理），后来把它mv proxy.conf proxy.conf.bak了\n- 关闭了系统的防火墙\n- 重启docker,重启k3s\n\n# 检查安装集群任务的状态\n```shell\nkubefate job describe 0f82371a-442c-4a50-aeb5-528e5a896d52\n```\n```\nUUID     \t0f82371a-442c-4a50-aeb5-528e5a896d52\nStartTime\t2023-06-09 12:14:38\nEndTime  \t2023-06-09 12:23:44\nDuration \t9m6s\nStatus   \tSuccess\nCreator  \tadmin\nClusterId\tfd3e2768-a84d-4732-9de6-87558d7bcd39\nStates   \t- update job status to Running\n         \t- create Cluster in DB Success\n         \t- helm install Success\n         \t- checkout Cluster status [529]\n         \t- job run Success\n\nSubJobs  \tmysql                ModuleStatus: Available, SubJobStatus: Success, Duration:   5m4s, StartTime: 2023-06-09 12:14:38, EndTime: 2023-06-09 12:19:43\n         \tnginx                ModuleStatus: Available, SubJobStatus: Success, Duration:   9m6s, StartTime: 2023-06-09 12:14:38, EndTime: 2023-06-09 12:23:44\n         \tpython               ModuleStatus: Available, SubJobStatus: Success, Duration:   7m5s, StartTime: 2023-06-09 12:14:38, EndTime: 2023-06-09 12:21:43\n         \tspark-worker         ModuleStatus: Available, SubJobStatus: Success, Duration:  2m53s, StartTime: 2023-06-09 12:14:38, EndTime: 2023-06-09 12:17:31\n         \tclient               ModuleStatus: Available, SubJobStatus: Success, Duration:  2m45s, StartTime: 2023-06-09 12:14:38, EndTime: 2023-06-09 12:17:23\n         \tdatanode             ModuleStatus: Available, SubJobStatus: Success, Duration:  2m36s, StartTime: 2023-06-09 12:14:38, EndTime: 2023-06-09 12:17:14\n         \tfateboard            ModuleStatus: Available, SubJobStatus: Success, Duration:  2m54s, StartTime: 2023-06-09 12:14:38, EndTime: 2023-06-09 12:17:32\n         \tnamenode             ModuleStatus: Available, SubJobStatus: Success, Duration:   2m5s, StartTime: 2023-06-09 12:14:38, EndTime: 2023-06-09 12:16:43\n         \tpulsar               ModuleStatus: Available, SubJobStatus: Success, Duration:  4m24s, StartTime: 2023-06-09 12:14:38, EndTime: 2023-06-09 12:19:02\n         \tspark-master         ModuleStatus: Available, SubJobStatus: Success, Duration:  2m45s, StartTime: 2023-06-09 12:14:38, EndTime: 2023-06-09 12:17:23\n```\n```shell\nkubefate cluster describe fd3e2768-a84d-4732-9de6-87558d7bcd39\n```\n```\nUUID        \tfd3e2768-a84d-4732-9de6-87558d7bcd39\nName        \tfate-9999\nNameSpace   \tfate-9999\nChartName   \tfate\nChartVersion\tv1.11.1\nRevision    \t1\nAge         \t27m\nStatus      \tRunning\nSpec        \talgorithm: Basic\n            \tchartName: fate\n            \tchartVersion: v1.11.1\n            \tcomputing: Spark\n            \tdevice: CPU\n            \tfederation: Pulsar\n            \timagePullSecrets:\n            \t- name: myregistrykey\n            \tingressClassName: nginx\n            \tistio:\n            \t  enabled: false\n            \tmodules:\n            \t- mysql\n            \t- python\n            \t- fateboard\n            \t- client\n            \t- spark\n            \t- hdfs\n            \t- nginx\n            \t- pulsar\n            \tname: fate-9999\n            \tnamespace: fate-9999\n            \tpartyId: 9999\n            \tpersistence: false\n            \tpodSecurityPolicy:\n            \t  enabled: false\n            \tpullPolicy: null\n            \tregistry: \"\"\n            \tskippedKeys:\n            \t- route_table\n            \tstorage: HDFS\n\nInfo        \tdashboard:\n            \t- spark.example.com\n            \t- notebook.example.com\n            \t- fateboard.example.com\n            \t- pulsar.example.com\n            \tip: 192.168.100.121\n            \tstatus:\n            \t  containers:\n            \t    client: Running\n            \t    datanode: Running\n            \t    fateboard: Running\n            \t    fateflow: Running\n            \t    mysql: Running\n            \t    namenode: Running\n            \t    nginx: Running\n            \t    pulsar: Running\n            \t    spark-master: Running\n            \t    spark-worker: Running\n            \t  deployments:\n            \t    fateboard: Available\n            \t    nginx: Available\n            \t    spark-master: Available\n            \t    spark-worker: Available\n            \t  statefulSets:\n            \t    client: Available\n            \t    datanode: Available\n            \t    mysql: Available\n            \t    namenode: Available\n            \t    pulsar: Available\n            \t    python: Available\n```"},{"title":"vim常用配置及操作","url":"/2023/06/03/vim常用配置及操作/","content":"\n# vim 插件的安装\n##  markdown-composer 插件的安装\n- 在`~/.vimrc`内添加vim-markdown插件\n```shell\nvim ~/.vimrc\n```\n内容如下：\n```\nPlug 'euclio/vim-markdown-composer'\n```\n\n由于这个插件是由rust编写的,vim-plug 进行安装时是克隆代码下来，但不会编译，可以到插件目录下手动编译这个插件\n\n```shell\ncd ~/.vim/plugged/vim-markdown-composer\ncargo build --release --no-default-features --features json-rpc\n```\n# 常用命令助记\n- 增加文本\n  - a/A(append): a 表示在当前光标的后面插入，A表示在当前行尾插入\n  - i/I(insert): i 表示在当前光标的前面插入，I表示在当前行首插入\n  - o/O(open a line): o 表示在当前行的下面插入一行，O表示在当前行的前面插入一行\n- 删除\n  - dd: 表示删除当前行\n  - x/X: 向后/向前删除一个字符\n  - dw(delete word): 删除光标位置后面的一个单词,可以配合数字来表示删除几个单词\n  - diw(delete inner word): 当光标在某个单词内部，现在想删除当前这个单词，就使用diw\n  - daw(delete around word): 和diw的区别是daw会把单词左右的空格也会删除\n- 修改\n  - `c`:(change)\n  - `ciw`:(change inner word):这个的应用场景是把光标移到双引号中的某个字符上，然后`ciw\"`,就可以把双引号中的\n的字符全删除并进入插入模式\n  - `ct)`:(change to `)`):这个的应用场景是把光标移动到左括号后面，然后`ct)`就可以把括号中的字符全删除并进入\n到插入模式\n- 查找\n  - `f`:(find): 这个是在当前行查找字符或移动光标到相应的字符上，比如查找s这个字符，命令为`fs`,光标就会移动>到当前行的`s`字符上,使用`;`定位到下一个。使用数字`0`返回到行的绝对行首或`$`回到行首再进行其它字符的查找。当\n然`F`为反方向的操作。\n  - `/`: 在光标位置往下查找单词可以在`/`后面跟单词就会查找这个单词并高亮显示；使用`?`加单词可以往反方向查找\n单词\n- 光标移动\n  - w(word): 移动到下一个单词\n  - b(back word): 移动到前一个单词\n  - 数字+G：定位行\n  - 0: 移动到绝对行头\n  - ^: 移动到行首\n  - $: 移动到行尾\n  - gg: 移动到第1行\n  - G：移动到最后一行\n  - ctl + o: 返回到上一个位置\n  - ctl + f（forward): 往下翻页\n  - ctl + u (upward): 往前翻页\n\n# 宏定义\n`normal`模式下按`q`键，再按`x`，表示使用寄存器`x`\n然后就开始录制了,等录制结束，按`ESC`，再按`q`就结束录制，然后就是调用这个宏重复做刚才的事。调用方法为:\n```\n@x\n```\n表示调用x寄存器中的宏,当然可以在前面加上一个数字来表示调用次数\n\n","tags":["vim","plugin"],"categories":["Linux"]},{"title":"k3s部署","url":"/2023/05/11/k3s部署/","content":"\n# 一、[官方文档](https://docs.k3s.io/zh/quick-start)\n\n# 二、安装步骤\n- 使用docker作为容器(默认为containerd)\n- 设置docker拉取的http代理\n- 安装K3S\n- 使用ingress-nginx(默认是traefik)\n\n\n## 使用docker作为容器\n- 可以使用`Rancher`的一个[Docker安装脚本](https://github.com/rancher/install-docker)来安装Docker\n- 也可以根据Docker官方文档手动[ubuntu下安装docker](https://docs.docker.com/engine/install/ubuntu/)\n### 卸载旧版\n```shell\nsudo apt-get remove docker docker-engine docker.io containerd runc\n```\n\n### 设置`repository`\n\n```shell\nsudo apt-get update\nsudo apt-get install ca-certificates curl gnupg\n```\n\n```shell\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\n```\n\n```shell\necho \\\n  \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n```\n\n### 安装`Docker Engine`\n\n```shell\nsudo apt-get update\n```\n\n```shell\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n```\n\n## 设置docker拉取的http代理\n\n```shell\nsudo mkdir -p /etc/systemd/system/docker.service.d\ncd /etc/systemd/system/docker.service.d\nsudo vim proxy.conf\n```\n文件内容如下：\n```\n[Service]\nEnvironment=\"HTTP_PROXY=http://127.0.0.1:7890/\"\nEnvironment=\"HTTPS_PROXY=http://127.0.0.1:7890/\"\nEnvironment=\"NO_PROXY=localhost,127.0.0.1\"\n```\n\n## 安装`K3S`\n以Docker为容器\n```shell\ncurl -sfL https://get.k3s.io | sh -s - --docker\n```\n> 如果服务器网络环境复杂，需要指定K3S服务节点的IP，则 `--node-ip=192.168.10.100`\n\n## 使用ingress-nginx作为反向代理\n之前在K3S搭建的环境中，默认是使用`traefik`的，在使用FedLCM部署FATE相关组件，里面使用了ingress-nginx，如果使用FedLCM去部署ingress-nginx，则会有一个坑：这个ingress-nginx在k3s中是部署成功了，但是FedLCM使用K8S的API去查询ingress-nginx是否部署完成返回的值是跟实际情况不符的。如果把`traefik`禁用了，就能避坑，这应该是K3S的一个bug(目前应该是解决了，后来我又部署过几次，没这个问题了)。\n\n> 解决方法是：只需使用 `--disable=traefik` 启动 K3s Server，然后部署你的 Ingress 即可。\n\n具体步骤：\n- 安装kubectl\n  ```shell\n  # 下载kubectl\n  curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n  # 安装kubectl\n  sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n  ```\n  ```shell\n  mkdir -p ~/.kube\n  sudo cat /etc/rancher/k3s/k3s.yaml\n  # 在~/.kube/下创建一个`config`文件把k3s.yaml中的内容放入到`config`中\n  ```\n- 安装helm\n  ```shell\n  curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash\n  ```\n- 安装 ingress-nginx\n  ```shell\n  helm upgrade --install ingress-nginx ingress-nginx  --repo https://kubernetes.github.io/ingress-nginx  --namespace ingress-nginx --create-namespace\n  ```\n- 查看 ingress-nginx controller信息\n  ```shell\n  kubectl get svc -n ingress-nginx ingress-nginx-controller\n  ```\n  ingress controller的服务类型有`NodePort`和`LoadBalancer`,这两种模式下，访问那些通过ingress反向代理的服务时，使用的IP地址是有区别的，`NodePort`模式下，没有`EXTERNAL-IP`\n\n","tags":["k3s"],"categories":["云原生","基础设施"]},{"title":"ingresss-nginx-controller部署和应用","url":"/2023/05/11/ingresss-nginx-controller部署和应用/","content":"\n# `Ingress`是什么\n`Ingress`公开从集群外部到集群内服务的`http`和`https`路由。流量路由由`Ingress`资源上定义的规则控制。下面是一个将所有流量都发送到同一个`Service`的简单`Ingress`示例：\n![简单示例](ingresss-nginx-controller部署和应用/ingress-simple.jpg)\n\n# `Ingress`的组成\n## ingress\n`ingress`是一个API对象，通过`yaml`文件来配置，`ingress`对象的作用是定义请求如何发送到`service`的规则，可以理解为配置模板。`ingress`通过`http`或`https`暴露集群内部`service`，给`service`提供外部`URI`、`负载均衡`、`SSL/TLS`能力以及基于域名的反向代理。`ingress`要依靠`ingress-controller`来具体实现以上功能。\n## Ingress-controller\n`Ingress-controller`是具体实现反向代理及负载均衡的程序，对`ingress`定义的规则进行解析，根据配置的规则来实现请求转发。`ingress-controller`并不是`k8s`自带组件，实际上`ingress-controller`只是一个统称，用户可以选择不同的`ingress-controller`实现，目前，由`k8s`维护的`ingress-controller`只有google云的GCE与ingress-nginx两个，其它还有很多第三方维护的ingress-controller,具体可以参考官方文档。但是不管哪一种`ingress-controller`，实现的机制都大同小异，只是在具体配置上有差异。\n\n一般来说，`ingress-controller`的形式都是一个pod，里面跑着daemon程序和反向代理程序。daemon负责不断监控集群的变化，根据`ingress`对象生成配置到反向代理，比如`ingress-nginx`配置，动态更新`upstream`，并在需要的时候`reload`程序应用新配置。为了方便，后面的例子都以`k8s`官方维护的`ingress-nginx`为例。\n\n## Ingress的工作原理\n- ingress-controller通过和kubernetes APIServer交互，动态去感知集群中ingress规则变化；\n- 然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service,生成一段nginx配置；\n- 再写到inginx-ingress-controller的pod里，这个ingress-controller的pod里运行着一个Nginx服务，控制器会把生成的nginx配置写入到/etc/nginx.conf中；\n- 然后reload一下使配置生效。以此达到域名区分配置和动态更新的作用。\n\nIngress流图\n![01](ingresss-nginx-controller部署和应用/ingress01.jpg)\n![02](ingresss-nginx-controller部署和应用/ingress02.jpg)\n例子如下图：\n![ingress-controller](ingresss-nginx-controller部署和应用/ingress-nginx-controller.jpg)\n\n# 部署\n## 下载部署文件和镜像\n### 下载ingress-nginx的部署文件\n```shell\n#需要下载别的版本请求改版本号\nwget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.0/deploy/static/provider/cloud/deploy.yaml\n#备注：该文件在github上也可以下载，地址是：https://github.com/kubernetes/ingress-nginx/blob/main/deploy/static/provider/cloud/deploy.yaml\n```\n### 关于镜像\n由于镜像网络问题，会导致yaml文件中的镜像无法下载，解决思路：先在docker hub上查找，下载下来之后，将其推送到私有的harbor镜像服务器上需要下载如下两个镜像：\n```shell\ncat deploy.yaml |grep image\n```\n```\nimage: registry.k8s.io/ingress-nginx/controller:v1.3.0@sha256:d1707ca76d3b044ab8a28277a2466a02100ee9f58a86af1535a3edf9323ea1b5\nimagePullPolicy: IfNotPresent\nimage: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.1.1@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660\nimagePullPolicy: IfNotPresent\nimage: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.1.1@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660\nimagePullPolicy: IfNotPresent\n```\n\n### 修改部署文件\n- hostNetwork：是为了打通Cluster和node的网络，让Cluster直接临听node的端口，一般是80和443，不用再通过随机绑定NodePort来访问集群服务。\n  > 以前访问：http://www.blockchainof.com:10080/server1/path 现在访问：http://www.blockchainof.com/server1/path 可以看到不需要端口了，因为hostNetwork直接监听node的80端口了\n- nodeSelector：在nodeSelector下添加hasIngress: \"true\"\n  > 可以给集群中的node添加标签，然后部署的时候nodeSelector就会根据标签找到具有这个标签的node，只在这部分node上进行部署。\n- DaemonSet: 把kind的值从Deployment改为DaemonSet，因为Deployment可能会把多个Pod调度到同一个node（同一个node上会存在pod的多个副本，而DaemonSet最多只有一个），这样比较符合多节点高可用的意义。\n\n修改后的deploy.yaml如下：\n```yaml\n......\napiVersion: apps/v1\n#kind: Deployment\nkind: DaemonSet  #这里把Deployment改成DaemonSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.3.0\n  name: ingress-nginx-controller\n  namespace: ingress-nginx\nspec:\n  minReadySeconds: 0\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/instance: ingress-nginx\n      app.kubernetes.io/name: ingress-nginx\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/instance: ingress-nginx\n        app.kubernetes.io/name: ingress-nginx\n    spec:\n      hostNetwork: true  #这里加一句\n      containers:\n      - args:\n        - /nginx-ingress-controller\n        - --publish-service=$(POD_NAMESPACE)/ingress-nginx-controller\n        - --election-id=ingress-controller-leader\n        - --controller-class=k8s.io/ingress-nginx\n        - --ingress-class=nginx\n        - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller\n        - --validating-webhook=:8443\n        - --validating-webhook-certificate=/usr/local/certificates/cert\n        - --validating-webhook-key=/usr/local/certificates/key\n        env:\n...\n      nodeSelector:\n        kubernetes.io/os: linux\n        hasIngress: \"true\"  # 这里根据标签选择node\n...\n```\n\n### 给节点增加标签\n在上一章节中`deploy.yaml`中`nodeSelector`下增加了`hasIngress: \"true\"`, 所以对应的，在需要部署`ingress controller`的节点打上`hasIngress`这个标签。\n```shell\nkubectl label nodes ${k8s-node1} hasIngress=true\nkubectl label nodes ${k8s-node2} hasIngress=true\n```\n\n### 部署\n```shell\nkubectl apply -f deploy.yaml \n```\n没什么意外的话，等待一段时间完成部署。\n\n# 应用\n## 部署服务（以tomcat和nginx为例）\n### 创建tomcat-nginx.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  namespace: dev\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-pod\n  template:\n    metadata:\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.1\n        ports:\n        - containerPort: 80\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tomcat-deployment\n  namespace: dev\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: tomcat-pod\n  template:\n    metadata:\n      labels:\n        app: tomcat-pod\n    spec:\n      containers:\n      - name: tomcat\n        image: tomcat:8.5-jre10-slim\n        ports:\n        - containerPort: 8080\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-service\n  namespace: dev\nspec:\n  ports:\n    - port: 80\n      name: nginx\n  clusterIP: None\n  selector:\n    app: nginx-pod\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: tomcat-service\n  namespace: dev\nspec:\n  ports:\n    - port: 8080\n      name: tomcat\n  clusterIP: None\n  selector:\n    app: tomcat-pod\n```\n创建\n```shell\nkubectl apply -f tomcat-nginx.yaml \n```\n```\ndeployment.apps/nginx-deployment created\ndeployment.apps/tomcat-deployment created\n```\n查看\n```shell\nkubectl get svc -n dev\n```\n```\nNAME             TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE\nnginx-service    ClusterIP   None         <none>        80/TCP     59m\ntomcat-service   ClusterIP   None         <none>        8080/TCP   59m\n```\n> 服务就已经部署好了\n\n## http代理\n### 创建ingress-http.yaml\n```yaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: ingress-http\n  namespace: dev\nspec:\n  rules:\n  - host: nginx.blockchainof.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: nginx-service\n          servicePort: 80\n  - host: tomcat.blockchainof.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: tomcat-service\n          servicePort: 8080\n```\n### 创建\n```shell\nkubectl create -f ingress-http.yaml\n```\n```\ningress.extensions/ingress-http created\n```\n### 查看\n```shell\nkubectl get ing ingress-http -n dev\n```\n```\nNAME           HOSTS                                  ADDRESS   PORTS   AGE\ningress-http   nginx.blockchainof.com,tomcat.blockchainof.com             80      18s\n```\n### 查看详情\n```shell\nkubectl describe ing ingress-http -n dev\n```\n```\nName:             ingress-http\nNamespace:        dev\n\n  nginx.blockchainof.com   \n                      /   nginx-service:80 (10.244.1.132:80,10.244.1.135:80,10.244.1.139:80)\n  tomcat.blockchainof.com  \n                      /   tomcat-service:8080 (10.244.1.129:8080,10.244.1.134:8080,10.244.1.140:8080)\nAnnotations:\nEvents:\n  Type    Reason  Age   From                      Message\n  ----    ------  ----  ----                      -------\n  Normal  CREATE  48s   nginx-ingress-controller  Ingress dev/ingress-http\n```\n### 查看ingress-controller的nginx配置是否发生修改\n```shell\nkubectl exec -it nginx-ingress-controller-7f74f657bd-t8pvt sh -n ingress-nginx\n/etc/nginx\n```\n```shell\ncat nginx.conf|grep nginx.blockchainof.com\n```\n```\n\t## start server nginx.blockchainof.com\n\t\tserver_name nginx.blockchainof.com ;\n\t## end server nginx.blockchainof.com\n```\n\n### 查看ingress-controller的svc端口\n```shell\nkubectl get svc -n ingress-nginx\n```","tags":["k3s","k8s","ingress","ingress-niginx-controller"],"categories":["云原生","基础设施"]},{"title":"Cpp11-function和bind用法详解","url":"/2023/03/27/Cpp11-function和bind用法详解/","content":"\n在设计回调函数的时候，无可避免地会接触到可回调对象。在C++11中，提供了std::function和std::bind两个方法来对可回调对象进行统一和封装。\n\n# 可调用对象\nC++ 中有如下几种可调用对象：函数、函数指针、lambda表达式、bind对象、函数对象。其中，lambda表达式和bind对象是C++11标准中提出的（bind机制并不是新标准中首次提出，而是对旧版本中bind1st和bind2nd的合并）。个人认为五种可调用对象中，函数和函数指针本质相同，而lambda表达式、bind对象及函数对象则异曲同工。\n\n# 函数\n这里的函数指的是普通函数，没什么可拓展的。\n\n# 函数指针\n函数指针和函数类型的区别：\n- 函数指针指向的是函数而非对象。和其它指针类型一样，函数指针指向某种特定类型；\n- 函数类型由它的返回值和参数类型决定，与函数名无关\n\n例：\n```cpp\nbool fun(int a, int b)\n```\n上述函数的函数类型是：`bool(int, int)`\n\n上述函数的函数指针`pf`是：`bool (*pf)(int, int)`\n\n一般对于函数来说，函数名即为函数指针：\n```cpp\n#include <iostream>\n\nint fun(int x, int y) {\n    std::cout << x + y << std::endl;\n    return x + y;\n}\n\nint fun1(int (*fp)(int, int), int x, int y) {\n    return fp(x, y);\n}\n\ntypedef int (*Ftype)(int, int);\nint fun2(Ftype fp, int x, int y) {\n    return fp(x, y);\n}\n\n//int main() {\n//    fun1(fun, 100, 100);\n//    fun2(fun, 200, 200);\n//}\n\n```\n上述例子就是将函数指针作为参数，再使用函数指针对函数进行调用。传参（函数指针）时，只需要把函数名称传入即可\n\n# lambda表达式\nlambda表达式就是一段可调用的代码。主要适合于只用到一两次的简短代码段。由于lambda是匿名的，所以保证了其不会被不安全地访问：\n```cpp\n#include <iostream>\n\nint fun3(int x, int y) {\n    auto f = [](int x, int y) { return x + y; };\n    std::cout << f(x, y) << std::endl;\n}\n\nint main() {\n   fun3(300, 300);\n}\n```\n\n# bind对象\nstd::bind可以用来生产一个可调用对象，来适应原对象的参数列表。\n\n# 函数对象\n重载了函数调用运算符`()`的类的对象，即为函数对象。\n\n# std::function\n由上文可以看出：由于可调用对象的定义方式比较多，但是函数的调用方式较为类似，因此需要使用一个统一的方式保存可调用对象或者传递可调用对象。于是，`std::function`就诞生了。\n\n`std::function`是一个可调用对象包装器，是一个类模板，可以容纳除了类成员函数指针之外的所有可调用对象，它可以用统一的方式处理函数、函数对象、函数指针，并允许保存和延迟它们的执行。\n\n定义function的一般形式：\n```cpp\n#include <functional>\n\nstd::function<函数类型>\n```\n\n例如：\n```cpp\n#include <functional>\n#include <iostream>\n\ntypedef std::function<int(int, int)> comfun;\n\n// 普通函数\nint add(int a, int b) { return a + b; }\n\n// lambda表达式\nauto mod = [](int a, int b) {\n    return a % b;\n};\n\n// 函数对象\nstruct divide {\n    int operator()(int denominator, int divisor) {\n        return denominator / divisor;\n    }\n};\n\nint main() {\n   comfun a = add;\n   comfun b = mod;\n   comfun c = divide();\n   std::cout << a(5, 3) << std::endl;\n   std::cout << b(5, 3) << std::endl;\n   std::cout << c(5, 3) << std::endl;\n}\n\n```\nstd::function可以取代函数指针的作用，因为它可以延迟函数的执行，特别适合作为`回调函数`使用。它比普通函数指针更加的灵活和便利。\n\n故而，std::function的作用可以归纳为：\n1. std::function对C++中各种可调用实体（普通函数、Lambda表达式、函数指针、以及其它函数对象等）的封装，形成一个新的可调用的std::function对象，简化调用；\n2. std::function对象是对C++中现有的可调用实体的一种类型安全的包裹（如：函数指针这类可调用实体，是类型不安全的）。\n\n# std::bind\nstd::bind可以看作一个通用的函数适配器，**它接受一个可调用对象，生成一个新的可调用对象来适应原对象的参数列表**。\n\nstd::bind将可调用对象与其参数一起进行绑定，绑定后的结果可以使用std::function保存。std::bind主要有以下两个作用：\n- 将可调用对象和其参数绑定成一个仿函数；\n- 只绑定部分参数，减少可调用对象传入的参数；\n\n调用bind的一般形式：\n```cpp\nauto newCallable = bind(callable, arg_list);\n```\n该形式表达的意思是：当调用`newCallable`时，会调用`callable`，并传给它`arg_list`中的参数。\n\n需要注意的是：`arg_list`中的参数可能包含形如`_n`的名字。其中`n`是一个整数，这些参数是占位符，表示`newCallable`的参数，它们占据了传递给`newCallable`的参数的位置。数值n表示生成的可调用对象中参数的位置：`_1`为`newCallable`的第一个参数，`_2`为第`2`个参数，以此类推。\n\n看下面代码：\n```cpp\n\n#include <iostream>\n\nclass A {\npublic:\n    void fun_3(int k, int m) {\n        std::cout << \"print: k = \" << k << \", m = \" << m << std::endl;\n    }\n};\n\nvoid fun_1(int x, int y, int z) {\n    std::cout << \"print: x = \" << x << \", y = \" << y << \", z = \" << z << std::endl;\n}\n\nvoid fun_2(int &a, int &b) {\n    ++a;\n    ++b;\n    std::cout << \"print: a = \" << a << \", b = \" << b << std::endl;\n}\n\nint main(int argc, char *argv[]) {\n    //f1的类型为function<void(int, int, int)>\n    auto f1 = std::bind(fun_1, 1, 2, 3); // 表示绑定函数fun_1 的第一，二，三个参数值为： 1, 2, 3\n    f1();\n\n    // 表示绑定函数 fun_1的第三个参数为3，而fun_1函数第一，二个参数分别由调用f3的时指定，注意，这里传参的顺序是可以根据placeholders::_n 指定的\n    auto f2 = std::bind(fun_1, std::placeholders::_1, std::placeholders::_2, 3);\n    f2(1, 2);\n\n    // 注意下面的std::placeholders::_n 的顺序\n    auto f3 = std::bind(fun_1, std::placeholders::_2, std::placeholders::_1, 3);\n    f3(1, 2);\n\n    int m = 2;\n    int n = 3;\n    auto f4 = std::bind(fun_2, std::placeholders::_1, n); // 表示绑定了fun_2的第二个参数为n，第二个参数由f4调用时的第一个参数指定\n    f4(m);\n    std::cout << \"m = \" << m << std::endl; // m=3 说明bind对于不预先绑定的参数，是引用传递的\n    std::cout << \"n = \" << n << std::endl; // n=3 说明bind对于预先绑定的参数，会产生一个值拷贝，而不是使用的n的引用\n\n    A a;\n    //f5的类型为function<void(int, int)>\n    auto f5 = std::bind(&A::fun_3, &a, std::placeholders::_1, std::placeholders::_2);\n    f5(10, 20); // 调用a.fun_3(10, 20)\n\n    auto f6 = std::bind(&A::fun_3, a, std::placeholders::_1, std::placeholders::_2);\n    f6(10, 20); // 调用a.fun_3(10, 20)\n\n    std::function<void(int, int)> fc = std::bind(&A::fun_3, a, std::placeholders::_1, std::placeholders::_2);\n    fc(10, 20);\n\n    return 0;\n}\n```\n由此例子可以看出：\n- 预绑定的参数是以值传递的形式，不预绑定的参数要用std::placeholders(占位符)的形式占位，从_1开始，依次递增，是以引用传递的形式；（这里的值传递或引用传递是针对bind生成对象来说的，并不是指可调用对象的调用）\n- std::placeholders表示新的可调用对象的参数的占位，其中的_n与原函数的该占位符所在位置进行匹配；也就是说bind产生的新的可调用对象的参数，可以和原函数的参数顺序不一致。\n- std::bind绑定类成员函数时，第一个参数表示对象的成员函数的指针，第二个参数表示对象的地址（这里好像可以直接传对象的变量进去，应该是会做隐式的转换，即取地址，具体没研究过），这是因为对象的成员函数需要有this指针。并且编译器不会将对象的成员函数指针，需要通过显式& 取地址进行转换。\n- std::bind的返回值是可调用实体，可以直接赋给std::function。\n\n\n","tags":["function","bind"],"categories":["C++","基础"]},{"title":"Cpp11-lambda表达式","url":"/2023/03/24/Cpp11-lambda表达式/","content":"\n# 引言\nlambda表达式是C++11最重要也是最常用的特性之一。lambda来源于函数式编程的概念，也是现代编程语言的一个特点。lambda表达式有如下优点：\n- 声明式编程风格：就地匿名定义目标函数或函数对象，不需要额外写一个命名函数或者函数对象。以更直接的方式去写程序，好的可读性和可维护性。\n- 简洁：不需要额外再写一个函数或者函数对象，避免了代码膨胀和功能分散，让开发者更加集中精力在手边的问题，同时也获取了更高的生产率。\n- 在需要的时间和地点实现功能闭包，使程序更灵活。\n\n# lambda表达式的概念和基本用法\nlambda表达式定义了一个匿名函数，并且可以捕获一定范围内的变量。lambda表达式的语法形式可简单归纳如下：\n```\n[capture](params)opt->ret{body;};\n```\n> 其中capture是捕获列表，params是参数列表，opt是函数选项，ret是返回值类型，body是函数体。\n\n因此，一个完整的lambda表达式看起来像这样：\n```cpp\n...\nauto f = [](int a) -> int { return a + 1; };\n\nstd::cout << f(1) << std::endl; // 输出： 2\n...\n```\n\n可以看到，上面通过一行代码定义了一个小小的功能闭包，用来将输入加1并返回。\n\n在很多时候，lambda表达式的返回值是非常明显的，比如下面这个例子。因此，C++11中允许省略lambda表达式的返回值定义：\n```cpp\n...\nauto f = [](int a){ return a + 1; };\n...\n```\n这样编译器就会根据return语句自动推导出返回值类型。\n\n需要注意的是，初始化列表不能用于返回值的自动推导：\n```cpp\n...\nauto x1 = [](int i) { return i; }; //OK: return type is int\nauto x2 = []() { return {1, 2}; }; // error:无法推导出返回值类型\n...\n```\n这时我们需要显式给出具体的返回值类型。\n\n另外，lambda表达式在没有参数列表时，参数列表是可以省略的。因此像下面的写法都是正确的：\n```cpp\n...\nauto f1 = []() { return 1; };\nauto f2 = [] { return 1; }; // 省略空参数列表\n...\n```\n\n# 使用lambda表达式捕获列表\nlambda表达式还可以通过捕获列表捕获一定范围的变量：\n- []不捕获任何变量\n- [&]捕获外部作用域中所有变量，并作为引用在函数体中使用（按引用捕获）。\n- [=]捕获外部作用域中所有变量，并作为副本在函数体中使用（按值捕获）。\n- [=, &foo]按值捕获外部作用域中所有变量，并按引用捕获foo变量。\n- [bar]按值捕获bar变量，同时不捕获其它变量。\n- [this]按值捕获当前类中的this指针，让lambda表达式拥有和当前类成员函数同样的访问权限。如果已经使用了&或者=，就默认添加此选项。捕获this的目的是可以在lambda中使用当前的成员函数和成员变量。\n\n下面看一下它的具体用法：\n```cpp\nclass A\n{\n    public:\n    int i_ = 0;\n    void func(int x, int y)\n    {\n        auto x1 = []{ return i_; };                    // error，没有捕获外部变量\n        auto x2 = [=]{ return i_ + x + y; };           // OK，捕获所有外部变量\n        auto x3 = [&]{ return i_ + x + y; };           // OK，捕获所有外部变量\n        auto x4 = [this]{ return i_; };                // OK，捕获this指针\n        auto x5 = [this]{ return i_ + x + y; };        // error，没有捕获x、y\n        auto x6 = [this, x, y]{ return i_ + x + y; };  // OK，捕获this指针、x、y\n        auto x7 = [this]{ return i_++; };              // OK，捕获this指针，并修改成员的值\n    }\n};\n```\n\n从上例中可以看到，lambda 表达式的捕获列表精细地控制了 lambda 表达式能够访问的外部变量，以及如何访问这些变量。\n\n需要注意的是，默认状态下 lambda 表达式无法修改通过复制方式捕获的外部变量。如果希望修改这些变量的话，我们需要使用引用方式进行捕获。\n\n一个容易出错的细节是关于 lambda 表达式的延迟调用的：\n```cpp\n...\nint a = 0;\nauto f = [=]{ return a; };      // 按值捕获外部变量\na += 1;                         // a被修改了\nstd::cout << f() << std::endl;  // 输出？\n...\n```\n在这个例子中，lambda 表达式按值捕获了所有外部变量。在捕获的一瞬间，a 的值就已经被复制到f中了。之后 a 被修改，但此时 f 中存储的 a 仍然还是捕获时的值，因此，最终输出结果是 0。\n\n**如果希望 lambda 表达式在调用时能够即时访问外部变量，我们应当使用引用方式捕获。**\n\n从上面的例子中我们知道，按值捕获得到的外部变量值是在 lambda 表达式定义时的值。此时所有外部变量均被复制了一份存储在 lambda 表达式变量中。此时虽然修改 lambda 表达式中的这些外部变量并不会真正影响到外部，我们却仍然无法修改它们。\n\n那么如果希望去**修改按值捕获的外部变量**应当怎么办呢？这时，需要显式指明 lambda 表达式为 mutable：\n\n```cpp\n...\nint a = 0;\nauto f1 = [=]{ return a++; };               // error, 修改按值捕获的外部变量\nauto f2 = [=]() mutable { return a++; };    // OK, mutable\n...\n```\n需要注意的一点是，被mutable修饰的lambda表达式就算没有参数也要写明参数列表\n\n# lambda表达式的类型\n最后，介绍一下lambda表达式的类型。\nlambda表达式的类型在C++11中被称为“闭包类型（Closure Type）“。因此，我们可以认为它是一个带有operator()的类——对括号运算符进行了重载的类，即仿函数。因此，我们可以使用std::function和std::bind来存储和操作lambda表达式：\n```cpp\n...\nstd::function<int(int)> f1 = [](int a) { return a; };\nstd::function<int(void)> f2 = std::bind([](int a){ return a; }, 123);\nf1(555); // 555\nf2(); // 123\n...\n```\n另外，**对于没有捕获任何变量的lambda表达式**，还可以被转换成一个普通的函数指针：\n```cpp\n...\nusing funct_t = int(*)(int);\nfunc_t f = [](int a) { return a; };\nf(123);\n...\n```\nlambda表达式可以说是就地定义仿函数闭包的”语法糖“。它的捕获列表捕获住的任何外部变量，最终均会变为**闭包类型的成员变量**。而一个使用了成员变量的类的operator(),如果能直接被转换为普通的函数指针，**那么lambda表达式本身的this指针就丢失掉了**。而没有捕获任何外部变量的lambda表达式则不存在这个问题。\n\n这里也可以很自然地解释为何按值捕获无法修改捕获的外部变量（这里指的是原始外部变里的值的副本，在闭包内部的一个成员变量）。因为按C++标准，lambda表达式的operator()默认是const的。一个const成员函数是无法修改成员变量的值的。而mutable的作用，就在于取消operator()的const。\n\n需要注意的是，没有捕获变量的lambda表达式可以直接转换为函数指针，而捕获变量的lambda表达式则不能转换为函数指针。看看下面的代码：\n```cpp\n...\n\ntypedef void(*Ptr)(int*);\n\nPtr p = [](int* p) { delete p; }; //正确，无状态的lambda（没有捕获）表达式可以直接转换为函数指针\nPtr p1 = [&](int* p) { delete p; }; // 错误，有状态的lambda不能直接转换为函数指针\n...\n```\n上面第二行代码能编译通过，而第三行代码不能编译通过，因为第三行代码捕获了变量，不能直接转为函数指针。\n\n# 声明式的编程风格，简洁的代码\n就地定义匿名函数，不再需要定义函数对象，大大简化了标准库算法的调用。比如，在C++11之前，我们要调用for_each函数将vecotr中的偶数打印出来，如下所示。\n\n【实例】lambda表达式代替函数对像的示例。\n```cpp\nclass CountEven\n{\n    int& count_;\npublic:\n    CountEven(int& count) : count_(count) {}\n    void operator()(int val)\n    {\n        if (!(val & 1))       // val % 2 == 0\n        {\n            ++ count_;\n        }\n    }\n};\n```\n```cpp\n...\nstd::vector<int> v = { 1, 2, 3, 4, 5, 6 };\nint even_count = 0;\nfor_each(v.begin(), v.end(), CountEven(even_count));\nstd::cout << \"The number of even is \" << even_count << std::endl;\n...\n```\n\n这样写既烦琐又容易出错。有了lambda表达式以后，我们可以使用真正的闭包概念来替换掉这里的仿函数，代码如下：\n```cpp\nstd::vector<int> v = { 1, 2, 3, 4, 5, 6 };\nint even_count = 0;\nfor_each( v.begin(), v.end(), [&even_count](int val)\n        {\n            if (!(val & 1))  // val % 2 == 0\n            {\n                ++ even_count;\n            }\n        });\nstd::cout << \"The number of even is \" << even_count << std::endl;\n```\nlambda表达式的价值在于，就地封装短小的功能闭包，可以极其方便地表达出我们希望执行的具体操作，并让上下文结合得更加紧密。\n\n\n","tags":["c++","cpp","lambda"],"categories":["C++","基础"]},{"title":"Primihub核心模型","url":"/2023/03/13/Primihub核心模型/","content":"\n# 核心模型\n初步了解PrimiHub是如何工作的：\n- 节点（Node）：一个加载安全协议和接收计算请求的可执行程序，节点为上层协议执行提供基础服务，目前提供的基础服务有数据集元数据服务、数据缓存服务；\n- 协议（Protocol）：指多方安全计算MPC协议\n- 虚拟节点（VMNode）：虚拟节点是节点上所有任务的执行器\n- 虚拟节点的角色（VMNode role）：指在一次行务执行中扮演的角色，分为两种：a.控制节点（Scheduler） b.工作节点（Worker）\n- 数据集（Dataset）：指任务需要计算的数据\n- 算法（Algorithm）：指任务执行的具体逻辑，将根据协议分配到指定节点上执行\n- 任务（Task）：特定协议正在执行的MPC计算任务，一个计算任务需要指定算法、数据集、协议（协议可自动由节点根据算法自动协商或人工指定）\n- 运行时（Worker）：任务（Task）的加载和运行器，一个运行时在启动时由VMNode分配使用的协议（Protocol）；\n- 运行时参与角色（Worker party）：运行时角色根据传入的安全协议指定与安全协议相关的角色\n\n## 核心模型如何工作\n![核心模型如何工作](Primihub核心模型/核心模型如何工作.jpg)","categories":["联邦学习"]},{"title":"Primihub环境搭建","url":"/2023/03/08/Primihub环境搭建/","content":"# 快速开始\n\n## 准备工作\n安装`docker`和`docker-compose`，或者下载`PrimiHub`整理好的[安装包](https://primihub.oss-cn-beijing.aliyuncs.com/dev/docker20.10.tar.gz), 下载后解压执行\n```shell\nbash install_docker.sh\n```\n完成`docker`和`docker-compose`的安装。\n\n然后下载仓库并进入到代码目录：\n```shell\ngit clone https://github.com/primihub/primihub.git\ncd primihub\n```\n\n## 启动节点\n### 启动测试用的节点\n使用`docker-compose`启动容器。容器包括：启动点、redis(数据集查找默认使用redis)、三个节点\n```shell\ndocker-compose up -d\n```\n查看运行起来的docker容器：\n```shell\ndocker-compose ps -a\n```\n如果一切顺利会看到类似如下的信息：\n```shell\nNAME                    COMMAND                  SERVICE                 STATUS              PORTS\nprimihub-node0          \"/bin/bash -c './pri…\"   node0                   running             0.0.0.0:6666->6666/tcp, 0.0.0.0:8050->50050/tcp\nprimihub-node1          \"/bin/bash -c './pri…\"   node1                   running             0.0.0.0:6667->6667/tcp, 0.0.0.0:8051->50051/tcp\nprimihub-node2          \"/bin/bash -c './pri…\"   node2                   running             0.0.0.0:6668->6668/tcp, 0.0.0.0:8052->50052/tcp\nredis                   \"docker-entrypoint.s…\"   redis                   running             0.0.0.0:6379->6379/tcp\nsimple_bootstrap_node   \"/app/simple-bootstr…\"   simple_bootstrap_node   running             0.0.0.0:4001->4001/tcp\n```\n\n但是，我这里遇到坑了，node0, node1, node2 这3个容器的状态为restarting。并且是不断restarting。使用命令：\n```shell\ndocker logs 容器ID\n```\n查看日志是加载mysql客户端的一个动态库文件失败。这个容器没打包好？issue总共也没有几条，更不用说搜索有没有遇到类似的问题了，可见这个项目用的人少得可怜，文档也不健全。\n\n解决方法: 检出另外的分支，再使用 docker-compose up -d\n> 测试了 feature/node_as_share_lib 是可以的，develope和master都不行\n\n## 创建一个MPC任务\n让三个节点共同执行一个多方安全计算（MPC)的逻辑回归任务\n\n```shell\nsudo docker run \"--network=host\" -it primihub/primihub-node:1.1.0 ./primihub-cli \"--server=127.0.0.1:8050\"\n```\n\n> 注：注意primihub-node的版本，要和前一章节中docker-compose启动的primihub-node版本一致\n\n# 使用docker-compose部署\n\n## 下载安装包，执行脚本，完成部署\n```shell\ncurl -s https://get.primihub.com/release/latest/docker-deploy.tar.gz | tar zxf -\ncd docker-deploy\nbash deploy.sh\n```\n\n## 查看部署结果\n```shell\n# docker-compose ps -a\nNAME                COMMAND                  SERVICE                 STATUS              PORTS\napplication1        \"/bin/sh -c 'java -j…\"   application1            running             \napplication2        \"/bin/sh -c 'java -j…\"   application2            running             \napplication3        \"/bin/sh -c 'java -j…\"   application3            running             \nbootstrap-node      \"/app/simple-bootstr…\"   simple-bootstrap-node   running             4001/tcp\nfusion              \"/bin/sh -c 'java -j…\"   fusion                  running             \ngateway1            \"/bin/sh -c 'java -j…\"   gateway1                running             \ngateway2            \"/bin/sh -c 'java -j…\"   gateway2                running             \ngateway3            \"/bin/sh -c 'java -j…\"   gateway3                running             \nloki                \"/usr/bin/loki -conf…\"   loki                    running             0.0.0.0:3100->3100/tcp, :::3100->3100/tcp\nmanage-web1         \"/docker-entrypoint.…\"   nginx1                  running             0.0.0.0:30811->80/tcp, :::30811->80/tcp\nmanage-web2         \"/docker-entrypoint.…\"   nginx2                  running             0.0.0.0:30812->80/tcp, :::30812->80/tcp\nmanage-web3         \"/docker-entrypoint.…\"   nginx3                  running             0.0.0.0:30813->80/tcp, :::30813->80/tcp\nmysql               \"docker-entrypoint.s…\"   mysql                   running             0.0.0.0:3306->3306/tcp, :::3306->3306/tcp\nnacos-server        \"bin/docker-startup.…\"   nacos                   running             0.0.0.0:8848->8848/tcp, 0.0.0.0:9555->9555/tcp, 0.0.0.0:9848->9848/tcp, :::8848->8848/tcp, :::9555->9555/tcp, :::9848->9848/tcp\nprimihub-node0      \"/bin/bash -c './pri…\"   node0                   running             0.0.0.0:6666->6666/tcp, 0.0.0.0:50050->50050/tcp, :::6666->6666/tcp, :::50050->50050/tcp\nprimihub-node1      \"/bin/bash -c './pri…\"   node1                   running             0.0.0.0:6667->6667/tcp, 0.0.0.0:50051->50051/tcp, :::6667->6667/tcp, :::50051->50051/tcp\nprimihub-node2      \"/bin/bash -c './pri…\"   node2                   running             0.0.0.0:6668->6668/tcp, 0.0.0.0:50052->50052/tcp, :::6668->6668/tcp, :::50052->50052/tcp\nrabbitmq1           \"docker-entrypoint.s…\"   rabbitmq1               running             25672/tcp\nrabbitmq2           \"docker-entrypoint.s…\"   rabbitmq2               running             25672/tcp\nrabbitmq3           \"docker-entrypoint.s…\"   rabbitmq3               running             25672/tcp\nredis               \"docker-entrypoint.s…\"   redis                   running             6379/tcp\n```\n\n## 使用说明\ndocker-compose.yaml 文件中的nginx1、nginx2、nginx3 模拟 3 个机构的管理后台，启动完成后在浏览器分别访问\n\nhttp://机器IP:30811\n\nhttp://机器IP:30812\n\nhttp://机器IP:30813\n\n默认用户密码都是 admin / 123456\n\n具体的联邦建模、隐私求交、匿踪查询等功能的操作步骤请参考 [快速试用管理平台](https://docs.primihub.com/docs/quick-start-platform)\n\n\n# primihub代码编译\n\n## Mac Silicon M1\n- 安装Xcode\n- 安装Bazel 5.0.0，最好是直接brew install bazelisk\n- 安装CMake，这个最坑，缺了这个，在这里卡了好久\n- 编写一个shell脚本，用来执行编译命令:\n    ```shell\n    #!/bin/bash\n\n    ./pre_build.sh\n    bazel build --config=darwin_arm64 --config=macos  :node :cli :opt_paillier_c2py :linkcontext\n    ```\n\n# 节点运行\n在编译成功后，在源码目录下生成了可执行文件，路径为：\n```\n./bazel_bin/node\n```\n可使用下面命令运行node\n\n```shell\n./bazel-bin/node --node_id=node0 --service_port=50050 --config=./config/node0.yaml\n```\n\n```shell\n./bazel-bin/node --node_id=node1 --service_port=50051 --config=./config/node1.yaml\n```\n\n```shell\n./bazel-bin/node --node_id=node2 --service_port=50052 --config=./config/node2.yaml\n```\n","tags":["联邦学习","多方安全计算","primihub"],"categories":["联邦学习"]},{"title":"重读《JAVA与模式》笔记系列-00008","url":"/2023/02/18/重读《JAVA与模式》笔记系列-00008/","content":"# 迪米特法则（LoD）\n迪米特法则(Law of Demeter或简写为LoD)又叫做最少知识原则（Least Knowledge Principle或简写为LKP)，就是说，一个对象应当对其他对象有尽可能少的了解。\n\n迪米特法则最初是用来作为面向对象的系统设计风格的一种法则，于1987年秋天由Ian Holland在美国东北大学（Northeastern University）为一个叫做迪米特（Demeter）的项目设计提出的，因此叫做迪米特法则。这条法则实际上是很多著名系统，比如火星登录软件系统、木星的欧罗巴卫星轨道飞船的软件系统的指导设计原则。\n\n## 迪米特法则的各种表述\n没有任何一个其它的OO设计原则像迪米特法则这样有如此之多的表述方式，下面给出的也只是众多的表述中较有代表性的几种：\n- 只与你直接的朋友们通信（Only talk to your immediate friends)。\n- 不要跟“陌生人”说话（Don't talk to strangers)。\n- 每一个软件单位对其它的单位都只有最少的知识，而且局限于那些与本单位密切相关的软件单位\n\n在上面的表述里面，什么是“直接”、“陌生”和“密切”则被有意地模糊化了，以便在不同的环境下可以有不同的解释。\n\n## 狭义的迪米特法则\n如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。如果其中的一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。\n\n### 朋友圈与陌生人\n如下图所示，“某人”与一个“朋友”组成自己的朋友圈，两个人都需要与一个圈外的“陌生人”发生相互作用。\n![某人的朋友圈](重读《JAVA与模式》笔记系列-00008/1.jpg)\n“朋友”与“陌生人”若是朋友，组成“朋友”的朋友圈如下图所示。\n![朋友的朋友圈](重读《JAVA与模式》笔记系列-00008/2.jpg)\n相比较之下，“某人”其实并不需要与“陌生人”直接发生相互作用，但是“朋友”则更需要与“陌生人”发生相互作用。这时候，迪米特法则建议“某人”不要直接与“陌生人”发生相互作用，而是通过“朋友”与之发生直接的相互作用，如下图所示。\n![某人和陌生人间接通讯](重读《JAVA与模式》笔记系列-00008/3.jpg)\n这时候，“朋友”实际上起到了将“某人”对“陌生人”的调用转发给“陌生人”的作用。这种传递叫做调用转发（Call Forwarding）。所谓调用转发，需要隐藏“陌生人”的存在，使得“某人”仅知道“朋友”，而不知道“陌生人”；换言之，“某人”会认为他所调用的这个方法是“朋友”的方法。\n\n### 朋友圈的确定\n以下条件称为“朋友”条件：\n- 当前对象本身（this）\n- 以参量形式传入到当前对象方法中的对象\n- 当前对象的实例变量直接引用的对象\n- 当前对象的实例变量如果是一个聚集，那么聚集中的元素也都是朋友\n- 当前对象所创建的对象\n\n任何一个对象，如果满足上面的条件之一，就是当前对象的“朋友”；否则就是“陌生人”\n\n### 不满足迪米特法则的系统\n这里要讨论的系统由三个类组成，分别是Someone，Friend和Stranger。其中Someone与Friend是朋友，而Friend与Stranger是朋友。系统的结构图如下：\n\n{% mermaid %}\n\nclassDiagram\n\nclass Someone {\n    +operation1():void\n}\n\nclass Friend {\n    -stranger:Stranger\n    +operation2():void\n    +provide():Stranger\n}\n\nclass Stranger {\n    +operation3():void\n}\n\nSomeone ..> Friend\n\nFriend o--> Stranger\n\nSomeone ..> Stranger\n{% endmermaid %}\n\n\n从上面的类图可以看出，Friend持有一个Stranger对象的引用，这就解释了为什么Friend与Stranger是朋友。为了解释为什么Someone与Friend是朋友，请参见这里给出的Someone的源码：\n```java\npublic class Someone {\n    public void operation1(Friend friend) {\n        Stranger stranger = friend.provide();\n        stranger.operation3();\n    }\n}\n```\n可以看出，Someone具有一个方法operation1()，这个方法接受Friend为参量。显然，根据“朋友”的定义，Friend是Someone的朋友。其中Friend的provide()方法会提供自己创建的Stranger的实例，代码如下：\n```java\npublic class Friend {\n    private Stranger stranger = new Stranger();\n    public void operation2() {\n\n    }\n    public Stranger provide() {\n        return stranger;\n    }\n}\n```\n显然，Someone的方法operation1()不满足迪米特法则。为什么呢？因为这个方法引用了Stranger对象，而Stranger对象不是Someone的朋友。\n\n### 使用迪米特法则进行改造\n可以使用迪米特法则对上面的例子进行改造，改造的做法就是调用转发。改造后的情况如下：\n\n{% mermaid %}\nclassDiagram\n\nclass Someone {\n    +operation1():void\n}\n\nclass Friend {\n    -stranger:Stranger\n    +operation2():void\n    +forward():void\n}\n\nclass Stranger {\n    +operation3():void\n}\n\nSomeone ..> Friend\n\nFriend o--> Stranger\n{% endmermaid %}\n\n从上面的类图可以看出，与改造前相比，在Someone与Stranger之间的联系已经没有了。Someone不需要知道Stranger的存在就可以做同样的事情。Someone的源代码如下：\n```java\npublic class Someone {\n    public void operation1(Friend friend) {\n        friend.forward();\n    }\n}\n```\n从源代码可以看出，Someone通过调用自己的朋友Friend对象的forward()方法做到了原来需要调用Stranger对象才能够做到的事情。那么这个forward()方法是做什么的呢？代码如下：\n```java\npublic class Friend {\n    private Stranger stranger = new Stranger();\n    public void operation2() {\n        System.out.println(\"In Friend.operation2()\");\n    }\n    public void forward() {\n        stranger.operation3();\n    }\n}\n```\n原来Friend类的forward()方法所做的就是以前Someone要做的事情，使用了Stranger的operation3()方法，而这种forward()方法叫做转发方法。由于使用了调用转发，使得调用的具体细节被隐藏在Friend内部，从而使Someone与Stranger之间的直接联系被省略掉了。这样一来，使得系统内部的耦合度降低。在系统的某一个类需要修改时，仅仅会直接影响到这个类的“朋友”们，而不会直接影响到其余部分。\n\n### 狭义的迪米特法则的缺点\n遵循狭义的迪米特法则会产生一个明显的缺点：会在系统里造出大量的小方法，散落在系统的各个角落。这些方法仅仅是传递间接的调用，因此与系统的商务逻辑无关。当设计师试图从一张类图看出总体的架构时，这些小的方法会造成迷惑和困扰。\n\n遵循类之间的迪米特法则会使一个系统的局部设计简化，因为每一个局部都不会和远距离的对象有直接的关联。但是，这也会造成系统的不同模块之间的通信效率降低，也会使系统的不同模块之间不容易协调。\n\n### 与依赖倒转原则互补使用\n为了克服狭义的迪米特法则的缺点，可以使用依赖倒转原则，引入一个抽象的类型引用“抽象陌生人”对象，使“某人”依赖于“抽象陌生人”。换言之，就是将“抽象陌生人”变成朋友，如下图：\n![迪米特法则和依赖倒转原则互补](重读《JAVA与模式》笔记系列-00008/4.jpg)\n\n\"某人“现在与一个抽象角色建立了朋友关系，这样做的好处是”朋友“可以随时将具体”陌生人“换掉。只要新的具体”陌生人“具有相同的抽象类型，那么”某人“就无法区分它们。这就允许”陌生人“的具体实现可以独立于”某人“而变化，如下图所示。\n![迪米特法则和依赖倒转原则互补](重读《JAVA与模式》笔记系列-00008/5.jpg)","tags":["LoD","迪米特法则"],"categories":["设计模式","设计原则的体现"]},{"title":"重读《JAVA与模式》笔记系列-00007","url":"/2023/02/12/重读《JAVA与模式》笔记系列-00007/","content":"# 合成/聚合复用原则(CARP)\n合成/聚合复用原则(Composite/Aggregate Reuse Principle, 或CARP)，经常又叫作合成复用原则(Composite Reuse Principle或CRP)。合成/聚合复用原则就是在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分：新的对象通过向这些对象的委派达到复用已有功能的目的。\n\n这个设计原则有另一个更简短的表述：要尽量使用合成/聚合，尽量不要使用继承。\n\n合成(Composite)一词的使用很广泛，经常导致混淆。为避免这些混淆，不妨先来考察一下“合成”与“聚合”的区别。\n\n## 合成和聚合的区别\n合成(Composition)和聚合(Aggregation)均是关联(Association)的特殊种类。聚合用来表示“拥有”关系或者整体与部分的关系；而合成则用来表示一种强得多的“拥有”关系。在一个合成关系里，部分和整体的生命周期是一样的。一个合成的新的对象完全拥有对其组成的支配权，包括它们的创建和湮灭等。使用程序语言的术语来讲，组合而成的新对象对组成部分的内存分配、内存释放有绝对的责任。\n\n更进一步来讲，一个合成的多重性(Multiplicity)不能超过1，换言之，一个合成关系中的成分对象是不能与另一个合成关系共享的。一个成分对象在同一时间内只能属于一个合成关系。如果一个合成关系湮灭了，那么所有的成分对象要么自己湮灭所有的成分对象(这种情况较为普通)，要么就得将这一责任交给别人（这种情况较为罕见）。\n\n用C程序员较易理解的语言来讲，合成是值的聚合(Aggregation by Value), 而通常所说的聚合则是引用的聚合(Aggreation by Reference)。\n\n## 复用的基本种类\n在面向对象的设计里，有两种基本的办法可以在不同的环境中复用已有的设计和实现，即通过合成/聚合或通过继承。那么这两种不同的复用方式在可维护性上面有何区别呢？\n\n### 合成/聚合复用\n由于合成或聚合可以将已有的对象纳入到新对象中，使之成为新对象的一部分，因此新的对象可以调用已有对象的功能。这样做有下面的好处：\n- 新对象存取成分对象的惟一方法是通过成分对象的接口。\n- 这种复用是黑箱复用，因为成分对象的内部细节是新对象所看不见的。\n- 这种复用支持包装。\n- 这种复用所需要的依赖较少。\n- 每一个新的类可以将焦点集中在一个任务上。\n- 这种复用可以在运行时间内动态进行，新对象可以动态地引用与成分对象类型相同的对象。\n一般而言，如果一个角色得到了更多的责任，那么可以使用用合成/聚合关系将新的责任委派到合适的对象。\n\n当然，这种复用也有缺点。其中最主要的缺点就是通过使用这种复用建造的系统会有较多的对象需要管理。\n\n### 通过继承达到复用的目的\n合成/聚合作为复用的手段可以应用到几乎任何环境中去。而与合成/聚合不同的是，继承只能应用到很有限的一些环境中去。换言之，尽管继承是一种非常重要的复用手段，但是设计师应当首先考虑使用合成/聚合，而不是继承。\n\n#### 继承的种类\n继承是面向对象的语言特有的复用工具，而且是最容易被滥用的复用工具。这里讨论的继承，是指从一个Java类到另一个Java类的实现性继承，也就是实现继承，并不包括接口继承。一个实现继承的例子如下图：\n\n{% mermaid %}\n\nclassDiagram\n\n蛋 <|-- 鸡\n\n{% endmermaid %}\n\n继承复用通过扩展一个已有对象的实现来得到新的功能，基类明显地捕获共同的属性和方法，而子类通过增加新的属性和方法来扩展超类的实现。继承是类型的复用，比如下面都是继承的例子：\n- 男人和女人是人类\n- 上推排序(Bubble Sort)是排序程序的一种\n- 汽车驾照是官方文件的一种\n- 正式雇员和临时雇员均是雇员的一种\n- 经理是正式雇员的一种\n\n在面向对象的设计理论早期，设计师十分热衷于继承，好像继承就是最好的复用手段。随着时间的推移和实践经验的积累，人们逐渐认识到了继承关系的缺点。\n\n#### 继承复用的优点\n利用继承关系达到复用的做法有下面的优点：\n- 新的实现较为容易，因为超类的大部分功能可以通过继承关系自动进入子类。\n- 修改或扩展继承而来的实现较为容易\n#### 继承复用的缺点\n与合成/聚合复用不同的是，继承有多个缺点：\n- 继承复用破坏包装，因为继承将超类的实现细节暴露给子类。由于超类的内部细节常常是对子类透明的，因此这种复用是透明的复用，又称“白箱”复用。\n- 如果超类的实现发生改变，那么子类的实现也不得不发生改变。因此，当一个基类发生改变时，这种改变会像水中投入石子引起的水波一样，将变化一圈又不圈地传导到一级又一级的子类，使设计师不得不相应地改变这些子类，以适应超类的变化。\n- 从超类继承而来的实现是静态的，不可能在运行时间内发生改变，因此没有足够的灵活性。\n  \n由于以上的这些缺点，尽量使用合成/聚合而不是继承来达到对实现的复用，是非常重要的设计原则。\n\n## 从代码重构的角度理解\n在很多情况下，缺乏经验的Java设计师之所以选择继承关系描述两个类之间的关系，是因为对继承关系的理解不够造成的。而要正确地使用继承关系，必须透彻地理解里氏代换原则和Coad法则。\n\n一般来说，对违反里氏代换原则的设计进行重构时，可以采取两个办法：一是加入一个抽象超类，这一办法已经在本书的“里氏代换原则”一章中讨论过了；二是将继承关系改写合成/聚合关系，这一点是本章讨论的重点。\n\n### 区分“Has-A”与“Is-A”\n“Is-A”是严格的分类学意义上的定义，意思是一个类是另一个类的“一种”。而”Has-A“则不同，它表示某一个角色具有某一项责任。\n\n导致错误地使用继承而不是合成/聚合的一个常见的原因是错误地把”Has-A“当作”Is-A“。”Is-A“代表一个类是另一个类的一种；”Has-A“代表一个类是另一个类的一个角色，而不是另一个的一个特殊种类。这就是Coad条件的第一条。\n\n请考虑一下下图所示的类图中所描述的例子。”人“被继承到”雇员“、”经理“、“学生”等子类。而实际上，“雇员”、“经理”和“学生”分别描述一种角色，而“人”可以同时有几种不同的角色。比如，一个“人”既然是“经理”，就必然是“雇员”；而此“人”可能同时还参加MBA课程，从而也是一个“学生”。使用继承来实现角色，则只能使每一个“人”具有“Has-A”角色，而且继承是静态的，这会使得一个“人”在成为“雇员”身份后，就永远为“雇员”，不能称为“经理”或“学生”，而这显然是不合理的。\n\n{% mermaid %}\n\nclassDiagram\n\n人 <|-- 雇员\n人 <|-- 经理\n人 <|-- 学生\n\n{% endmermaid %}\n\n这一错误的设计源自把“角色”的等级结构与“人”的等级结构混淆起来，把Has-A角色误解为Is-A角色。因此要纠正这一错误，关键是区分“人”和“角色”的区别。下图所示的设计就正确地做到了这一点。\n\n{% mermaid %}\n\nclassDiagram\n角色 <|-- 雇员\n角色 <|-- 经理\n角色 <|-- 学生\n人 \"1\" *--> \"*\" 角色\n\n{% endmermaid %}\n\n从上图可以看出，每一个“人”都可以有一个以上的“角色”，所以一个人可以同时是“雇员”，又是“经理”，甚至同时又是“学生”。而且由于“人”与“角色”的耦合是通过合成的，因此，角色可以有动态的变化。一个“人”可以开始是一个“雇员”，然后晋升为“经理”，然后又由于他参加了MBA课程，又成为了“学生”。\n\n这就是说，当一个类是另一个类的角色时，不应当使用继承描述这种关系。\n\n### 与里氏代换原则联合使用\n里氏代换原则是继承复用的基石。如果在任何使用B类型的地方都可以使用S类型，那么S类型才能称为B类型的子类型（Subtype），而B类型才能称为S类型的基类型（Base Type）。\n\n换言之，只有当每一个S在任何情况下都是一种B的时候，才可以将S设计成为B的子类。如果两个类的关系是\"Has-A“关系而不是”Is-A“关系，这两个类一定违反了里氏代换原则。\n\n只有两个类满足里氏代换原则，才有可能是”Is-A“关系。\n\n### Java语言API中的例子\n在Java语言的API中，有几个明显违反这一原则的例子，其中最为著名的就是Stack和Properties。前者被不当地设置为Vector的子类，而Properties被不恰当地设置成Hashtable的子类，\n![Java语言API中的例子](重读《JAVA与模式》笔记系列-00007/1.jpg)\n\n一个Stack不是一个Vector，所以Stack不应当设置成为Vector的子类。同样地，一个性质列（Properties）也不是一个Hashtable。在两种情况下，使用聚合比使用继承关系更合适。\n\n由于Properties继承了Hashtable的行为，因而当p是一个Properties类型的对象时，`p.getProperties(key)`和`p.get(key)`就会给出不同的结果。前者来自于Properties本身，因此会利用默认值；而后者则来自于Hashtable，因此不会利用默认值。\n\n更糟糕的是，由于Properties是Hashtable的子类，因此，客户端可以通过类型的转换，直接使用超类型的行为。比如，Properties假定所有的键和值都是String类型的，如果不是，就会导致运行崩溃。但是，客户端完全可以通过Hashtable提供的行为加入任意类型的键和值。绕过Properties的接口，并导致Properties的内部矛盾和崩溃。\n\n这样一来，Properties其实仅仅是有一些Hashtable的属性的，换言之，这是一个\"Has-A”的关系，而不是一个“Is-A”的关系。","tags":["CARP","合成","聚合","复用原则","里氏代换","Coad法测"],"categories":["设计模式","设计原则的体现"]},{"title":"重读《JAVA与模式》笔记系列-00006","url":"/2023/02/08/重读《JAVA与模式》笔记系列-00006/","content":"\n# 引言\n接口隔离原则(Interface Segregation Principle, 常常缩写做ISP)，讲的是：使用多个专门的接口比使用单一的总接口要好。换言之，从一个客户类的角度来讲：一个类对另外一个类的依赖性应当是建立在最小的接口上的。\n\n# 什么是接口隔离原则\n正如本书在“专题：Java接口”一章中所指出的那样，人们所说的“接口”往往是指两种不同的东西：一种是指Java语言中的有严格定义的Interface结构，比如java.lang.Runnable就是一个Java接口；另一种就是一个类型所具有的方法特征的集合，也称做“接口”，但仅是一种逻辑上的抽象。对应这两种不同的用词，接口隔离原则的表达方式以及含义都有所不同。\n\n## 角色的合理划分\n将“接口”理解为一个类所提供的所有方法的特征集合，也就是一种在逻辑上才存在的概念。这样的话，接口的划分就直接带来类型的划分。\n\n一个接口相当于剧本中的一种角色，而此角色在一个舞台上由哪一个演员来演则相当于接口的实现。因此，一个接口应当简单地代表一个角色，而不是多个角色。如果系统涉及到多个角色的话，那么每一个角色都应当由一个特定的接口代表。\n\n为了避免混淆，本书将这种角色划分的原则叫做角色隔离原则。\n\n## 定制服务\n将接口理解成为狭义的Java接口，这样一来，接口隔离原则讲的就是为同一个角色提供宽、窄不同的接口，以对付不同的客户端，如下图所示。这种办法在服务行业中叫做定制服务(Customized Service)，这也是本书给这种诠释的一个名字。\n\n{% mermaid %}\n\nclassDiagram\nclass IService1 {\n\t<<interface>>\n}\nIService1: +m1()\nIService1: +p2()\n\nclass IService2 {\n\t<<interface>>\n}\nIService2: +m2()\nIService2: +p1()\n\nclass IService3 {\n\t<<interface>>\n}\nIService3: +m1()\nIService3: +p1()\nIService3: +p2()\n\nIService1 <|-- Service\nIService2 <|-- Service\nIService3 <|-- Service\n\nClient1 --> IService1\nClient2 --> IService2\nClient3 --> IService3\n\nService: +m1()\nService: +m2()\nService: +p1()\nService: +p2()\n\n{% endmermaid %}\n\n在上面的示意性类图中，有一个角色Service以及三个不同的客户端。这三个客户端需要的服务都是稍稍不同的，因此系统分别为它们提供了三个不同的Java接口，即IService1，IService2以及IService3。显然，每一个Java接口都仅将客户端需要的接口暴露给客户端，而没有将客户端不需要的行为放到接口中。熟悉适配器模式的读者可以辨认出，这是适配器模式的应用。\n\n## 接口污染\n过于臃肿的接口是对接口的污染(Interface Contamination)。\n\n由于每一个接口都代表一个角色，实现一个接口的对象，在它的整个生命周期中都扮演这个角色，因此将角色区分清楚就是系统设计的一个重要工作。因此，一个符合逻辑的推断，不应当将几个不同的角色都交给同一个接口，而应当交给不同的接口。\n\n一个没有经验的设计师往往想节省接口的数目，因此将一些看上去差不多的接口合并。一些人将这看做是代码优化的一部分，这是错误的。\n\n准确而恰当地划分角色以及角色所对应的接口，是面向对象的设计的一个重要的组成部分。将没有关系的接口合并在一起，形成一个臃肿的大接口，是对角色和接口的污染。\n\n## 现迪米特法则的关系\n迪米特法则要求任何一个软件实体，除非绝对需要，不然不要与外界通信。即使必须进行通信，也应当尽量限制通信的广度和深度。\n\n显然，定制服务原则拒绝向客户提供不需要提供的行为，是符合迪米特法则的。\n\n# 一个角色隔离原则的例子\n本节从代码重构的角度讨论怎样将一个臃肿的角色重新分割成更为合适的较小角色。\n## 全文查询引擎的系统设计\n本章在这里以一个网站的全文查询引擎的系统设计为例，这个例子取材自一个真实的项目，如果读者使用过AltaVisa公司的文字搜索引擎软件包的话，就会很熟悉本例子的情形。一个动态的资料网站将大量的文件资料存储在文件中或关系数据库里面，用户可以通过输入一个或数个关键词进行全文搜索。这个搜索引擎需要维持一个索引库，在本例子里面索引库以文本文件方式存于文件系统中。在源数据被修改、删除或增加时，搜索引擎要做相应的动作，以保证引擎的索引文件也被相应地更新。\n## 反面例子\n首先，下图所示为一个不好的解决方案。一个叫做BadExample的接口负责所有的操作，从提供搜索功能到建立索引的功能，甚至包括搜索结果集合的功能均在一个接口内提供。\n\n{% mermaid %}\n\nclassDiagram\n\nclass Client {\n   -indexCursor:Indexer \n   -searcher:Searcher\n}\n\nclass BadExample {\n    <<interface>>\n    +first():void\n    +last():void\n    +next():void\n    +previous():void\n    +getExcerpt():String\n    +getFullRecord():String\n    +reIndexAll():void\n    +updateIndex():void\n    +search(keywords:String[]):void\n    +getResultset():void\n}\n\nClient o--> BadExample\n\n{% endmermaid %}\n\n这个解决方案违反了角色分割原则，把不同功能的接口放在一起，由一个接口给出包括搜索器角色、索引生成器角色以及搜索结果集角色在内的所有角色。\n\n## 角色的分割\n那么，遵守接口隔离原则的做法是怎么样的呢？如下图所示：\n{% mermaid %}\n\nclassDiagram\nclass Indexer {\n    <<interface>>\n    +reIndexAll():void\n    +updateIndex():void\n}\nclass Searcher {\n    <<interface>>\n    +search(keywords:String[]):void\n    +getResultset():void\n}\nclass FileIndexer {\n    +reIndexAll():void\n    +updateIndex():void\n}\nclass RdbIndexer {\n    +reIndexAll():void\n    +updateIndex():void\n}\nFileIndexer ..|>Indexer\nRdbIndexer ..|>Indexer\nclass Resultset {\n    <<interface>>\n    +first():void\n    +last():void\n    +next():void\n    +previous():void\n    +getExcerpt():String\n    +getFullRecord():String\n}\n\nSearcher o--> Resultset\n\nclass Client {\n    -indexCursor:Indexer\n    -searcher:Searcher\n}\n\nClient o-->Indexer\nClient o--Searcher\n\n{% endmermaid %}\n\n在图中可以看出，搜索引擎的功能被分割为三个角色：\n- 搜索器角色\n- 索引生成器角色\n- 搜索结果集角色\n\n以索引生成器角色为例，由于索引生成因数据的格式不同而不同，故分为RdbIndexer和FileIndexer两种实现。FileIndexer类代表诸如*.txt、*.html、 *.html、 *.doc 以及 *.pdf等文件类型的数据生成全文索引，而RdbIndexer则针对关系数据库的数据进行全文索引生成。这两个实现扮演的同为索引生成器角色，就好像扮演同样角色的两个不同演员一样。\n\n搜索器角色则是与索引生成器角色完全不同的角色，它提供用户全文搜索功能。用户传进一些关键字，搜索器角色则返回一个Resultset对象。\n\n搜索结果集角色就是Resultset。它给用户提供对集合进行迭代走访的功能，如first()将光标移到集合的第一个元素；last()将光标移到集合的最后一个元素；next()将光标移到集合的下一个元素；previous()将光标移到集合的前一个元素；而getExerpt()则返回当前记录的摘要；而getFullRecord()则将记录的全文返回。\n\n# 定制服务的例子\n定制服务(Customized Service)也是一个重要的设计原则。它的意思是说，如果客户端仅仅需要某一些方法的话，那么就应当向客户端提供这些需要的方法，而不要提供不需要的方法。\n\n这样做的效果是什么呢？\n- 这样做很整洁。从美学的角度上考虑，这是一个很好的做法。从这样的一个设计可以看出，设计师花了很多的时间在分析和划分这些接口上面。但是这并不是最重要的效果，没有人会仅仅因为美学效果而将这一原则当作面向对象的设计原则。\n- 系统的可维护性。向客户端提供public接口是一种承诺，一个public接口一旦提供，就很难撤回。作为软件提供商，没有人愿意做出过多的承诺，特别是不必要的承诺。过多的承诺会给系统的维护造成不必要的负担。如果这些接口仅仅是提供给公司内部的系统使用，那么将这些接口隔离开来，也可以降低维护的成本。因为如果一旦所提供的服务出现变化的话，设计师知道哪些客户端会受到影响，哪些不会受到影响。这显然也是符合迪米特法则的。\n\n## 备忘录模式\n备忘录模式(Memento Pattern)的用意是在不破坏封装的条件下，捕捉一个对象的状态，并将之外部化，从而可以在将来合适的时候把这个对象还原到存储起来的状态。备忘录模式的简略类图如下所示：\n![备忘录简略类图](重读《JAVA与模式》笔记系列-00006/1.jpg)\n在这里，不破坏封装是一个关键词。为了做到这一点，必须使备忘录对象向外界提供双重接口，也即一个窄接品和一个宽接口。\n\n宽接口是为发起人角色准备的，因为这个备忘录角色所存储的状态就是属于这个发起人角色的，而且这个角色需要访问备忘录角色所存储的信息以便恢复自己的状态。\n\n窄接口是为包括负责人角色在内的所有其它对象准备的，因为它们不需要、也不应该读取备忘录角色所存储的信息。\n\n换言之，发起人角色和负责人角色就相当于备忘录角色的不同客户端，而这种为不同客户端提供不同接口的做法就是定制服务概念的体现。\n\n## 迭代子模式\n迭代子模式提供一个迭代子对象，使得客户端可以顺序地访问一个聚集中的元素，而不必暴露聚集的内部表象。迭代子模式的示意图如下所示：\n![迭代子模式简略类图](重读《JAVA与模式》笔记系列-00006/2.jpg)\n\n换言之，上面的这个系统的客户端和系统内部的迭代子对象都需要访问聚集对象，但是它们所需要的访问性质有所不同。前者仅需要通过一个迭代子接口遍历聚集元素，而迭代子对象则需要知道聚集对象的内部结构信息。\n\n因此，聚集对象向不同的客户端提供不同的接口，一个是宽接口，提供给迭代子对象；另一个是窄接口，提供给系统的客户端。","tags":["ISP","接口隔离原则"],"categories":["设计模式","设计原则的体现"]},{"title":"《区块链原理、设计与应用》阅读摘录-0004","url":"/2023/02/02/《区块链原理、设计与应用》阅读摘录-0004/"},{"title":"Golang等值运算符机制详解","url":"/2023/02/01/Golang等值运算符机制详解/","content":"\n# 背景\n这篇文章源于代码中关于nil判断的一个问题。先从一段代码看起，下面这段代码是将传入的对象转换成`JSON string`并返回，其中，如果判断`i==nil`时，会返回`\"\"`。\n```go\nfunc ToJSONString(i interface{}) string {\n   if i == nil {\n      return \"\"\n   }\n   bytes, _ := json.Marshal(i)\n   return string(bytes)\n}\n```\n这段代码初看并没有太大的问题，但实际上这里隐含了一个不容易被发现的问题，在说明这个问题之前，我们先看下这段代码在什么情况下会出现问题：\n```go\ntype Data struct {\n   V int `json:\"v\"`\n}\n\nfunc TestToJSONString(t *testing.T) {\n   a := assert.New(t)\n\n   a.Equal(\"\", ToJSONString(nil))\n\n   var data *Data\n   a.Equal(\"\", ToJSONString(data))\n\n   var k *int\n   a.Equal(\"\", ToJSONString(k))\n}\n```\n这段测试代码中三个断言分别返回：\n```\nPASS\nFAIL, Expect: \"\", Actual: \"null\"\nFAIL, Expect: \"\", Actual: \"null\"\n```\n这里很让人疑惑，data应该是nil，似乎data==nil的结论是false，为了确认这个问题，我们引入一段代码。\n```go\nvar a *int = nil\nvar b interface{} = nil\n\nfmt.Println(\"a == nil:\", a == nil)\nfmt.Println(\"b == nil:\", b == nil)\nfmt.Println(\"a == b:\", a == b)\n```\n结果为：\n```\na == nil: true\nb == nil: true\na == b: false // 重点\n```\n这个例子比较简单，让我们看一个很相似，但稍微复杂些的例子\n```go\nvar a *int = nil\nvar b interface{} = a\n\nfmt.Println(\"a == nil:\", a == nil)\nfmt.Println(\"b == nil:\", b == nil)\nfmt.Println(\"a == b:\", a == b)\n```\n结果为：\n```\na == nil: true\nb == nil: false // 重点\na == b: true\n```\n# 到底发生了什么？\n首先我们要了解的是：在Go中，每个指针都有2个基本信息，指针的类型和指针的值，后续我将会使用`(type, value)`这样的形式来体现。也就是说，`a := nil`这样的代码无法通过编译，因为它缺失了`type`，所以需要这样`var a *int = nil`。\n我们可以在fmt中输出这些指针的`type`：\n```go\nvar a *int = nil\nvar b interface{} = nil\n\nfmt.Printf(\"a.type:%T\\n\", a) // a.type:*int\nfmt.Printf(\"b.type:%T\\n\", b) // b.type:<nil>\n```\n我们现在已经了解了`interace{}`的默认`type`为`nil`，下面我们不使用硬编码的方式，而是将`a`传递给`b`，然后再来看下结果：\n```go\nvar a *int = nil\nvar b interface{} = a\n\nfmt.Printf(\"a.type:%T\\n\", a) // a.type:*int\nfmt.Printf(\"b.type:%T\\n\", b) // b.type:*int\n```\n也就是说，`b`现在有了一个新的类型`*int`。目前你已经了解了关于类型的一些基本机制，但还有一些问题还没有被解答.\n\n# 当执行`==`时，发生了什么？\n```go\nvar a *int = nil\nvar b interface{} = nil\n\nfmt.Printf(\"a=(%T, %v)\\n\", a, a)\nfmt.Printf(\"b=(%T, %v)\\n\", b, b)\nfmt.Println(\"a == nil:\", a == nil)\nfmt.Println(\"b == nil:\", b == nil)\nfmt.Println(\"a == b:\", a == b)\n```\n结果：\n```\na=(*int, <nil>)\nb=(<nil>, <nil>)\na == nil: true\nb == nil: true\na == b: false\n```\n这段代码乍一看似乎不可能，像是在说：a==nil、b==nil，但a!=b。实际情况是，类型判断不仅仅只判断二者的值，还会判断其类型。\n```\na == nil // 等价于：(*int, nil) == (*int, nil)\nb == nil // 等价于：(nil, nil) == (nil, nil)\na == b   // 等价于：(*int, nil) == (nil, nil)\n```\n当我们用这样的方式写出来时，我们可以很轻易的明白，a!=b是成立的，但这些信息并不会在代码中体现出来，这也正是容易出现误解的地方。在这里，如果你想要判断二者是否都是nil，你可以这样写\n```go\nif a == nil && b == nil {\n  // do something\n}\n```\n接下来我们再来看看前面那个令人困惑的例子，相关结果直接跟在了代码后面\n```go\nvar a *int = nil\nvar b interface{} = a\n\nfmt.Printf(\"a=(%T, %v)\\n\", a, a)   // a=(*int, <nil>)\nfmt.Printf(\"b=(%T, %v)\\n\", b, b)   // b=(*int, <nil>)\nfmt.Println(\"a == nil:\", a == nil) // a == nil: true\nfmt.Println(\"b == nil:\", b == nil) // b == nil: false\nfmt.Println(\"a == b:\", a == b)     // a == b: true\n```\n现在我们再来看b==nil这段代码会发现明朗许多：\n```go\nb == nil // 等价于：(*int, nil) == (nil, nil)\n```\n这里可能会疑惑，为什么等式右侧的`nil`，其`type`为`nil`呢？这是因为当`b`指定为`interface{}`类型的时候，无法确定其真实的类型，随着程序的运行，其类型可能会不断改变，所以其类型默认为`nil`。\n更进一步，我们可以看一个硬编码的数字是如何进行比较判断的。数字会根据上下文来推断自己的类型，一个具体的例子如下：\n```go\nvar a int = 12\nvar b float64 = 12\nvar c interface{} = a\n\nfmt.Println(\"a==12:\", a == 12) // true  => (int, 12) == (int, 12)\nfmt.Println(\"b==12:\", b == 12) // true  => (float64, 12) == (float64, 12)\nfmt.Println(\"c==12:\", c == 12) // true  => (int, 12) == (int, 12)\nfmt.Println(\"a==c:\", a == c)   // true  => (int, 12) == (int, 12)\nfmt.Println(\"b==c:\", b == c)   // false => (float64, 12) == (int, 12)\n```\n一个需要注意的点是，当`12`与一个`interface{}`进行比较时，会默认转换为`(int, 12)`，类似的`interface{}`也会被强制转换为`(nil, nil)`，如下代码展示了这个过程:\n```go\nvar b float64 = 12\nvar c interface{} = b\n\nfmt.Println(\"c==12:\", c == 12) // c==12: false\nfmt.Printf(\"c=(%T,%v)\\n\", c, c) // c=(float64,12)\nfmt.Printf(\"hard-coded=(%T,%v)\\n\", 12, 12) // hard-coded=(int,12)\n```\n\n# 回到最开始的`nil`判断\n让我们回到最开始出现问题的代码，现在再来看会清晰许多\n```go\nfunc ToJSONString(i interface{}) string {\n   if i == nil {\n      return \"\"\n   }\n   bytes, _ := json.Marshal(i)\n   return string(bytes)\n}\n\nfunc TestToJSONString() {\n  // ...\n  var data *Data\n  a.Equal(\"\", ToJSONString(data))\n}\n```\n第2行中，`i==nil`的判断相当于`(*Data, nil) == (nil, nil)`，显而易见，这样的等式并不会成立。当然，我们有其他的办法处理这样的等式判断，这需要用到`reflect`包，如下：\n```go\nfunc ToJSONString(i interface{}) string {\n   if i == nil || (reflect.ValueOf(i).Kind() == reflect.Ptr && reflect.ValueOf(i).IsNil()) {\n      return \"\"\n   }\n   bytes, _ := json.Marshal(i)\n   return string(bytes)\n}\n```\n","tags":["nil"],"categories":["Golang","基础"]},{"title":"Fabric-Idemix说明","url":"/2023/01/30/Fabric-Idemix说明/","content":"[抄自这个链接](https://blog.csdn.net/ice_fire_x/article/details/104639727)\n# Idemix是什么\nIdemix(Identity Mixer)的核心是零知识证明(Zero Knowledge Proof)，用户无需暴露私有数据以及任何有用的信息，也能证明自己拥有这些私有数据，对方能够进行有效验证，这就是零知识证明。\n\nIdemix是一个密码协议套件(X.509+加密算法)，保留隐私实现匿名性，交易时不用透露交易者的身份，而且交易间是无关联的，不可往前追溯。\n\nIdentity包含三个角色，包括用户(User)、发行者(Issuer)、验证者(Verifier)，各自作用如下：\n- 用户：通过Idemix生成一个proof，证明自己知道某个秘密\n- 发行者：(Fabric CA或idemixgen工具)验证用户的隶属属性，然后颁发一个证书\n- 验证者：(fabric MSP)验证proof\n![Identity Mixer Overview](Fabric-Idemix说明/Idemix-1.png)\n\n# Idemix的实现\nFabric中Peer通过Fabric CA进行Enroll、Register、Revoke的操作、还可以通过Identity Mixer对交易进行签名验签的操作；Identity Mixer和Fabric CA都需要调用加密包进行具体的流程。\n![实现流程](Fabric-Idemix说明/Idemix-2.png)\n\n## 带有Identity Mixer的MSP\n除了X.509证书外，还可以通过发行Idemix凭据来实现MSP。fabric MSP作为验证者（Verifier），发行者为用户颁发数字证书，用户生成Idenmix凭据后向验证者提供proof，用于验证属性是否正确。目前Idemix凭据只支持3个属性，包括：\n- OU\n- isAdmin\n- Enrollment ID\n![Identity Mixer In Hyperledger Fabric](Fabric-Idemix说明/Idemix-3.png)\n\n# Idemix的特性\nIdemix与X.509的相同点：\n- 一组属性被签名，且签名不可伪造\n- 凭证通过密码学的方式绑定到一个密钥\n\nIdemix与X.509的不同点：\n- Idemix通过零知识证明来确保不会泄露知识或信息，并且用户拥有凭证密钥；而X.509通过最初签名的公钥来验证，知道私钥的人才能生成证明；\n- Idemix是各个信息间是无关联的，且不可往回追溯；而X.509显示所有属性，因此所有用于签发交易的X.509证书使用都是关联的。\n\n![两者对比](Fabric-Idemix说明/Idemix-4.png)\nIdemix与X.509是可以共存的，可以通过在configtx.yam里面指定“msptype: idemix”来支持Idemix，如下所示：\n![配置支持Idemix](Fabric-Idemix说明/Idemix-5.png)\nIdemix仍然有一些局限性：\n\n- 只支持固定的属性，例如OU、Role attribute、Enrollment ID、Revocation Handle attribute等；\n- 不支持Idemix的撤销\n- Peers还不能使用Idemix来进行背书，目前Peers的Idemix MSP只是用来验证签名，Idemix签名只能通过客户端SDK来进行；\n- 建议每个channel或每个网络只使用一个基于Idemix的MSP，因为Idemix当前仅提供同一组织（MSP）中client的匿名性。","tags":["零知识证明"],"categories":["区块链","Fabric"]},{"title":"Fabric-discover说明","url":"/2023/01/29/Fabric-discover说明/","content":"\n# 引言\n客户端要往`Fabric`网络中发送请求，首先需要知道网络网络的相关信息，如网络中成员组织信息、背书节点的地址、链码安装信息等。在`Fabric v1.2.0`版之前，这些信息需要调用者手动指定，容易出错；另外，当网络中信息变更后（如节点上下线）还需要再次更新。为了解决这些问题，社区自`v1.2.0`版本开始在`Peer`节点上提供`Discovery gRPC`服务，并编写了`discover`客户端工具（入口位于`fabric/discovery/cmd/cmd.go`)，查询`Discovery`服务获取指定信息（如通道内的邻居节点、可对某链码进行背书的节点组）。\n\n# 主要功能\n`discover`工具目前提供如下查询功能：\n- 节点信息，使用`peers`子命令查询通道内各节点的`MSP ID`、`服务地址`和`证书等信息`\n- 通道配置，使用`config`子命令查询通道的配置信息，包括通道内成员组织的身份信息、排序服务信息等。\n- 链码背书信息，使用`endorsers`子命令查询对某个链码可以进行背书的节点信息。命令使用格式为：\n  ```\n  discover [全局参数] <子命令> [子命令参数列表]\n  ```\n  注意：节点信息和链码背书信息查询功能在默认情况下只支持组织管理员，如果希望普通成员也可以查询，需要开启`peer`配置，`core.yaml`中：\n  ```yaml\n  peer:\n    discovery:\n        orgMembersAllowedAccess: true\n  ```\n![命令帮助](Fabric-discover说明/cmd-help.jpg)\n\n# 全局参数\n`discover`支持的全局参数和相关说明如下：\n- --help, 输出帮助信息.\n- --configFile=CONFIGFILE, 指定从配置文件中载入参数配置，无须从命令行指定参数\n- --peerTLSCA=PEERTLSCA, 指定校验`Peer`端TLS的CA证书。\n- --tlsCert=TLSCERT, 指定客户端使用的TLS证书（可选，当`Peer`校验客户端TLS时）。\n- --tlsKey=TLSKEY, 指定客户端使用的TLS私钥（可选，当`Peer`校验客户端TLS时）。\n- --userKey=USERKEY, 客户端签名私钥。\n- --userCert=USERCERT, 客户端签名证书。\n- --MSP=MSP, 指定客户端的`MSP ID`\n\n# peers 子命令\n显示通道中的`peer`节点信息，包括它们的`MSP ID`、`gRPC服务监听地址`和`身份证书`。例如通过`peer0.org1.example.com`节点查询`businesschannel`通道内的`peer`节点信息：\n```shell\ndiscover peers \\\n    --channel businesschannel \\\n    --peerTLSCA /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem \\\n    --userKey /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/msp/keystore/priv_sk \\\n    --userCert /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem \\\n    --MSP Org1MSP --tlsCert /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/tls/client.crt \\\n    --tlsKey /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/tls/client.key \\\n    --server peer0.org1.example.com:7051\n```\n正常返回结果如下：\n```json\n[\n\t{\n\t\t\"MSPID\": \"Org1MSP\",\n\t\t\"LedgerHeight\": 9,\n\t\t\"Endpoint\": \"peer0.org1.example.com:7051\",\n\t\t\"Identity\": \"-----BEGIN CERTIFICATE-----\\nMIICKDCCAc+gAwIBAgIRAIc6sjio0hnYI+sBuebcN9gwCgYIKoZIzj0EAwIwczEL\\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\\ncmFuY2lzY28xGTAXBgNVBAoTEG9yZzEuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\\nLm9yZzEuZXhhbXBsZS5jb20wHhcNMjIwMjE3MTAzMDAwWhcNMzIwMjE1MTAzMDAw\\nWjBqMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\\nU2FuIEZyYW5jaXNjbzENMAsGA1UECxMEcGVlcjEfMB0GA1UEAxMWcGVlcjAub3Jn\\nMS5leGFtcGxlLmNvbTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABEHhWvyNC5Pp\\noJmF9pZzdVkKrLcjhS3ePhEIW/53NrnqZUB5QT6NRvo+rxqpIxAjMMZTTg2OewJd\\ng/crbYls2GyjTTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1Ud\\nIwQkMCKAIGk9e22kEiVLy3ReWOlHBJklL9JCedP2QWQP/12fsPLuMAoGCCqGSM49\\nBAMCA0cAMEQCICVqogpr/tI+sNTy8EYbkuuek4gw5Y/bNNI5cTZJpefKAiB8Zr2o\\nx1r62J3DV5qmF2jEAVRV8duwliiAkKW4q1xcNA==\\n-----END CERTIFICATE-----\\n\",\n\t\t\"Chaincodes\": [\n\t\t\t\"hyperledger-fabric-contract-java-demo\",\n\t\t\t\"_lifecycle\"\n\t\t]\n\t},\n\t{\n\t\t\"MSPID\": \"Org1MSP\",\n\t\t\"LedgerHeight\": 9,\n\t\t\"Endpoint\": \"peer1.org1.example.com:8051\",\n\t\t\"Identity\": \"-----BEGIN CERTIFICATE-----\\nMIICKDCCAc6gAwIBAgIQYSi1/xYV9ghavadHl49VMDAKBggqhkjOPQQDAjBzMQsw\\nCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy\\nYW5jaXNjbzEZMBcGA1UEChMQb3JnMS5leGFtcGxlLmNvbTEcMBoGA1UEAxMTY2Eu\\nb3JnMS5leGFtcGxlLmNvbTAeFw0yMjAyMTcxMDMwMDBaFw0zMjAyMTUxMDMwMDBa\\nMGoxCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1T\\nYW4gRnJhbmNpc2NvMQ0wCwYDVQQLEwRwZWVyMR8wHQYDVQQDExZwZWVyMS5vcmcx\\nLmV4YW1wbGUuY29tMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEp42mYDwJKY11\\nntYoyWAwXtIyJiWH/9EB93jVPsFALzicKbibE1vSZlGl1mkb7M5wYCtfai11Bqqz\\nUFEz7e+DsqNNMEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0j\\nBCQwIoAgaT17baQSJUvLdF5Y6UcEmSUv0kJ50/ZBZA//XZ+w8u4wCgYIKoZIzj0E\\nAwIDSAAwRQIhAP+WvJIfhdpG/zkc1GrlTwZOppc0JZL9Nl0MfhJ4TMpiAiAfJ8kF\\njJeEYOonkKeZcRG77WoeB/+32BCUJNsSIwYyKA==\\n-----END CERTIFICATE-----\\n\",\n\t\t\"Chaincodes\": [\n\t\t\t\"hyperledger-fabric-contract-java-demo\",\n\t\t\t\"_lifecycle\"\n\t\t]\n\t},\n\t{\n\t\t\"MSPID\": \"Org2MSP\",\n\t\t\"LedgerHeight\": 9,\n\t\t\"Endpoint\": \"peer0.org2.example.com:7051\",\n\t\t\"Identity\": \"-----BEGIN CERTIFICATE-----\\nMIICKTCCAc+gAwIBAgIRAJnk+wcTIbag0SNs4f2TAeIwCgYIKoZIzj0EAwIwczEL\\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\\ncmFuY2lzY28xGTAXBgNVBAoTEG9yZzIuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\\nLm9yZzIuZXhhbXBsZS5jb20wHhcNMjIwMjE3MTAzMDAwWhcNMzIwMjE1MTAzMDAw\\nWjBqMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\\nU2FuIEZyYW5jaXNjbzENMAsGA1UECxMEcGVlcjEfMB0GA1UEAxMWcGVlcjAub3Jn\\nMi5leGFtcGxlLmNvbTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABKtm2wfuhEqm\\nht8CqbV1CKAe7YRAao5ySPMCCswpXuX3Amw65L0pFLELhhFHvqoTmwTZOLNHeHCl\\nJoDQgoM5DUyjTTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1Ud\\nIwQkMCKAINRek9OkgUPYeL4655/hNDSGXlXS/7qqtIzG+9yf2LG2MAoGCCqGSM49\\nBAMCA0gAMEUCIQCB9+ASmx0BgYaN30Zeq+z3Gtj/q1yqrae2bD0dJspbMwIgcAFC\\nx9CQ52jYET7PbIqJOGPksb8amAPUAJXBOIxVJ7U=\\n-----END CERTIFICATE-----\\n\",\n\t\t\"Chaincodes\": [\n\t\t\t\"hyperledger-fabric-contract-java-demo\",\n\t\t\t\"_lifecycle\"\n\t\t]\n\t},\n\t{\n\t\t\"MSPID\": \"Org2MSP\",\n\t\t\"LedgerHeight\": 9,\n\t\t\"Endpoint\": \"peer1.org2.example.com:8051\",\n\t\t\"Identity\": \"-----BEGIN CERTIFICATE-----\\nMIICKDCCAc+gAwIBAgIRAMV4swH5jaaH+rQ13cBAzcwwCgYIKoZIzj0EAwIwczEL\\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\\ncmFuY2lzY28xGTAXBgNVBAoTEG9yZzIuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\\nLm9yZzIuZXhhbXBsZS5jb20wHhcNMjIwMjE3MTAzMDAwWhcNMzIwMjE1MTAzMDAw\\nWjBqMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\\nU2FuIEZyYW5jaXNjbzENMAsGA1UECxMEcGVlcjEfMB0GA1UEAxMWcGVlcjEub3Jn\\nMi5leGFtcGxlLmNvbTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABJQ2FIGAqO2J\\ngR9LzplbIGt2OXCHklyoQzl/o8OubrAy0hc88KqCFJQeH9gynDDrZM8eSyrlNWTO\\nf6ZXcoMMRbejTTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1Ud\\nIwQkMCKAINRek9OkgUPYeL4655/hNDSGXlXS/7qqtIzG+9yf2LG2MAoGCCqGSM49\\nBAMCA0cAMEQCICAY5hjEBFmhjJgOPNZx7oJIh5YlhPPMPuVnofwXR4ZCAiAVnOzZ\\nGzUNe7WFYhT4L2l7xLPl51FjigMoLYjG2Jt+ng==\\n-----END CERTIFICATE-----\\n\",\n\t\t\"Chaincodes\": [\n\t\t\t\"hyperledger-fabric-contract-java-demo\",\n\t\t\t\"_lifecycle\"\n\t\t]\n\t}\n]\n```\n\n# config 子命令\n显示网络中的通道配置信息，包括各个组织的`MSP`信息和排序节点信息。例如通过`peer0.org1.example.com`节点查询`businesschannel`通道内的配置信息，可以执行如下命令：\n```shell\ndiscover config \\\n--channel businesschannel \\\n--peerTLSCA /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem \\\n--userKey /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/msp/keystore/priv_sk \\\n--userCert /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem \\\n--MSP Org1MSP --tlsCert /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/tls/client.crt \\\n--tlsKey /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/tls/client.key \\\n--server peer0.org1.example.com:7051\n```\n正常返回结果如下：\n```json\n{\n\t\"msps\": {\n\t\t\"OrdererMSP\": {\n\t\t\t\"name\": \"OrdererMSP\",\n\t\t\t\"root_certs\": [\n\t\t\t\t\"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNQVENDQWVTZ0F3SUJBZ0lSQU53NEdYbDlIMmE0S2hKdzM4TzlhWHd3Q2dZSUtvWkl6ajBFQXdJd2FURUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhGREFTQmdOVkJBb1RDMlY0WVcxd2JHVXVZMjl0TVJjd0ZRWURWUVFERXc1allTNWxlR0Z0CmNHeGxMbU52YlRBZUZ3MHlNakF5TVRjeE1ETXdNREJhRncwek1qQXlNVFV4TURNd01EQmFNR2t4Q3pBSkJnTlYKQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVFlXNGdSbkpoYm1OcApjMk52TVJRd0VnWURWUVFLRXd0bGVHRnRjR3hsTG1OdmJURVhNQlVHQTFVRUF4TU9ZMkV1WlhoaGJYQnNaUzVqCmIyMHdXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CQndOQ0FBUzdMSWppODVNTVVscGo0bTd6ZW1RZU9TS2EKTnBFWHA3bEF1R3Ryb3ZSMUIwMTVBRzZ4aTFCcCtCRVJNUjZTZXpVV2pGRDlKWHJqWHVJRXc0R0o5YjZZbzIwdwphekFPQmdOVkhROEJBZjhFQkFNQ0FhWXdIUVlEVlIwbEJCWXdGQVlJS3dZQkJRVUhBd0lHQ0NzR0FRVUZCd01CCk1BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0tRWURWUjBPQkNJRUlJSlJGclVMcnQxdk5GQmJORG5OR2RZSkNGSmEKMkdVK0VLbVpEd1ZkVzBLNU1Bb0dDQ3FHU000OUJBTUNBMGNBTUVRQ0lCdnZ6ekhtVW5aUExiWStNYWdDcGhGOApINjJRcnpmSkxnTHZXQmFaaW5LeEFpQlZxQkZWMVBValFoS09RbEVnbzcxeE1HVXlLNHEvbHAwNGF2empXVjY0CmRRPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\"\n\t\t\t],\n\t\t\t\"crypto_config\": {\n\t\t\t\t\"signature_hash_family\": \"SHA2\",\n\t\t\t\t\"identity_identifier_hash_function\": \"SHA256\"\n\t\t\t},\n\t\t\t\"tls_root_certs\": [\n\t\t\t\t\"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNSRENDQWVxZ0F3SUJBZ0lSQUs4eXNvYjliUmNJRGJyVjJVZjdFTDh3Q2dZSUtvWkl6ajBFQXdJd2JERUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhGREFTQmdOVkJBb1RDMlY0WVcxd2JHVXVZMjl0TVJvd0dBWURWUVFERXhGMGJITmpZUzVsCmVHRnRjR3hsTG1OdmJUQWVGdzB5TWpBeU1UY3hNRE13TURCYUZ3MHpNakF5TVRVeE1ETXdNREJhTUd3eEN6QUoKQmdOVkJBWVRBbFZUTVJNd0VRWURWUVFJRXdwRFlXeHBabTl5Ym1saE1SWXdGQVlEVlFRSEV3MVRZVzRnUm5KaApibU5wYzJOdk1SUXdFZ1lEVlFRS0V3dGxlR0Z0Y0d4bExtTnZiVEVhTUJnR0ExVUVBeE1SZEd4elkyRXVaWGhoCmJYQnNaUzVqYjIwd1dUQVRCZ2NxaGtqT1BRSUJCZ2dxaGtqT1BRTUJCd05DQUFSSlRjKzArcU9RNjU2WkEwanoKVEZWNnRVSkloaWJJbjhxekY5dzduNlpOZkMvaUVjUGI5NmJaMFA2UTZjWGw4SGpySG1qOG9BOVhVUW9LNVc3UgpBU0NlbzIwd2F6QU9CZ05WSFE4QkFmOEVCQU1DQWFZd0hRWURWUjBsQkJZd0ZBWUlLd1lCQlFVSEF3SUdDQ3NHCkFRVUZCd01CTUE4R0ExVWRFd0VCL3dRRk1BTUJBZjh3S1FZRFZSME9CQ0lFSU5iQ0ZOcy9wUXRQSllZU1RvYkYKRjdnTThIa0o5SFhlL3dGeXFMbHh1YU1yTUFvR0NDcUdTTTQ5QkFNQ0EwZ0FNRVVDSVFDMG9Pdjh6YU95T1JYTApzVFp2VnFUclIrNzBvcTVzRGZNNHNsSStyTE5nM0FJZ01SZjRpUFY2MDFwa2E3ZnpUOUdpTHZmN0hsUWRDZnhDClN3ZC9xRFh4ZElVPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\"\n\t\t\t],\n\t\t\t\"fabric_node_ous\": {\n\t\t\t\t\"enable\": true,\n\t\t\t\t\"client_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNQVENDQWVTZ0F3SUJBZ0lSQU53NEdYbDlIMmE0S2hKdzM4TzlhWHd3Q2dZSUtvWkl6ajBFQXdJd2FURUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhGREFTQmdOVkJBb1RDMlY0WVcxd2JHVXVZMjl0TVJjd0ZRWURWUVFERXc1allTNWxlR0Z0CmNHeGxMbU52YlRBZUZ3MHlNakF5TVRjeE1ETXdNREJhRncwek1qQXlNVFV4TURNd01EQmFNR2t4Q3pBSkJnTlYKQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVFlXNGdSbkpoYm1OcApjMk52TVJRd0VnWURWUVFLRXd0bGVHRnRjR3hsTG1OdmJURVhNQlVHQTFVRUF4TU9ZMkV1WlhoaGJYQnNaUzVqCmIyMHdXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CQndOQ0FBUzdMSWppODVNTVVscGo0bTd6ZW1RZU9TS2EKTnBFWHA3bEF1R3Ryb3ZSMUIwMTVBRzZ4aTFCcCtCRVJNUjZTZXpVV2pGRDlKWHJqWHVJRXc0R0o5YjZZbzIwdwphekFPQmdOVkhROEJBZjhFQkFNQ0FhWXdIUVlEVlIwbEJCWXdGQVlJS3dZQkJRVUhBd0lHQ0NzR0FRVUZCd01CCk1BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0tRWURWUjBPQkNJRUlJSlJGclVMcnQxdk5GQmJORG5OR2RZSkNGSmEKMkdVK0VLbVpEd1ZkVzBLNU1Bb0dDQ3FHU000OUJBTUNBMGNBTUVRQ0lCdnZ6ekhtVW5aUExiWStNYWdDcGhGOApINjJRcnpmSkxnTHZXQmFaaW5LeEFpQlZxQkZWMVBValFoS09RbEVnbzcxeE1HVXlLNHEvbHAwNGF2empXVjY0CmRRPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"client\"\n\t\t\t\t},\n\t\t\t\t\"peer_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNQVENDQWVTZ0F3SUJBZ0lSQU53NEdYbDlIMmE0S2hKdzM4TzlhWHd3Q2dZSUtvWkl6ajBFQXdJd2FURUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhGREFTQmdOVkJBb1RDMlY0WVcxd2JHVXVZMjl0TVJjd0ZRWURWUVFERXc1allTNWxlR0Z0CmNHeGxMbU52YlRBZUZ3MHlNakF5TVRjeE1ETXdNREJhRncwek1qQXlNVFV4TURNd01EQmFNR2t4Q3pBSkJnTlYKQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVFlXNGdSbkpoYm1OcApjMk52TVJRd0VnWURWUVFLRXd0bGVHRnRjR3hsTG1OdmJURVhNQlVHQTFVRUF4TU9ZMkV1WlhoaGJYQnNaUzVqCmIyMHdXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CQndOQ0FBUzdMSWppODVNTVVscGo0bTd6ZW1RZU9TS2EKTnBFWHA3bEF1R3Ryb3ZSMUIwMTVBRzZ4aTFCcCtCRVJNUjZTZXpVV2pGRDlKWHJqWHVJRXc0R0o5YjZZbzIwdwphekFPQmdOVkhROEJBZjhFQkFNQ0FhWXdIUVlEVlIwbEJCWXdGQVlJS3dZQkJRVUhBd0lHQ0NzR0FRVUZCd01CCk1BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0tRWURWUjBPQkNJRUlJSlJGclVMcnQxdk5GQmJORG5OR2RZSkNGSmEKMkdVK0VLbVpEd1ZkVzBLNU1Bb0dDQ3FHU000OUJBTUNBMGNBTUVRQ0lCdnZ6ekhtVW5aUExiWStNYWdDcGhGOApINjJRcnpmSkxnTHZXQmFaaW5LeEFpQlZxQkZWMVBValFoS09RbEVnbzcxeE1HVXlLNHEvbHAwNGF2empXVjY0CmRRPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"peer\"\n\t\t\t\t},\n\t\t\t\t\"admin_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNQVENDQWVTZ0F3SUJBZ0lSQU53NEdYbDlIMmE0S2hKdzM4TzlhWHd3Q2dZSUtvWkl6ajBFQXdJd2FURUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhGREFTQmdOVkJBb1RDMlY0WVcxd2JHVXVZMjl0TVJjd0ZRWURWUVFERXc1allTNWxlR0Z0CmNHeGxMbU52YlRBZUZ3MHlNakF5TVRjeE1ETXdNREJhRncwek1qQXlNVFV4TURNd01EQmFNR2t4Q3pBSkJnTlYKQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVFlXNGdSbkpoYm1OcApjMk52TVJRd0VnWURWUVFLRXd0bGVHRnRjR3hsTG1OdmJURVhNQlVHQTFVRUF4TU9ZMkV1WlhoaGJYQnNaUzVqCmIyMHdXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CQndOQ0FBUzdMSWppODVNTVVscGo0bTd6ZW1RZU9TS2EKTnBFWHA3bEF1R3Ryb3ZSMUIwMTVBRzZ4aTFCcCtCRVJNUjZTZXpVV2pGRDlKWHJqWHVJRXc0R0o5YjZZbzIwdwphekFPQmdOVkhROEJBZjhFQkFNQ0FhWXdIUVlEVlIwbEJCWXdGQVlJS3dZQkJRVUhBd0lHQ0NzR0FRVUZCd01CCk1BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0tRWURWUjBPQkNJRUlJSlJGclVMcnQxdk5GQmJORG5OR2RZSkNGSmEKMkdVK0VLbVpEd1ZkVzBLNU1Bb0dDQ3FHU000OUJBTUNBMGNBTUVRQ0lCdnZ6ekhtVW5aUExiWStNYWdDcGhGOApINjJRcnpmSkxnTHZXQmFaaW5LeEFpQlZxQkZWMVBValFoS09RbEVnbzcxeE1HVXlLNHEvbHAwNGF2empXVjY0CmRRPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"admin\"\n\t\t\t\t},\n\t\t\t\t\"orderer_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNQVENDQWVTZ0F3SUJBZ0lSQU53NEdYbDlIMmE0S2hKdzM4TzlhWHd3Q2dZSUtvWkl6ajBFQXdJd2FURUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhGREFTQmdOVkJBb1RDMlY0WVcxd2JHVXVZMjl0TVJjd0ZRWURWUVFERXc1allTNWxlR0Z0CmNHeGxMbU52YlRBZUZ3MHlNakF5TVRjeE1ETXdNREJhRncwek1qQXlNVFV4TURNd01EQmFNR2t4Q3pBSkJnTlYKQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVFlXNGdSbkpoYm1OcApjMk52TVJRd0VnWURWUVFLRXd0bGVHRnRjR3hsTG1OdmJURVhNQlVHQTFVRUF4TU9ZMkV1WlhoaGJYQnNaUzVqCmIyMHdXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CQndOQ0FBUzdMSWppODVNTVVscGo0bTd6ZW1RZU9TS2EKTnBFWHA3bEF1R3Ryb3ZSMUIwMTVBRzZ4aTFCcCtCRVJNUjZTZXpVV2pGRDlKWHJqWHVJRXc0R0o5YjZZbzIwdwphekFPQmdOVkhROEJBZjhFQkFNQ0FhWXdIUVlEVlIwbEJCWXdGQVlJS3dZQkJRVUhBd0lHQ0NzR0FRVUZCd01CCk1BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0tRWURWUjBPQkNJRUlJSlJGclVMcnQxdk5GQmJORG5OR2RZSkNGSmEKMkdVK0VLbVpEd1ZkVzBLNU1Bb0dDQ3FHU000OUJBTUNBMGNBTUVRQ0lCdnZ6ekhtVW5aUExiWStNYWdDcGhGOApINjJRcnpmSkxnTHZXQmFaaW5LeEFpQlZxQkZWMVBValFoS09RbEVnbzcxeE1HVXlLNHEvbHAwNGF2empXVjY0CmRRPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"orderer\"\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t\"Org1MSP\": {\n\t\t\t\"name\": \"Org1MSP\",\n\t\t\t\"root_certs\": [\n\t\t\t\t\"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVekNDQWZpZ0F3SUJBZ0lSQU9wamxIMFRsLzlteXYrSWZzRGVSSnN3Q2dZSUtvWkl6ajBFQXdJd2N6RUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhHVEFYQmdOVkJBb1RFRzl5WnpFdVpYaGhiWEJzWlM1amIyMHhIREFhQmdOVkJBTVRFMk5oCkxtOXlaekV1WlhoaGJYQnNaUzVqYjIwd0hoY05Nakl3TWpFM01UQXpNREF3V2hjTk16SXdNakUxTVRBek1EQXcKV2pCek1Rc3dDUVlEVlFRR0V3SlZVekVUTUJFR0ExVUVDQk1LUTJGc2FXWnZjbTVwWVRFV01CUUdBMVVFQnhNTgpVMkZ1SUVaeVlXNWphWE5qYnpFWk1CY0dBMVVFQ2hNUWIzSm5NUzVsZUdGdGNHeGxMbU52YlRFY01Cb0dBMVVFCkF4TVRZMkV1YjNKbk1TNWxlR0Z0Y0d4bExtTnZiVEJaTUJNR0J5cUdTTTQ5QWdFR0NDcUdTTTQ5QXdFSEEwSUEKQkVoVGc2cFRtZ214QnExM0VvRmx5SGozeWd5em9ydWZQb1J3MjlXUVdUNFluMFhTZnNmT1RUZHZRKzJlRThxSgo5WHNVenFmKzVkc2Y4dDF4SFpmR2wxU2piVEJyTUE0R0ExVWREd0VCL3dRRUF3SUJwakFkQmdOVkhTVUVGakFVCkJnZ3JCZ0VGQlFjREFnWUlLd1lCQlFVSEF3RXdEd1lEVlIwVEFRSC9CQVV3QXdFQi96QXBCZ05WSFE0RUlnUWcKYVQxN2JhUVNKVXZMZEY1WTZVY0VtU1V2MGtKNTAvWkJaQS8vWFordzh1NHdDZ1lJS29aSXpqMEVBd0lEU1FBdwpSZ0loQU5lRzUzL3hxMHZHTXpaaVVwWG9RZGwySGZFeU9pVXl3bG43c3AvY0hTOGxBaUVBa3dWN09GckhOTnZECkJUT2szVnVneWxwcytOdWxXTGpOU0hXWTB2NTZaZDA9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\"\n\t\t\t],\n\t\t\t\"crypto_config\": {\n\t\t\t\t\"signature_hash_family\": \"SHA2\",\n\t\t\t\t\"identity_identifier_hash_function\": \"SHA256\"\n\t\t\t},\n\t\t\t\"tls_root_certs\": [\n\t\t\t\t\"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNWekNDQWYyZ0F3SUJBZ0lRTGUwVEFISlZGaW0zUXB0OGJQSUhFREFLQmdncWhrak9QUVFEQWpCMk1Rc3cKQ1FZRFZRUUdFd0pWVXpFVE1CRUdBMVVFQ0JNS1EyRnNhV1p2Y201cFlURVdNQlFHQTFVRUJ4TU5VMkZ1SUVaeQpZVzVqYVhOamJ6RVpNQmNHQTFVRUNoTVFiM0puTVM1bGVHRnRjR3hsTG1OdmJURWZNQjBHQTFVRUF4TVdkR3h6ClkyRXViM0puTVM1bGVHRnRjR3hsTG1OdmJUQWVGdzB5TWpBeU1UY3hNRE13TURCYUZ3MHpNakF5TVRVeE1ETXcKTURCYU1IWXhDekFKQmdOVkJBWVRBbFZUTVJNd0VRWURWUVFJRXdwRFlXeHBabTl5Ym1saE1SWXdGQVlEVlFRSApFdzFUWVc0Z1JuSmhibU5wYzJOdk1Sa3dGd1lEVlFRS0V4QnZjbWN4TG1WNFlXMXdiR1V1WTI5dE1SOHdIUVlEClZRUURFeFowYkhOallTNXZjbWN4TG1WNFlXMXdiR1V1WTI5dE1Ga3dFd1lIS29aSXpqMENBUVlJS29aSXpqMEQKQVFjRFFnQUV0OWg1T3VpZlVZekdyN21YcnFSQUJMRDVXTWVJQnUzKzlCcFJsOUhtbnRaSnR1a2JpS0IwbDdkdApvcTROYmVHM1NSRmNvUDFodlI5L1NuZjF2Ny81LzZOdE1Hc3dEZ1lEVlIwUEFRSC9CQVFEQWdHbU1CMEdBMVVkCkpRUVdNQlFHQ0NzR0FRVUZCd01DQmdnckJnRUZCUWNEQVRBUEJnTlZIUk1CQWY4RUJUQURBUUgvTUNrR0ExVWQKRGdRaUJDQjhXckdseUQydUVuZmJjcW50SnBxUzFDTXZ5aHRUYlFpOUVYb0ZIdFBkUnpBS0JnZ3Foa2pPUFFRRApBZ05JQURCRkFpRUFvZzVPY29jVGs1eGFmU2hmMjAzUzJSU2JXNm1xZldhWXZFWC80RjdEUnlBQ0lDaExueHNTCjZPMGJJZm1BbUVQaERFV0E4TTM2M1RkbWpQQTBCbCtXb2lwTQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\"\n\t\t\t],\n\t\t\t\"fabric_node_ous\": {\n\t\t\t\t\"enable\": true,\n\t\t\t\t\"client_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVekNDQWZpZ0F3SUJBZ0lSQU9wamxIMFRsLzlteXYrSWZzRGVSSnN3Q2dZSUtvWkl6ajBFQXdJd2N6RUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhHVEFYQmdOVkJBb1RFRzl5WnpFdVpYaGhiWEJzWlM1amIyMHhIREFhQmdOVkJBTVRFMk5oCkxtOXlaekV1WlhoaGJYQnNaUzVqYjIwd0hoY05Nakl3TWpFM01UQXpNREF3V2hjTk16SXdNakUxTVRBek1EQXcKV2pCek1Rc3dDUVlEVlFRR0V3SlZVekVUTUJFR0ExVUVDQk1LUTJGc2FXWnZjbTVwWVRFV01CUUdBMVVFQnhNTgpVMkZ1SUVaeVlXNWphWE5qYnpFWk1CY0dBMVVFQ2hNUWIzSm5NUzVsZUdGdGNHeGxMbU52YlRFY01Cb0dBMVVFCkF4TVRZMkV1YjNKbk1TNWxlR0Z0Y0d4bExtTnZiVEJaTUJNR0J5cUdTTTQ5QWdFR0NDcUdTTTQ5QXdFSEEwSUEKQkVoVGc2cFRtZ214QnExM0VvRmx5SGozeWd5em9ydWZQb1J3MjlXUVdUNFluMFhTZnNmT1RUZHZRKzJlRThxSgo5WHNVenFmKzVkc2Y4dDF4SFpmR2wxU2piVEJyTUE0R0ExVWREd0VCL3dRRUF3SUJwakFkQmdOVkhTVUVGakFVCkJnZ3JCZ0VGQlFjREFnWUlLd1lCQlFVSEF3RXdEd1lEVlIwVEFRSC9CQVV3QXdFQi96QXBCZ05WSFE0RUlnUWcKYVQxN2JhUVNKVXZMZEY1WTZVY0VtU1V2MGtKNTAvWkJaQS8vWFordzh1NHdDZ1lJS29aSXpqMEVBd0lEU1FBdwpSZ0loQU5lRzUzL3hxMHZHTXpaaVVwWG9RZGwySGZFeU9pVXl3bG43c3AvY0hTOGxBaUVBa3dWN09GckhOTnZECkJUT2szVnVneWxwcytOdWxXTGpOU0hXWTB2NTZaZDA9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"client\"\n\t\t\t\t},\n\t\t\t\t\"peer_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVekNDQWZpZ0F3SUJBZ0lSQU9wamxIMFRsLzlteXYrSWZzRGVSSnN3Q2dZSUtvWkl6ajBFQXdJd2N6RUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhHVEFYQmdOVkJBb1RFRzl5WnpFdVpYaGhiWEJzWlM1amIyMHhIREFhQmdOVkJBTVRFMk5oCkxtOXlaekV1WlhoaGJYQnNaUzVqYjIwd0hoY05Nakl3TWpFM01UQXpNREF3V2hjTk16SXdNakUxTVRBek1EQXcKV2pCek1Rc3dDUVlEVlFRR0V3SlZVekVUTUJFR0ExVUVDQk1LUTJGc2FXWnZjbTVwWVRFV01CUUdBMVVFQnhNTgpVMkZ1SUVaeVlXNWphWE5qYnpFWk1CY0dBMVVFQ2hNUWIzSm5NUzVsZUdGdGNHeGxMbU52YlRFY01Cb0dBMVVFCkF4TVRZMkV1YjNKbk1TNWxlR0Z0Y0d4bExtTnZiVEJaTUJNR0J5cUdTTTQ5QWdFR0NDcUdTTTQ5QXdFSEEwSUEKQkVoVGc2cFRtZ214QnExM0VvRmx5SGozeWd5em9ydWZQb1J3MjlXUVdUNFluMFhTZnNmT1RUZHZRKzJlRThxSgo5WHNVenFmKzVkc2Y4dDF4SFpmR2wxU2piVEJyTUE0R0ExVWREd0VCL3dRRUF3SUJwakFkQmdOVkhTVUVGakFVCkJnZ3JCZ0VGQlFjREFnWUlLd1lCQlFVSEF3RXdEd1lEVlIwVEFRSC9CQVV3QXdFQi96QXBCZ05WSFE0RUlnUWcKYVQxN2JhUVNKVXZMZEY1WTZVY0VtU1V2MGtKNTAvWkJaQS8vWFordzh1NHdDZ1lJS29aSXpqMEVBd0lEU1FBdwpSZ0loQU5lRzUzL3hxMHZHTXpaaVVwWG9RZGwySGZFeU9pVXl3bG43c3AvY0hTOGxBaUVBa3dWN09GckhOTnZECkJUT2szVnVneWxwcytOdWxXTGpOU0hXWTB2NTZaZDA9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"peer\"\n\t\t\t\t},\n\t\t\t\t\"admin_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVekNDQWZpZ0F3SUJBZ0lSQU9wamxIMFRsLzlteXYrSWZzRGVSSnN3Q2dZSUtvWkl6ajBFQXdJd2N6RUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhHVEFYQmdOVkJBb1RFRzl5WnpFdVpYaGhiWEJzWlM1amIyMHhIREFhQmdOVkJBTVRFMk5oCkxtOXlaekV1WlhoaGJYQnNaUzVqYjIwd0hoY05Nakl3TWpFM01UQXpNREF3V2hjTk16SXdNakUxTVRBek1EQXcKV2pCek1Rc3dDUVlEVlFRR0V3SlZVekVUTUJFR0ExVUVDQk1LUTJGc2FXWnZjbTVwWVRFV01CUUdBMVVFQnhNTgpVMkZ1SUVaeVlXNWphWE5qYnpFWk1CY0dBMVVFQ2hNUWIzSm5NUzVsZUdGdGNHeGxMbU52YlRFY01Cb0dBMVVFCkF4TVRZMkV1YjNKbk1TNWxlR0Z0Y0d4bExtTnZiVEJaTUJNR0J5cUdTTTQ5QWdFR0NDcUdTTTQ5QXdFSEEwSUEKQkVoVGc2cFRtZ214QnExM0VvRmx5SGozeWd5em9ydWZQb1J3MjlXUVdUNFluMFhTZnNmT1RUZHZRKzJlRThxSgo5WHNVenFmKzVkc2Y4dDF4SFpmR2wxU2piVEJyTUE0R0ExVWREd0VCL3dRRUF3SUJwakFkQmdOVkhTVUVGakFVCkJnZ3JCZ0VGQlFjREFnWUlLd1lCQlFVSEF3RXdEd1lEVlIwVEFRSC9CQVV3QXdFQi96QXBCZ05WSFE0RUlnUWcKYVQxN2JhUVNKVXZMZEY1WTZVY0VtU1V2MGtKNTAvWkJaQS8vWFordzh1NHdDZ1lJS29aSXpqMEVBd0lEU1FBdwpSZ0loQU5lRzUzL3hxMHZHTXpaaVVwWG9RZGwySGZFeU9pVXl3bG43c3AvY0hTOGxBaUVBa3dWN09GckhOTnZECkJUT2szVnVneWxwcytOdWxXTGpOU0hXWTB2NTZaZDA9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"admin\"\n\t\t\t\t},\n\t\t\t\t\"orderer_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVekNDQWZpZ0F3SUJBZ0lSQU9wamxIMFRsLzlteXYrSWZzRGVSSnN3Q2dZSUtvWkl6ajBFQXdJd2N6RUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhHVEFYQmdOVkJBb1RFRzl5WnpFdVpYaGhiWEJzWlM1amIyMHhIREFhQmdOVkJBTVRFMk5oCkxtOXlaekV1WlhoaGJYQnNaUzVqYjIwd0hoY05Nakl3TWpFM01UQXpNREF3V2hjTk16SXdNakUxTVRBek1EQXcKV2pCek1Rc3dDUVlEVlFRR0V3SlZVekVUTUJFR0ExVUVDQk1LUTJGc2FXWnZjbTVwWVRFV01CUUdBMVVFQnhNTgpVMkZ1SUVaeVlXNWphWE5qYnpFWk1CY0dBMVVFQ2hNUWIzSm5NUzVsZUdGdGNHeGxMbU52YlRFY01Cb0dBMVVFCkF4TVRZMkV1YjNKbk1TNWxlR0Z0Y0d4bExtTnZiVEJaTUJNR0J5cUdTTTQ5QWdFR0NDcUdTTTQ5QXdFSEEwSUEKQkVoVGc2cFRtZ214QnExM0VvRmx5SGozeWd5em9ydWZQb1J3MjlXUVdUNFluMFhTZnNmT1RUZHZRKzJlRThxSgo5WHNVenFmKzVkc2Y4dDF4SFpmR2wxU2piVEJyTUE0R0ExVWREd0VCL3dRRUF3SUJwakFkQmdOVkhTVUVGakFVCkJnZ3JCZ0VGQlFjREFnWUlLd1lCQlFVSEF3RXdEd1lEVlIwVEFRSC9CQVV3QXdFQi96QXBCZ05WSFE0RUlnUWcKYVQxN2JhUVNKVXZMZEY1WTZVY0VtU1V2MGtKNTAvWkJaQS8vWFordzh1NHdDZ1lJS29aSXpqMEVBd0lEU1FBdwpSZ0loQU5lRzUzL3hxMHZHTXpaaVVwWG9RZGwySGZFeU9pVXl3bG43c3AvY0hTOGxBaUVBa3dWN09GckhOTnZECkJUT2szVnVneWxwcytOdWxXTGpOU0hXWTB2NTZaZDA9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"orderer\"\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t\"Org2MSP\": {\n\t\t\t\"name\": \"Org2MSP\",\n\t\t\t\"root_certs\": [\n\t\t\t\t\"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVVENDQWZlZ0F3SUJBZ0lRWDhHQkcvWDg0V29LdmtOeUNaZnU5ekFLQmdncWhrak9QUVFEQWpCek1Rc3cKQ1FZRFZRUUdFd0pWVXpFVE1CRUdBMVVFQ0JNS1EyRnNhV1p2Y201cFlURVdNQlFHQTFVRUJ4TU5VMkZ1SUVaeQpZVzVqYVhOamJ6RVpNQmNHQTFVRUNoTVFiM0puTWk1bGVHRnRjR3hsTG1OdmJURWNNQm9HQTFVRUF4TVRZMkV1CmIzSm5NaTVsZUdGdGNHeGxMbU52YlRBZUZ3MHlNakF5TVRjeE1ETXdNREJhRncwek1qQXlNVFV4TURNd01EQmEKTUhNeEN6QUpCZ05WQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVApZVzRnUm5KaGJtTnBjMk52TVJrd0Z3WURWUVFLRXhCdmNtY3lMbVY0WVcxd2JHVXVZMjl0TVJ3d0dnWURWUVFECkV4TmpZUzV2Y21jeUxtVjRZVzF3YkdVdVkyOXRNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUUKRWs1RnpVQTFYYmtKZk5jRnJQSUxvLytKejhMSXdhcFM3U2FneUhBQ0ZhQTRuK0djcVk0Q3d0SDg3WnRmQnNMYgpvaUh5THVDam8reDhnNnAyREN5MXNxTnRNR3N3RGdZRFZSMFBBUUgvQkFRREFnR21NQjBHQTFVZEpRUVdNQlFHCkNDc0dBUVVGQndNQ0JnZ3JCZ0VGQlFjREFUQVBCZ05WSFJNQkFmOEVCVEFEQVFIL01Da0dBMVVkRGdRaUJDRFUKWHBQVHBJRkQySGkrT3VlZjRUUTBobDVWMHYrNnFyU014dnZjbjlpeHRqQUtCZ2dxaGtqT1BRUURBZ05JQURCRgpBaUVBNVo5Z0tqODFKVHg2U0wzR2hYWm12V0FtYTIzclE1OUpHTXRBR0IyQURjd0NJRlFoM3JCOGdkM0ZKM0hnCkdSVEgwakZlTGtGMURHdEdRRWJ0Vys2ektMZVUKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\"\n\t\t\t],\n\t\t\t\"crypto_config\": {\n\t\t\t\t\"signature_hash_family\": \"SHA2\",\n\t\t\t\t\"identity_identifier_hash_function\": \"SHA256\"\n\t\t\t},\n\t\t\t\"tls_root_certs\": [\n\t\t\t\t\"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNWekNDQWYyZ0F3SUJBZ0lRUityNWtGYnF6WUR2cFhJNzFPd0JYVEFLQmdncWhrak9QUVFEQWpCMk1Rc3cKQ1FZRFZRUUdFd0pWVXpFVE1CRUdBMVVFQ0JNS1EyRnNhV1p2Y201cFlURVdNQlFHQTFVRUJ4TU5VMkZ1SUVaeQpZVzVqYVhOamJ6RVpNQmNHQTFVRUNoTVFiM0puTWk1bGVHRnRjR3hsTG1OdmJURWZNQjBHQTFVRUF4TVdkR3h6ClkyRXViM0puTWk1bGVHRnRjR3hsTG1OdmJUQWVGdzB5TWpBeU1UY3hNRE13TURCYUZ3MHpNakF5TVRVeE1ETXcKTURCYU1IWXhDekFKQmdOVkJBWVRBbFZUTVJNd0VRWURWUVFJRXdwRFlXeHBabTl5Ym1saE1SWXdGQVlEVlFRSApFdzFUWVc0Z1JuSmhibU5wYzJOdk1Sa3dGd1lEVlFRS0V4QnZjbWN5TG1WNFlXMXdiR1V1WTI5dE1SOHdIUVlEClZRUURFeFowYkhOallTNXZjbWN5TG1WNFlXMXdiR1V1WTI5dE1Ga3dFd1lIS29aSXpqMENBUVlJS29aSXpqMEQKQVFjRFFnQUVUWlBZRkxmSUJMUUFkcDVmZ0NxSnZ3SjMyeDY5OG1LWEhibEY2cUR4bFVvMG5GUnRmbkhTU2NLZQplNXdmREtlM0pHS3pWek1RSDJQUlFTSVVHRGVKNWFOdE1Hc3dEZ1lEVlIwUEFRSC9CQVFEQWdHbU1CMEdBMVVkCkpRUVdNQlFHQ0NzR0FRVUZCd01DQmdnckJnRUZCUWNEQVRBUEJnTlZIUk1CQWY4RUJUQURBUUgvTUNrR0ExVWQKRGdRaUJDQm5CN25MTy9yczNHeWpQM09KaXAvYks3OHBDMURjSWtVQUg5T29IWjM4V1RBS0JnZ3Foa2pPUFFRRApBZ05JQURCRkFpQTQwUWNNYzlTdGZONnVVcFhhdGJQWUpyV21TekErdmdVS3MyS1hxQTNxa3dJaEFLeGh4UGVICkhicXRRK2x0bUFHT3JxUTd1RHM5Q0NtWS9WVFNDYmg4Z2E4RAotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\"\n\t\t\t],\n\t\t\t\"fabric_node_ous\": {\n\t\t\t\t\"enable\": true,\n\t\t\t\t\"client_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVVENDQWZlZ0F3SUJBZ0lRWDhHQkcvWDg0V29LdmtOeUNaZnU5ekFLQmdncWhrak9QUVFEQWpCek1Rc3cKQ1FZRFZRUUdFd0pWVXpFVE1CRUdBMVVFQ0JNS1EyRnNhV1p2Y201cFlURVdNQlFHQTFVRUJ4TU5VMkZ1SUVaeQpZVzVqYVhOamJ6RVpNQmNHQTFVRUNoTVFiM0puTWk1bGVHRnRjR3hsTG1OdmJURWNNQm9HQTFVRUF4TVRZMkV1CmIzSm5NaTVsZUdGdGNHeGxMbU52YlRBZUZ3MHlNakF5TVRjeE1ETXdNREJhRncwek1qQXlNVFV4TURNd01EQmEKTUhNeEN6QUpCZ05WQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVApZVzRnUm5KaGJtTnBjMk52TVJrd0Z3WURWUVFLRXhCdmNtY3lMbVY0WVcxd2JHVXVZMjl0TVJ3d0dnWURWUVFECkV4TmpZUzV2Y21jeUxtVjRZVzF3YkdVdVkyOXRNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUUKRWs1RnpVQTFYYmtKZk5jRnJQSUxvLytKejhMSXdhcFM3U2FneUhBQ0ZhQTRuK0djcVk0Q3d0SDg3WnRmQnNMYgpvaUh5THVDam8reDhnNnAyREN5MXNxTnRNR3N3RGdZRFZSMFBBUUgvQkFRREFnR21NQjBHQTFVZEpRUVdNQlFHCkNDc0dBUVVGQndNQ0JnZ3JCZ0VGQlFjREFUQVBCZ05WSFJNQkFmOEVCVEFEQVFIL01Da0dBMVVkRGdRaUJDRFUKWHBQVHBJRkQySGkrT3VlZjRUUTBobDVWMHYrNnFyU014dnZjbjlpeHRqQUtCZ2dxaGtqT1BRUURBZ05JQURCRgpBaUVBNVo5Z0tqODFKVHg2U0wzR2hYWm12V0FtYTIzclE1OUpHTXRBR0IyQURjd0NJRlFoM3JCOGdkM0ZKM0hnCkdSVEgwakZlTGtGMURHdEdRRWJ0Vys2ektMZVUKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"client\"\n\t\t\t\t},\n\t\t\t\t\"peer_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVVENDQWZlZ0F3SUJBZ0lRWDhHQkcvWDg0V29LdmtOeUNaZnU5ekFLQmdncWhrak9QUVFEQWpCek1Rc3cKQ1FZRFZRUUdFd0pWVXpFVE1CRUdBMVVFQ0JNS1EyRnNhV1p2Y201cFlURVdNQlFHQTFVRUJ4TU5VMkZ1SUVaeQpZVzVqYVhOamJ6RVpNQmNHQTFVRUNoTVFiM0puTWk1bGVHRnRjR3hsTG1OdmJURWNNQm9HQTFVRUF4TVRZMkV1CmIzSm5NaTVsZUdGdGNHeGxMbU52YlRBZUZ3MHlNakF5TVRjeE1ETXdNREJhRncwek1qQXlNVFV4TURNd01EQmEKTUhNeEN6QUpCZ05WQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVApZVzRnUm5KaGJtTnBjMk52TVJrd0Z3WURWUVFLRXhCdmNtY3lMbVY0WVcxd2JHVXVZMjl0TVJ3d0dnWURWUVFECkV4TmpZUzV2Y21jeUxtVjRZVzF3YkdVdVkyOXRNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUUKRWs1RnpVQTFYYmtKZk5jRnJQSUxvLytKejhMSXdhcFM3U2FneUhBQ0ZhQTRuK0djcVk0Q3d0SDg3WnRmQnNMYgpvaUh5THVDam8reDhnNnAyREN5MXNxTnRNR3N3RGdZRFZSMFBBUUgvQkFRREFnR21NQjBHQTFVZEpRUVdNQlFHCkNDc0dBUVVGQndNQ0JnZ3JCZ0VGQlFjREFUQVBCZ05WSFJNQkFmOEVCVEFEQVFIL01Da0dBMVVkRGdRaUJDRFUKWHBQVHBJRkQySGkrT3VlZjRUUTBobDVWMHYrNnFyU014dnZjbjlpeHRqQUtCZ2dxaGtqT1BRUURBZ05JQURCRgpBaUVBNVo5Z0tqODFKVHg2U0wzR2hYWm12V0FtYTIzclE1OUpHTXRBR0IyQURjd0NJRlFoM3JCOGdkM0ZKM0hnCkdSVEgwakZlTGtGMURHdEdRRWJ0Vys2ektMZVUKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"peer\"\n\t\t\t\t},\n\t\t\t\t\"admin_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVVENDQWZlZ0F3SUJBZ0lRWDhHQkcvWDg0V29LdmtOeUNaZnU5ekFLQmdncWhrak9QUVFEQWpCek1Rc3cKQ1FZRFZRUUdFd0pWVXpFVE1CRUdBMVVFQ0JNS1EyRnNhV1p2Y201cFlURVdNQlFHQTFVRUJ4TU5VMkZ1SUVaeQpZVzVqYVhOamJ6RVpNQmNHQTFVRUNoTVFiM0puTWk1bGVHRnRjR3hsTG1OdmJURWNNQm9HQTFVRUF4TVRZMkV1CmIzSm5NaTVsZUdGdGNHeGxMbU52YlRBZUZ3MHlNakF5TVRjeE1ETXdNREJhRncwek1qQXlNVFV4TURNd01EQmEKTUhNeEN6QUpCZ05WQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVApZVzRnUm5KaGJtTnBjMk52TVJrd0Z3WURWUVFLRXhCdmNtY3lMbVY0WVcxd2JHVXVZMjl0TVJ3d0dnWURWUVFECkV4TmpZUzV2Y21jeUxtVjRZVzF3YkdVdVkyOXRNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUUKRWs1RnpVQTFYYmtKZk5jRnJQSUxvLytKejhMSXdhcFM3U2FneUhBQ0ZhQTRuK0djcVk0Q3d0SDg3WnRmQnNMYgpvaUh5THVDam8reDhnNnAyREN5MXNxTnRNR3N3RGdZRFZSMFBBUUgvQkFRREFnR21NQjBHQTFVZEpRUVdNQlFHCkNDc0dBUVVGQndNQ0JnZ3JCZ0VGQlFjREFUQVBCZ05WSFJNQkFmOEVCVEFEQVFIL01Da0dBMVVkRGdRaUJDRFUKWHBQVHBJRkQySGkrT3VlZjRUUTBobDVWMHYrNnFyU014dnZjbjlpeHRqQUtCZ2dxaGtqT1BRUURBZ05JQURCRgpBaUVBNVo5Z0tqODFKVHg2U0wzR2hYWm12V0FtYTIzclE1OUpHTXRBR0IyQURjd0NJRlFoM3JCOGdkM0ZKM0hnCkdSVEgwakZlTGtGMURHdEdRRWJ0Vys2ektMZVUKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"admin\"\n\t\t\t\t},\n\t\t\t\t\"orderer_ou_identifier\": {\n\t\t\t\t\t\"certificate\": \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVVENDQWZlZ0F3SUJBZ0lRWDhHQkcvWDg0V29LdmtOeUNaZnU5ekFLQmdncWhrak9QUVFEQWpCek1Rc3cKQ1FZRFZRUUdFd0pWVXpFVE1CRUdBMVVFQ0JNS1EyRnNhV1p2Y201cFlURVdNQlFHQTFVRUJ4TU5VMkZ1SUVaeQpZVzVqYVhOamJ6RVpNQmNHQTFVRUNoTVFiM0puTWk1bGVHRnRjR3hsTG1OdmJURWNNQm9HQTFVRUF4TVRZMkV1CmIzSm5NaTVsZUdGdGNHeGxMbU52YlRBZUZ3MHlNakF5TVRjeE1ETXdNREJhRncwek1qQXlNVFV4TURNd01EQmEKTUhNeEN6QUpCZ05WQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVApZVzRnUm5KaGJtTnBjMk52TVJrd0Z3WURWUVFLRXhCdmNtY3lMbVY0WVcxd2JHVXVZMjl0TVJ3d0dnWURWUVFECkV4TmpZUzV2Y21jeUxtVjRZVzF3YkdVdVkyOXRNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUUKRWs1RnpVQTFYYmtKZk5jRnJQSUxvLytKejhMSXdhcFM3U2FneUhBQ0ZhQTRuK0djcVk0Q3d0SDg3WnRmQnNMYgpvaUh5THVDam8reDhnNnAyREN5MXNxTnRNR3N3RGdZRFZSMFBBUUgvQkFRREFnR21NQjBHQTFVZEpRUVdNQlFHCkNDc0dBUVVGQndNQ0JnZ3JCZ0VGQlFjREFUQVBCZ05WSFJNQkFmOEVCVEFEQVFIL01Da0dBMVVkRGdRaUJDRFUKWHBQVHBJRkQySGkrT3VlZjRUUTBobDVWMHYrNnFyU014dnZjbjlpeHRqQUtCZ2dxaGtqT1BRUURBZ05JQURCRgpBaUVBNVo5Z0tqODFKVHg2U0wzR2hYWm12V0FtYTIzclE1OUpHTXRBR0IyQURjd0NJRlFoM3JCOGdkM0ZKM0hnCkdSVEgwakZlTGtGMURHdEdRRWJ0Vys2ektMZVUKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\",\n\t\t\t\t\t\"organizational_unit_identifier\": \"orderer\"\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t\"orderers\": {\n\t\t\"OrdererMSP\": {\n\t\t\t\"endpoint\": [\n\t\t\t\t{\n\t\t\t\t\t\"host\": \"orderer0.example.com\",\n\t\t\t\t\t\"port\": 7050\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"host\": \"orderer1.example.com\",\n\t\t\t\t\t\"port\": 8050\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"host\": \"orderer2.example.com\",\n\t\t\t\t\t\"port\": 9050\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t}\n}\n```\n# endorsers 子命令\n显示网络中的背书节点信息，包括它们的`MSP ID`、`帐本高度`、`服务地址`和`身份证书`等。\n```shell\ndiscover --configFile discover_config.yaml \\\n    endorsers \\\n        --channel businesschannel \\\n        --chaincode hyperledger-fabric-contract-java-demo \\\n        --server peer0.org1.example.com:7051\n```\n> `discover_config.yaml` 文件可以使用 saveConfig 命令生成\n正常返回结果如下：\n```json\n[\n\t{\n\t\t\"Chaincode\": \"hyperledger-fabric-contract-java-demo\",\n\t\t\"EndorsersByGroups\": {\n\t\t\t\"G0\": [\n\t\t\t\t{\n\t\t\t\t\t\"MSPID\": \"Org1MSP\",\n\t\t\t\t\t\"LedgerHeight\": 9,\n\t\t\t\t\t\"Endpoint\": \"peer1.org1.example.com:8051\",\n\t\t\t\t\t\"Identity\": \"-----BEGIN CERTIFICATE-----\\nMIICKDCCAc6gAwIBAgIQYSi1/xYV9ghavadHl49VMDAKBggqhkjOPQQDAjBzMQsw\\nCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy\\nYW5jaXNjbzEZMBcGA1UEChMQb3JnMS5leGFtcGxlLmNvbTEcMBoGA1UEAxMTY2Eu\\nb3JnMS5leGFtcGxlLmNvbTAeFw0yMjAyMTcxMDMwMDBaFw0zMjAyMTUxMDMwMDBa\\nMGoxCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1T\\nYW4gRnJhbmNpc2NvMQ0wCwYDVQQLEwRwZWVyMR8wHQYDVQQDExZwZWVyMS5vcmcx\\nLmV4YW1wbGUuY29tMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEp42mYDwJKY11\\nntYoyWAwXtIyJiWH/9EB93jVPsFALzicKbibE1vSZlGl1mkb7M5wYCtfai11Bqqz\\nUFEz7e+DsqNNMEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0j\\nBCQwIoAgaT17baQSJUvLdF5Y6UcEmSUv0kJ50/ZBZA//XZ+w8u4wCgYIKoZIzj0E\\nAwIDSAAwRQIhAP+WvJIfhdpG/zkc1GrlTwZOppc0JZL9Nl0MfhJ4TMpiAiAfJ8kF\\njJeEYOonkKeZcRG77WoeB/+32BCUJNsSIwYyKA==\\n-----END CERTIFICATE-----\\n\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"MSPID\": \"Org1MSP\",\n\t\t\t\t\t\"LedgerHeight\": 9,\n\t\t\t\t\t\"Endpoint\": \"peer0.org1.example.com:7051\",\n\t\t\t\t\t\"Identity\": \"-----BEGIN CERTIFICATE-----\\nMIICKDCCAc+gAwIBAgIRAIc6sjio0hnYI+sBuebcN9gwCgYIKoZIzj0EAwIwczEL\\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\\ncmFuY2lzY28xGTAXBgNVBAoTEG9yZzEuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\\nLm9yZzEuZXhhbXBsZS5jb20wHhcNMjIwMjE3MTAzMDAwWhcNMzIwMjE1MTAzMDAw\\nWjBqMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\\nU2FuIEZyYW5jaXNjbzENMAsGA1UECxMEcGVlcjEfMB0GA1UEAxMWcGVlcjAub3Jn\\nMS5leGFtcGxlLmNvbTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABEHhWvyNC5Pp\\noJmF9pZzdVkKrLcjhS3ePhEIW/53NrnqZUB5QT6NRvo+rxqpIxAjMMZTTg2OewJd\\ng/crbYls2GyjTTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1Ud\\nIwQkMCKAIGk9e22kEiVLy3ReWOlHBJklL9JCedP2QWQP/12fsPLuMAoGCCqGSM49\\nBAMCA0cAMEQCICVqogpr/tI+sNTy8EYbkuuek4gw5Y/bNNI5cTZJpefKAiB8Zr2o\\nx1r62J3DV5qmF2jEAVRV8duwliiAkKW4q1xcNA==\\n-----END CERTIFICATE-----\\n\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"G1\": [\n\t\t\t\t{\n\t\t\t\t\t\"MSPID\": \"Org2MSP\",\n\t\t\t\t\t\"LedgerHeight\": 9,\n\t\t\t\t\t\"Endpoint\": \"peer0.org2.example.com:7051\",\n\t\t\t\t\t\"Identity\": \"-----BEGIN CERTIFICATE-----\\nMIICKTCCAc+gAwIBAgIRAJnk+wcTIbag0SNs4f2TAeIwCgYIKoZIzj0EAwIwczEL\\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\\ncmFuY2lzY28xGTAXBgNVBAoTEG9yZzIuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\\nLm9yZzIuZXhhbXBsZS5jb20wHhcNMjIwMjE3MTAzMDAwWhcNMzIwMjE1MTAzMDAw\\nWjBqMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\\nU2FuIEZyYW5jaXNjbzENMAsGA1UECxMEcGVlcjEfMB0GA1UEAxMWcGVlcjAub3Jn\\nMi5leGFtcGxlLmNvbTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABKtm2wfuhEqm\\nht8CqbV1CKAe7YRAao5ySPMCCswpXuX3Amw65L0pFLELhhFHvqoTmwTZOLNHeHCl\\nJoDQgoM5DUyjTTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1Ud\\nIwQkMCKAINRek9OkgUPYeL4655/hNDSGXlXS/7qqtIzG+9yf2LG2MAoGCCqGSM49\\nBAMCA0gAMEUCIQCB9+ASmx0BgYaN30Zeq+z3Gtj/q1yqrae2bD0dJspbMwIgcAFC\\nx9CQ52jYET7PbIqJOGPksb8amAPUAJXBOIxVJ7U=\\n-----END CERTIFICATE-----\\n\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"MSPID\": \"Org2MSP\",\n\t\t\t\t\t\"LedgerHeight\": 9,\n\t\t\t\t\t\"Endpoint\": \"peer1.org2.example.com:8051\",\n\t\t\t\t\t\"Identity\": \"-----BEGIN CERTIFICATE-----\\nMIICKDCCAc+gAwIBAgIRAMV4swH5jaaH+rQ13cBAzcwwCgYIKoZIzj0EAwIwczEL\\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\\ncmFuY2lzY28xGTAXBgNVBAoTEG9yZzIuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\\nLm9yZzIuZXhhbXBsZS5jb20wHhcNMjIwMjE3MTAzMDAwWhcNMzIwMjE1MTAzMDAw\\nWjBqMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\\nU2FuIEZyYW5jaXNjbzENMAsGA1UECxMEcGVlcjEfMB0GA1UEAxMWcGVlcjEub3Jn\\nMi5leGFtcGxlLmNvbTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABJQ2FIGAqO2J\\ngR9LzplbIGt2OXCHklyoQzl/o8OubrAy0hc88KqCFJQeH9gynDDrZM8eSyrlNWTO\\nf6ZXcoMMRbejTTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1Ud\\nIwQkMCKAINRek9OkgUPYeL4655/hNDSGXlXS/7qqtIzG+9yf2LG2MAoGCCqGSM49\\nBAMCA0cAMEQCICAY5hjEBFmhjJgOPNZx7oJIh5YlhPPMPuVnofwXR4ZCAiAVnOzZ\\nGzUNe7WFYhT4L2l7xLPl51FjigMoLYjG2Jt+ng==\\n-----END CERTIFICATE-----\\n\"\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t\"Layouts\": [\n\t\t\t{\n\t\t\t\t\"quantities_by_group\": {\n\t\t\t\t\t\"G0\": 1,\n\t\t\t\t\t\"G1\": 1\n\t\t\t\t}\n\t\t\t}\n\t\t]\n\t}\n]\n```\n\n# saveConfig 子命令\n该命令并不与`peer`节点打交道，它将由参数指定的变量信息保存为本地文件。这样用户在执行后续命令时可以指定该文件，而无须再指定各个参数值。需要通过`--configFile=CONFIGFILE`来指定所存放的参数信息文件路径。例如，保存指定的参数信息到本地的`discover_config.yaml`文件。\n```shell\ndiscover saveConfig --configFile discover_config.yaml \\\n    --peerTLSCA /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem \\\n    --userKey /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/msp/keystore/priv_sk \\\n    --userCert /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem \\\n    --MSP Org1MSP --tlsCert /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/tls/client.crt \\\n    --tlsKey /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin\\@org1.example.com/tls/client.key\n```\n`discover_config.yaml`文件：\n```yaml\nversion: 0\ntlsconfig:\n  certpath: /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/tls/client.crt\n  keypath: /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/tls/client.key\n  peercacertpath: /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem\n  timeout: 0s\nsignerconfig:\n  mspid: Org1MSP\n  identitypath: /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem\n  keypath: /etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/keystore/priv_sk\n```\n\n有了这个参数文件，当再使用同样的参数时就无须手动指定，直接使用`--configFile discover_config.yaml`即可。当然，用户也可以手动编写参数文件，但直接使用`saveConfig`命令自动生成将更加方便、高效。\n","tags":["服务发现"],"categories":["区块链","Fabric"]},{"title":"Fabric-configtxlator说明","url":"/2023/01/28/Fabric-configtxlator说明/","content":"\n# 作用\n因为无论配置交易文件`.tx`和初始区块文件`.block`都是二进制格式，用户无法直接编辑。`configtxlator`工具将这些配置文件在二进制格式和方便阅读的`json`格式之间进行转换。开发`configtxlator`工具是为了支持独立于`SDK`来进行重新配置。`configtxlator`工具被设计为提供一个API让任意SDK的用户都能够与之交互来更新配置。工具的名称是`configtx`和`translator`的拼接，意在传达该工具简单地在不同的等效数据之间进行转换。它不产生配置，也不提交或撤回配置。它不修改配置本身，只是简单地提供一些配置格式的不同的映射展现。\n\n本地命令行可使用命令：\n- 编码(proto_encode)\n- 解码(proto_decode)\n- 对比修改结构(compute_update)\n- 版本信息(version)\n\n远程`RESTful`路由:\n- 编码(proto_encode)\n- 解码(proto_decode)\n- 对比修改结构(compute_update)\n\n# 使用步骤\n- 使用SDK获取最新的配置\n- 然后使用`configtxlator`工具将二进制文件转换为可读的配置文件\n- 编辑可读的配置文件\n- 使用`configtxlator`工具计算更新的配置与原有配置的差异\n- 使用SDK提交配置以及签名\n---\n## 本地使用\n在`cli`中动态增加组织的时候，我们在命令行下直接使用`configtxlator proto_encode`和`configtxlator proto_decode`这种方式。\n\n`proto_encode`和`proto_decode`两个命令所拥有的参数是一样的，都需要以下几个参数：\n- `type`: 消息结构类型\n- `input`: 输入参数，encode时值为json格式，decode时值为proto格式的字节数组。\n- `output`: 输出结果，和输入相对，输出的是json或者proto格式。\n\ntype包含以下几种:\n| -- | -- |\n| type |  description |\n| -- | -- |\n| common.Block | 区块结构 |\n| common.Envelope | 带有效载荷和数字签名的数字信封，区块的数据部分就是序列化后的数字信封 |\n| common.ConfigEnvelope | 包含链配置的数字信封，内容包含ConfigUpdateEnvelope |\n| common.ConfigUpdateEnvelope | 提交给排序节点的配置数字信封 |\n| common.Config | ConfigEnvelope的配置部分 |\n| common.ConfigUpdate | ConfigUpdateEnvelope的一部分 |\n\n`compute_update`计算修改量，命令有以下几个参数\n- `original`: 原始proto\n- `updated`: 修改后的proto\n- `channel_id`: 通道id\n- `output`: 对比计算后的目标配置proto\n\n举例：将当前`channel`的块消息的配置`decode`为`json`文件\n```shell\nconfigtxlator proto_decode --input orderer.block --type common.Block\n```\n> 这里所使用的 orderer.block 文件请参考 [Fabric开发模式运行](http://www.blockchainof.com/2023/01/10/Fabric%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F%E8%BF%90%E8%A1%8C/) 2.4中所生成的创始块对应的文件。只要是区块数据，都可以使用这个命令进行解析。\n\n## 远程调用RESTful接口\n和本地调用类似，不详细介绍，直接举例吧：\n```shell\ncurl -X POST --data-binary @orderer.block \"${CONFIGTXLATOR_URL}/protolator/decode/common.Block\"\n```","tags":["二进制","JSON","转换"],"categories":["区块链","Fabric"]},{"title":"详解Golang中的init函数","url":"/2023/01/18/详解Golang中的init函数/","content":"# init函数说明\n初始化每个包后，会自动执行`init()`函数，并且执行优先级高于主函数的执行优先级。`init`函数通常用于：\n- 变量初始化\n- 检查/修复状态\n- 注册器\n- 运行计算\n  \n# 包初始化\n为了使用导入的程序包，必须首先对其进行初始化。初始化始终在单个线程中执行，并且以程序包依赖关系的顺序执行。这由`Golang`运行时系统控制，如下图所示：\n- 初始化导入的包（递归导入）\n- 计算并为块中声明的变量分配初始值\n- 在包中执行初始化函数\n\n![init调用顺序](详解Golang中的init函数/init函数执行顺序.jpg)\n\n# 示例代码\n```go\npackage main\n\nimport \"fmt\"\n\nvar _ int64=s()\n\nfunc init() {\n    fmt.Println(\"init function\")\n}\n\nfunc s() int64 {\n    fmt.Println(\"function s()\")\n    return 1\n}\n\nfunc main() {\n    fmt.Println(\"main\")\n}\n```\n执行结果：\n```\nfunction s()\ninit function\nmain\n```\n>即使程序包被多次导入，初始化也只执行1次\n\n## 特性\n### 无法引用\ninit函数不需要传入能数，也不需要返回任何值。与main相比，init没有声明，**因此无法引用**。\n```go\npackage main\n\nimport \"fmt\"\n\nfunc init() {\n    fmt.Println(\"init\")\n}\nfunc main() {\n    init()\n}\n```\n编译上述代码会报：`undefined: init`\n\n### 一个源文件可以包含多个init函数\n```go\npackage main\n\nimport \"fmt\"\n\nfunc init() {\n    fmt.Println(\"init1\")\n}\nfunc init() {\n    fmt.Println(\"init2\")\n}\nfunc main() {\n    fmt.Println(\"main\")\n}\n```\n执行结果：\n```\ninit1\ninit2\nmain\n```\n","tags":["init"],"categories":["Golang","基础"]},{"title":"《区块链原理、设计与应用》阅读摘录-0003","url":"/2023/01/16/《区块链原理、设计与应用》阅读摘录-0003/","content":"\n# 管理Fabric网络\n\n## 简介\n`Fabric`网络启动后，可以对网络中资源进行管理。要据资源类型的不同，目前主要包括3类操作：\n- 通道操作，包括对通道进行创建、加入通道、查询信息、更新配置等操作。\n- 节点管理，包括对`Peer`节点进行启动、重置、回滚、暂停、继续、重建DB和升级DB等操作。\n- 链码操作，包括链码的生命周期，如打包、安装、批准、提交、升级和调用链码等。\n\n另外，为了提高使用网络的效率，`Fabric`提供了事件通知机制（可以确认交易是否最终提交）和网络信息自动发现功能，并支持对网络进行在线升级。这些都为使用网络提供了便利。下面将具体进行介绍。\n\n## 使用通道\n### 通道操作命令\n命令行下可以使用`peer channel`命令（实现位于`internal/peer/channel`)进行通道操作，包括`create`, `fetch`, `join`, `list`, `update`, `getinfo`, `signconfigtx`等子命令。其中`create`, `fetch`, `update`命令主要与排序服务打交道；`join`, `list`, `getinfo`与`Peer`节点打交道；`signconfigtx`则为本地处理。\n\n各通道操作命令的功能如下表所示：\n![通道操作命令](《区块链原理、设计与应用》阅读摘录-0003/通道操作命令.jpeg)\n可以通过 peer channel<subcommand> --help 来查看具体的命令使用说明。\n\n### 命令选项\n`peer channel`命令支持的全局选项如下表：\n![peer channel命令的全局选项及说明](《区块链原理、设计与应用》阅读摘录-0003/命令选项.jpeg)\n\n客户端支持从环境变量中读取操作的默认`Peer`地址和身份信息，可以提前通过环境变量来指定：\n```shell\n#目标Peer\nCORE_PEER_ADDRESS=<peer endpoint>\n#连接目标Peer时信任的TLS根证书\nCORE_PEER_TLS_ROOTCERT_FILE=<peer tls ca path>\n#使用的客户端用户的MSP ID\nCORE_PEER_LOCALMSPID=<user msp id>\n#使用的客户端用户MSP路径\nCORE_PEER_MSPCONFIGPATH=<user msp path>\n```\n例如，下面的命令指定了对组织org1.example.com的peer0.org1.example.com节点执行相关操作，身份为组织的管理员Admin。代码如下：\n```shell\nCORE_PEER_ADDRESS=peer0.org1.example.com:7051 \\\nCORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt \\\nCORE_PEER_LOCALMSPID=\"Org1MSP\" \\\nCORE_PEER_MSPCONFIGPATH=/etc/hyperledger/fabric/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp \\\npeer channel <subcommand>\n```\n\n### 创建通道\n`create`子命令由拥有创建通道权限组织管理员身份来调用，在指定的排序服务上创建新的应用通道，需要提供服务地址。该子命令支持的选项包括：\n- -c, --channelID string, 创建通道名称\n- -f, --file string, 指定创建通道所用的交易文件\n- --outputBlock string, 创建通道成功后，将初始区块写到本地指定文件，默认为./.block。\n- -t, --timeout duration, 创建超时，默认为10秒。\n\n一般情况下，通过提前创建的通道配置文件来指定配置信息。如果不指定通道配置文件，则默认采用`SampleConsortium`配置和本地的`MSP`组织来构造配置交易结构。例如，利用事先创建的配置交易文件`channel.tx`来创建新的应用通道`businesschannel`, 命令代码如下：\n```shell\nAPP_CHANNEL=\"businesschannel\"\npeer channel create \\\n-o orderer:7050 \\\n-c ${APP_CHANNEL} \\\n-f ./channel.tx \\\n--timeout 30s\n```\n加入成功后，本地会产生该应用通道的初始区块文件`businesschannel.block`\n\n创建应用通道的主要过程如下图所示，需要与排序服务交互两次：发起创建通请求到系统通道，然后获取所创建应用通道的初始区块。\n![应用通道的创建](《区块链原理、设计与应用》阅读摘录-0003/应用通道的创建.jpeg)\n创建应用通道的实现流程\n![应用通道的创建的实现流程](《区块链原理、设计与应用》阅读摘录-0003/应用通道的创建的实现流程.jpeg)\n\n主要步骤包括：\n- 客户端调用`sendCreateChainTransaction()`,读取指定的配置交易文件（或利用默认配置），构造一个创建应用通道的配置交易结构，添加签名，封装为`Envelope`结构。其中指定通道头部类型为`CONFIG_UPDATE`,核心的数据为`ConfigUpdateEnvelope`结构。\n- 客户端发送配置交易到排序服务。\n- `Orderder`收到`CONFIG_UPDATE`消息后，检查指定的通道是否存在，若不存在，则创建通道，并构造该应用通道的初始区块。\n  - `Orderer`首先检查通道应用（Application）配置中的组织都在创建的联盟（Consortium)内, 配置到组织中。\n  - 之后从系统通道中获取`Orderder`相关的配置，并创建应用通道配置。应用配置对应的`mod_policy`为`Admins`。\n  - 根据`ChannelCreateionPolicy`指定策略，利用新创建应用通道的成员，进行权限校验。\n  - 接下来根据`CONFIG_UPDATE`消息的内容更新获取到的配置信息。所有配置发生变更后版本号都要更新。\n  - 创建签名`Proposal`消息（头部类型为`ORDERER_TRANSACTION`),进行共识，指定目标为系统通道。\n  - `Orderer`共识完成后提交交易，初始化对应本地结构，完成应用通道的创建过程。\n- 客户端从排序服务的`Deliver`服务获取应用通道的初始区块（具体过程类似`fetch`命令），请求类型为`DELIVER_SEEK_INFO`, 核心的数据为`SeekInfo`结构。\n- 客户端将收到的区块写入本地的`chainID+\".block\"`文件。这个文件后续会加入通道的节点中备用。\n\n其中，发往排序服务的`Envelope`消息结构定义如下：\n```go\n// github.com/hyperledger/fabric-protos-go/common/common.pb.go\ntype Envelope struct {\n  // 序列化的载荷数据，可以为任意内容\n  Payload []byte\n  // 载荷头部中的消息创建者对载荷的签名\n  Signature []byte\n}\n```\n`Envelope`的结构通常如下图所示，其中载荷包括头部和数据两部分。\n![Envelope的结构](《区块链原理、设计与应用》阅读摘录-0003/Envelope.jpeg)\n\n\n### 加入通道\n`join`子命令会将指定的`Peer`节点加入指定的应用通道中。需要提前拥有所加入应用通道的初始区块文件，并且只有属于通道的某个组织的管理员身份才可以成功执行该操作。加入通道命令主要通过调用`Peer`的配置系统链码进行处理。例如，通过如下命令可将`Peer`节点加入应用通道`businesschannel`中。该子命令支持`-b`, `--blockpath string`选项，用来指定通道初始区块文件路径。代码如下：\n```shell\npeer channel join \\\n-b ${APP_CHANNEL}.block\n\nPeer joined the channel!\n```\n加入应用通道的主要过程如下图，只与`Peer`节点打交道\n![加入应用通道](《区块链原理、设计与应用》阅读摘录-0003/加入应用通道.jpeg)\n\n主要步骤：\n- 客户端首先创建一个`ChaincodeSpec`结构，其`input`中的`Args`第一个参数是`cscc.JoinChain`（指定调用配置链码的操作），第二个参数为所加入通道的配置区块。\n- 利用`ChaincodeSpec`构造一个`ChaincodeInvocationSpec`结构。\n- 利用`ChaincodeInvocationSpec`，创建`Proposal`结构并进行签名，`channel`头部类型为`CONFIG`。\n- 客户端通过`gRPC`将`Proposal`签名后发给`Endorser`（所操作的Peer），调用\n  `ProcessProposal(ctx context.Context,in *SignedProposal,opts...grpc.CallOption)(*ProposalResponse,error)`方法进行处理。主要通过配置系统链码从配置区块中读取通道内已有成员的TLS CA根证书，加入本地的根证书信任结构中，并进行本地链结构的初始化工作。\n  ![加入应用通道-流程](《区块链原理、设计与应用》阅读摘录-0003/加入应用通道流程.jpeg)\n- 初始化完成后，即可收到来自通道内的`Gossip`消息等。\n\n其中，发送给`Peer`的`SignedProposal`消息十分常见，定义如下：\n```go\ntype SignedProposal struct {\n  // 字节码格式的提案内容\n  ProposalBytes []byte `protobuf:\"bytes,1,opt,name=proposal_bytes,json=proposalBytes,proto3\" json:\"proposal_bytes,omitempty\"`\n  // 对提案内容的签名，签名人需要为提案发起者（身份信息包括在提案头部中）\n  Signature     []byte `protobuf:\"bytes,2,opt,name=signature,proto3\" json:\"signature,omitempty\"`\n}\n```\n![SignedProposal结构](《区块链原理、设计与应用》阅读摘录-0003/SignedProposal.jpeg)\n\n`Peer`返回的`ProposalResponse`消息定义如下：\n```go\ntype ProposalResponse struct {\n  // 消息协议版本\n  Version int32 `protobuf:\"varint,1,opt,name=version\" json:\"version,omitempty\"`\n  // 消息创建时的时间戳\n  Timestamp *google_protobuf1.Timestamp `protobuf:\"bytes,2,opt,name=timestamp\" json:\"timestamp,omitempty\"`\n  // 返回消息，包括状态、消息、元数据载荷等\n  Response *Response `protobuf:\"bytes,4,opt,name=response\" json:\"response,omitempty\"`\n  // 数据载荷，包括提案的Hash值，和扩展的行动等\n  Payload []byte `protobuf:\"bytes,5,opt,name=payload,proto3\" json:\"payload,omitempty\"`\n  // 背书信息列表，包括背书者的证书，以及其对\"载荷+背书者证书\"的签名\n  Endorsement *Endorsement `protobuf:\"bytes,6,opt,name=endorsement\" json:\"endorsement, omitempty\"`\n}\n```\n**注意：执行加入通道命令成功返回，并不确保`Peer`最终能加入通道。**\n\n### 列出所加入的通道\n`list`子命令会列出指定的`Peer`节点已经加入的所有应用通道的列表。列出通道命令主要通过调用`Peer`的配置系统链码进行处理。\n例如通过如下命令，可以列出本地`Peer`节点已加入的所有应用通道。\n```shell\npeer channel list\n\nChannels peers has joined to:\n    businesschannel\n    businesschannel2\n```\n列出所加入的应用通道的主要过程如下，与加入过程类似，向`Peer`发送请求，注意类型是`ENDORSER_TRANSACTION`。\n![列出加入的所有通道-流程](《区块链原理、设计与应用》阅读摘录-0003/列出加入的所有通道-流程.jpeg)\n实现流程如下：\n![列出加入的所有通道-实现流程](《区块链原理、设计与应用》阅读摘录-0003/列出加入的所有通道-实现流程.jpeg)\n\n主要步骤：\n- 客户端首先创建一个`ChaincodeSpec`结构，其`input`中的`Args`第一个参数是`cscc.GetChannels`(指定调用配置链码的操作)。\n- 利用`ChaincodeSpec`构造一个`ChaincodeInvocationSpec`结构\n- 利用`ChaincodeInvocationSpec`创建`Proposal`结构并进行签名，`channel`头部类型为`ENDORSER_TRANSACTION`。\n- 客户端通过`gRPC`将`Proposal`发给`Endorser`（所操作的Peer），调用`ProcessProposal(ctx context.Context,in *SignedProposal,opts...grpc.CallOption)(*ProposalResponse,error)`方法进行处理。主要是通过配置系统链码查询本地链信息并返回。\n- 命令执行成功后，客户端会受到来自Peer端的回复消息，从其中提取出应用通道列表信息并输出。\n\n其中，比较重要的数据结构同样也包括ChaincodeSpec、ChaincodeInvocationSpec、Proposal等，注意channel头部类型以及ChaincodeSpec结构中的数据与加入通道的消息中的略有差异， 如下图：\n![SignedProposal结构](《区块链原理、设计与应用》阅读摘录-0003/SignedProposal1.jpeg)\n\n### 获取某区块\n`fetch`子命令会面向排序服务进行查询，获取通道的指定区块，并写入本地文件。命令如下：\n```shell\npeer channel fetch [outputfile] j[flags]\n```\n\n该子命令支持的选项包括：\n- --bestEffort 忽略遇到的错误，尽最大努力继续获取区块\n- -c, --channelID string 所获取的通道的名称\n例如，通过如下命令，可以获取已存在的`businesschannel`应用通道的初始区块，并保存到本地的`businesschannel.block`文件：\n```shell\npeer channel fetch oldest businesschannel1_0.block \\\n-c ${APP_CHANNEL} \\\n-o orderer:7050\n```\n```shell\npeer channel fetch 1 businesschannel1_1.block \\\n-c ${APP_CHANNEL} \\\n-o orderer:7050\n```\n获取区块的主要过程如下图：（以指定区块号为例），从排序服务获取指定的区块。\n![获取区块](《区块链原理、设计与应用》阅读摘录-0003/获取区块.jpeg)\n实现流程\n![获取区块实现流程](《区块链原理、设计与应用》阅读摘录-0003/获取区块实现流程.jpeg)\n主要步骤：\n- 客户端构造`SeekInfo`结构，该结构可以指定要获取的区块范围（如果获取配置区块，先从最新区块中解析配置区块号，然后通过区块号指定）。这里`Start`和`Stop`指定为目标区块。\n- 客户端利用`SeekInfo`结构，构造`Envelope`并进行签名，通过`deliverClient`经`gRPC`通道发给排序服务的`Deliver()`接口。\n- 从排序服务获取指定通道的区块后，写到本地文件中。\n\n其中，发往排序服务的`Envelope`结构如下：\n![Envelope结构](《区块链原理、设计与应用》阅读摘录-0003/Envelope1.jpeg)\n\n### 更新通道配置\n`update`子命令的执行过程与`create`命令类似，会向排序服务发起更新的配置交易请求。需要提前创建的通道更新配置交易文件指定配置信息，才可执行该命令。该子命令支持选项包括：\n- -c, --channelID string 所更新的通道名称。\n- -f, --file string 指定更新通道所用的交易文件\n\n如下操作来更新通道中的锚节点配置，首先利用`configtxgen`来创建锚节点配置更新文件，之后使用该更新文件对通道进行配置更新操作：\n```shell\nconfigtxgen \\\n -profile APP_CHANNEL_PROFILE \\\n -outputAnchorPeersUpdate ./update_anchors.tx \\\n -channelID ${APP_CHANNEL} \\\n -asOrg Org1MSP\n```\n```shell\npeer channel update \\\n -c ${APP_CHANNEL} \\\n -o orderer:7050 \\\n -f ./update_anchors.tx\n```\n\n更新应用通道的过程如下，与创建应用通道过程类似，直接发送交易更新请求给排序服务。\n![更新通道](《区块链原理、设计与应用》阅读摘录-0003/更新通道.jpeg)\n实现流程\n![更新通道实现流程](《区块链原理、设计与应用》阅读摘录-0003/更新通道实现流程.jpeg)\n\n主要步骤：\n- 客户端读取指定的配置交易文件，构造一个更新应用通道的配置交易信封结构，确认通道头部类型为`CONFIG_UPDATE`，通道ID存在且与命令行一致。\n- 客户端对更新信封结构进行签名，最终构造签名信封结构，通道头部类型为`CONFIG_UPDATE`。\n- 客户端通过`gRPC`发送配置交易到排序服务的`Broadcast`接口。\n- 排序服务收到`CONFIG_UPDATE`消息后，判断是配置消息后，进行配置相关处理。\n  - 调用`ProcessConf igUpdateMsg()`尝试接受配置，计算新配置结构（封装为`CONFIG`类型的信封结构）和对应的序号；\n  - 排序服务将新的配置信封结构发送给后端队列（如Raft或Kafka）进行排序，并响应客户端答复；\n  - 排序完成后，排序服务将新的配置交易存放到账本结构中等待Peer节点获取。\n- 客户端在发出请求后会接收到响应，但实际请求仍在排序服务异步进行。\n\n### 获取通道基本信息\n`getinfo`命令可以向指定的`Peer`节点获取某个通道的基本信息，包括高度、当前Hash、前导区块Hash等。该子命令支持选项`-c`,`--channelID string`，即所获取信息的通道的名称。例如，查询默认Peer节点上businesschannel通道的信息，代码如下：\n```shell\n$ peer channel getinfo -c ${APP_CHANNEL}\n\nBlockchain info: {\"height\":7,\"currentBlockHash\":\"bHlVT/swOzeJ8JaTXyhStu40QL4JBx ZBD695FISJf2o=\",\"previousBlockHash\":\"ViDfGewz/GRg3wDz68dtg4s9NNojtq3ciBB4VcpGBuk=\"} \n```\n\n获取通道基本信息的主要过程如下图所示，与列出所加入通道命令类似，通过调用Peer的cscc来查询。\n![获取通道基本信息](《区块链原理、设计与应用》阅读摘录-0003/获取通道信息.jpeg)\n实现流程\n![获取通道基本信息实现流程](《区块链原理、设计与应用》阅读摘录-0003/获取通道基本信息实现流程.jpeg)\n\n主要步骤：\n- 客户端首先创建一个`ChaincodeSpec`结构，其`input`中的`Args`第一个参数是cscc.Getchannels（指定调用配置链码的操作），第二个参数为所加入通道的配置区块。\n- 利用`ChaincodeSpec`构造一个`ChaincodeInvocationSpec`结构。\n- 利用`ChaincodeInvocationSpec`，创建`Proposal`结构并进行签名，`channel`头部类型为`ENDORSER_TRANSACTION`。\n- 客户端通过`gRPC`将`Proposal`签名后发给`Endorser`（所操作的`Peer`），调用`ProcessProposal(ctx context.Context,in*SignedProposal,opts...grpc.CallOption)(*ProposalResponse,error)`方法进行处理，主要通过配置系统链码获取对应账本的基本信息并返回客户端。\n\n### 对通道配置更新添加签名\n`signconfigtx`可以对本地的通道更新交易进行签名，属于客户端本地操作，不与`Peer`或`Orderer`打交道。该子命令支持选项`-f`,`--file string`，即指定所签名的通道配置更新交易文件。例如，对本地的通道配置更新添加签名，代码如下：\n```shell\npeer channel signconfigtx -f config_delta_env.pb \n```","categories":["区块链","Fabric","阅读摘录"]},{"title":"去中心化身份(DID)","url":"/2023/01/13/去中心化身份-DID/","content":"\n# 导读\n今天，我们的生活与使用的应用和服务的联系越来越紧密。使用电子商务进行网上购物，使用社交网络交流，使用电子邮件进行工作沟通，这样的例子不胜枚举。\n\n使用这些服务需要证明我们的身份和授权。虽然我们习惯于提供低级别的身份信息，如姓名和电子邮件地址，但其它服务可能需要一个高级别的身份，如驾驶执照。\n\n然而，目前的身份管理系统有几个缺陷：\n- 数据中心化，数据由服务提供者存储用户数据，存储在服务提供者的服务器中。\n- 安全风险，因为恶意行为者可能破坏服务器并窃取你的信息。\n\n去中心化身份改进了现有的身份管理标准，让用户对个人数据有更大的控制力。在一个去中心化的身份框架中，个人存储他们的身份信息，并选择与第三方分享哪些信息。因为在去中心化的标识符被存储在区块链网络中，它们是防篡改的，安全的，并且可以被任何人即时验证的。这减少了在服务器中存储身份信息的需要，使用户更容易无缝访问服务。\n\n本文详细解释了去中心化身份意味着什么，它是如何工作的，以及为什么它很重要。本文将涵盖一些关键的概念，如去中心化的标识符和去中心化的认证，并探索现有的去中心化身份项目。\n\n# 去中心化身份意味着什么？\n去中心化身份是一种新的身份和访问管理（IAM: Identity and Access Management）形式，不再是用户信息的集中存储。去中心化身份支持个人对其数据的控制，因此它也被称为自我主权身份（SSI: Self-Sovereign Identity)。\n\n通俗地说，去中心化身份允许你拥有自己的身份。那么，它在实践中是如何运作的呢？你的身份是独一无二用来描述你的属性和凭证的集合。一些身份标识可能是自我拥有的，如你的名字、生日、电子邮件地址、用户名。而有些可能是机构颁发的，如大学学位、驾驶执照或护照编号。\n\n在去中心化身份管理中，用户在`数字钱包`中存储凭证和个人信息。就像现实生活中的钱包一样，数字钱包保存着你的身份证明，如你的执照或身份证。\n\n去中心化身份标识将身份信息的存储在分布式的计算机系统中，如分布式账本或区块链（[这里有一个视频介绍](https://www.youtube.com/watch?v=gWfAIYXcyH4))，使用分布式帐本来保存身份要素，使其免于被篡改和盗窃。因此，即使你的身份信息是以电子格式记录的，它也不能被更改、窃取或删除。\n\n分布式账本固有的透明度使身份信息可以立即得到验证，而不一定要依赖发行者。\n\n下面是一个关于去中心化身份如何运作的简要说明：\n- 一个组织（交通警察大队）想给你（用户）发一个证书（驾驶执照）。你发送你的钱包地址，这是分布式账本或区块链上用于存储数据的特定位置。然后DMV(交通警察大队，下文使用简写DMV)用其私钥签署交易，将凭证发送到你的数字钱包。\n- 现在，你可以在任何时候分享这个凭证，以确定你的身份。例如在完成贷款申请时。使用一个受信任的工具，对方可以检查你的凭证的有效性。在这种情况下，该工具检查公钥和交易细节，以确认发行机构和发行日期。\n- 请注意，信息本身并不存储在区块链上。相反，区块链会生成一个不可改变的交易记录，看到信息从发行机构传递给你。这种`数字指纹`（也称为啥希值）对每个凭证来说都是独一无二的，可以可靠地证明你的所有权。\n\n去中心化身份生态系统中的各种参与者包括：\n- 用户：拥有和使用身份信息片段的个人。像我们这样的用户可以将各种身份信息保存在数字钱包中，并在需要时分享它们。\n- 凭证机构（Issuer）：向用户发放凭证的组织和机构。这可以是地方税务局，雇主，学术机构，以及任何可以发布身份信息的实体。\n- 验证人：需要身份信息来建立信任和授予服务访问权的第三方。例如，一家电商网店在允许你购买某些物品之前，可能需要你的年龄或公民身份证明。你提供的任何信息都需要得到适当的验证。\n  ![去中心化身份生态系统概述](去中心化身份-DID/1.png)\n\n# 去中心化身份是如何工作的？\n万维网联盟（W3C）将去中心化身份（DID）定义为一种可验证的、去中心化的数字身份形式。DID可以为任何实体创建，包括一个组织、个人，甚至一个设备。\n\nDID旨在由用户控制，存储在一个去中心化的架构中，如点对点网络或分布式账本，而不是一个中心化的登记薄。因此，DID在密码学上是安全的，可以抵御变化，并且可以在不依赖原始发行者的情况下进行验证。\n\n# 去中心化身份和可验证凭证\n可验证凭证是对DID的补充，为去中心化身份管理提供支持。W3C将可验证凭证定义为“可验证凭证代表发行人以防篡改和尊重隐私的方式做出的声明”。\n\n当一所大学颁发学术证书时，它是在“申领”接受者已经接受了一定时期的教育。同样，疫苗接种证书是申领人已经接受了疫苗。虽然这些申领已经作为实体文件存在，但在网上使用它们会带来一些问题。让我们想象一下，在KYC(了解你的客户)过程中，需要上传驾驶执照来验证你在KYC注册时的年龄。\n\n- 首先，服务提供者不能确认凭证的真实性。\n- 第二，你的私人信息现在被储存在多个服务器上，增加了身份被盗的风险。\n- 第三，你需要存存好执照的实体副本，因为如果实体执照丢失了，那么你就无法证明你的身份。\n  \n可验证凭证可从三个方面解决这些问题：\n- 使用`零知识证明`来证明申领数据的有效性而不透露私人信息\n- 使用公钥密码学来验证凭证发布机构\n- 将信息存储在可验证的数据注册处（区块链、分布式帐本）\n  \n使用我们最初的例子，你就不需要在KYC期间上传整个驾驶热照。相反，你可以只分享一个可验证凭证的链接。可验证凭证使用零知识证明来保护身份持有人的隐私。零知识证明有助于证明信息的真实性，而不会将整个信息透露给第三方。让我们用驾驶执照的例子来解释`ZK-proof`如何保护你的隐私。服务提供者实际上不会看到驾照上列出的你的出生日期。然而，该证书将通过公钥识别发行者（DMV)。由于DMV只向一定年龄范围内的个人发放执照，那么我们可以假设你的年龄是正确的。下图展示了可验证凭证（VC）如何工作。\n  ![可验证凭证（VC）如何工作](去中心化身份-DID/2.jpeg)\n  \n  可验证凭证存储在不可改变的区块链上，这意味着只要你有钱包和私钥，你就可以访问它们。它们不能被破坏、修改、偷窃或删除。更重要的是，它们不在发行机构的控制之下。\n\n  可验证凭证是去中心化身份管理的一个重要组成部分。有了可验证凭证，我们可以创建物理凭证的数字版本，并在网上使用它们，而不必披露超过必要的信息。第三方可以很容易地确认这些凭证的真实性，而不需要依赖发证机构。\n\n# 什么是去中心化认证？\nCOVID-19的大流行迅速加速了向数字生活方式的转变。现在，你可以选择在家里做银行业务、视频会议、通信和购物等事情。\n\n访问这些平台需要验证你的身份获得使用这些服务的许可以。例如，一个银行网站可能要求你提供一个电子邮件地址和密码。然而，传统的认证可能会有相当多的问题。你不仅要为不同的服务创建多个登录名，而且必须记住每一个登录名，否则有可能失去访问权。用户可能在多个网站上重复使用密码，以使在线认证更容易，但这只会增加身份被盗的风险。如果黑客窃取一个密码，他们可以轻易地在十几个不同的平台上冒充你。\n![基于密码认证的问题](去中心化身份-DID/3.jpeg)\n统一登录认证是目前的解决方案之一，旨在使在线认证更容易和更安全。在这里，一组实体同意依靠一个来源来获得身份信息。统一登录认证的一个很好的你例子是用你的Facebook或谷歌帐户（国内通常是微信）登录一个网站。\n\n但统一登录认证并不是银弹。你的身份信息仍然托管在一个中央服务器上（Facebook和Google），所以数据泄漏或身份盗窃的风险仍然存在。\n![统一登录认证系统依靠第三方服务来验证身份](去中心化身份-DID/4.jpeg)\n\n分布式认证是一个较新的概念，用户可以使用可验证凭证来访问在线服务。假设你想访问一个网上银行服务。你可以提交一个来自政府机构的可验证凭证来证明你的身份，而不是提交身份证件。这就不需要银行在授予访问权之前要求并存储你的信息。而且，你将来不需要一个账户来登录，因为服务提供者可以签发一个可验证凭证来进行持续验证。登录网站将佝连接你的数字钱包一样简单！\n![去中心化认证与传统认证](去中心化身份-DID/5.jpeg)\n\n# 为什么去中心化身份很重要？\n去中心化身份有望彻底改变我们的数据共享方式。以下是去中心化身份管理的一些好处：\n- 更容易认证\n---\n去中心化身份可以消除密码和恼人的多因素认证协议。有了无密码认证，使用在线服务变得更容易和更快，因为你不需要输入长密码。组织机构可以快速验证用户身份，而不强迫他们接受繁琐的KYC流程。贷款申请、政府注册、网站注册，所有这些都会更快发生，因为服务提供者可以通过第三方工具来验证你的身份。\n\n- 更好的数据安全\n---\n如前所述，许多组织要求新用户提交身份信息。这个也不是大问题，但是很多公司在保护用户数据方面被证明是草率的。现代数据中心是黑客的蜜罐，数据泄露已导致企业和消费者的巨大损失。\n\n一个去中心化身份框架消除了集中存储用户信息的需要。在处理个个身份信息（PII:Personally Identifiable Information）时，这一点尤为重要，例如你的医疗记录或信用卡信息。敏感的身份信息将被安全地存储在你的数字钱包中，允许你仅在必要时分享它。\n\n去中心化身份系统也将减少身份盗窃的案例，你的个人信息和凭证不会待在数据仓库里供黑客窃取。你也不需要密码来访问网站，所以网络钓鱼攻击将不可避免地失败。\n\n![去中心化身份可以减少数据泄漏和ID盗窃](去中心化身份-DID/6.jpeg)\n\n# 降低数据管理成本\n根据统计，全球企业在管理用户数据上的花费占其收入的4-7%，企业每年在数据库管理上花查岗数十亿美元，但这些资金肯定有更好的用途。\n\n去中心化身份让用户存储个人数据，为企业减轻负担。由于没有数据中心需要管理，服务提供者可以减少运营成本，并将资金重新投入到改善服务产品中。\n\n# 监管合规\n从欧盟到美国（国内也一样），监管机构正在收紧数据隐私法。不遵守用户隐私保护的企业，或将面临严厉制裁。\n\n去中心化身份框架免除了组织建立数据库来存储用户信息的责任。因此，公司可以更好地遵数据隐私法，避免引起监管机构的愤怒。\n\n# 更丰富的用户体验\n想一想为你使用的几十个服务管理不同的身份资料的困难。如果你可以在不同的平台上使用相同的身份，而不用担心重复创建新的登录信息，会怎么样？\n\n有了去中心化身份，一个可互操作的互联网，你可以在不同的网站上使用一个ID，这将成为现实。你将能够通过连接你的钱包在不同的服务之间无缝切换。\n\n![去中心化身份可以改善用户的在线体验](去中心化身份-DID/7.jpeg)\n\n# 个人对数据的所有权和控制权\n去中心化身份被描述为自我主权身份，因为它把个人数据的控制权放在个人手中。你的私人信息不会成为第三方的财产，被存在中心数据库中。\n\n在一个去中心化身份系统中，你决定哪些信息会被第三方知晓。零知识证明通过消除披露敏感信息的需要来进一步保护你的隐私。例如，你可以证明你的年龄，而无需向服务提供者展示你的地址或国籍。\n\n由于可验证凭证是数字化的，你的身份变得可携带。你不需要随身携带驾驶执照或免疫证书来证明你的疫苗接种情况。\n\n可验证凭证可以独立验证，所以你永远不必依赖发行人来验证你的信息。在任何时候，你的个人信息和凭证都在你的控制之下。\n![去中心化身份允许用户保留对凭证的控制](去中心化身份-DID/8.jpeg)\n\n# 加强组织和用户之间的信任\n信任是维系公司和客户之间关系的胶水。当双方相互信任时，可以建立互利的关系。\n\n然而，在我们今天的世界上，信任是一种稀缺的商品。消费者不相信公司不会收集他们的数据--而且可能是错误的管理。而组织则对可能进行身份欺诈的用户很警惕，因此他们在提供服务之前需要漫长的验证过程。\n\n去中心化身份可以解决这两个问题，并在用户和服务提供者之间创造前所未有的信任水平。\n\n加密安全和可验证凭证可以帮助公司验证用户身份，加速客户进入。而用户在与服务提供者交互时也不会担心数据泄露和身份被盗，这对每个人来说都是双赢。","tags":["DID","去中心化身份"],"categories":["区块链","应用"]},{"title":"《区块链原理、设计与应用》阅读摘录-0002","url":"/2023/01/13/《区块链原理、设计与应用》阅读摘录-0002/","content":"\n# 准备启动配置文件\n`Fabric`网络在启动之前，需要提前生成一些用于启动的配置文件，主要包括`MSP`相关身份文件`(msp/*)`、`TLS`相关身份文件`(tlsca/*)`、系统通道初始区块`(orderer.genesis.block)`、新建应用通道交易文件`(businesschannel.tx)`、锚节点配置更新交易文件`(Org1MSPanchors.tx和Org2MSPanchors.tx)`等。\n\n各启动配置文件的功能如下：\n![启动配置文件](《区块链原理、设计与应用》阅读摘录-0002/boostrap-config-files.jpeg)\n\n# 配置文件的生成过程\n## 生成组织关系和身份证书\n`Fabric`网络作为联盟链，需要多个成员组织共同维护。成员之间通过身份进行识别，网络通过身份来限制访问权限，因此各成员组织都需要提前准备对应的身份文件，并部署到其所拥有的节点和客户端上。\n\n用户可通过标准PKI服务（如果使用`Fabric CA`实现）或`OpenSSL`工具，手动生成各个实体的证书和私钥。`Fabric`项目还提供了`cryptogen`工具（基于`Go`语言`crypto`标准库）在本地生成，需要提前准备`crypto-config.yaml`配置文件。\n\n`crypto-config.yaml`配置文件的结构十分简单，支持定义两种类型`(OrdererOrgs和PeerOrgs)`的若干组织。每个组织中又可以定义多个节点`(Spec)`和用户`(User)`。\n\n本示例的`crypo-config.yaml`配置文件中，定义了一个`OrderderOrgs`类型的组织`example.com`，包括3个节点：两个`PeerOrgs`类型的组织`org1.example.com`和`org2.example.com`，分别包括2个节点和1个普通用户身份，文件内容如下：\n```yaml\nOrdererOrgs:\n  - Name: Orderer\n    Domain: example.com\n    CA:\n        Country: US\n        Province: California\n        Locality: San Francisco\n    Specs:\n      - Hostname: orderer0\n      - Hostname: orderer1\n      - Hostname: orderer2\nPeerOrgs:\n  - Name: Org1\n    Domain: org1.example.com\n    EnableNodeOUs: true\n    CA:\n        Country: US\n        Province: California\n        Locality: San Francisco\n    Template:\n      Count: 2\n    Users:\n      Count: 1\n  - Name: Org2\n    Domain: org2.example.com\n    EnableNodeOUs: true\n    CA:\n        Country: US\n        Province: California\n        Locality: San Francisco\n    Template:\n      Count: 2\n    Users:\n      Count: 1\n```\n\n使用该配置文件，通过如下命令可**生成**指定组织结构的身份文件，并存放到`crypto-config`目录下：\n```shell\ncryptogen generate \\\n    --config=./crypto-config.yaml \\\n    --output ./crypto-config\n```\n用户修改配置后，还可以通过`extend`子命令来**更新**`crypto-config`目录：\n```shell\ncryptogen extend \\\n    --config=./crypto-config.yaml \\\n    --input ./crypto-config\n```\n\n查看刚生成的`crypto-config`目录，结构如下：\n```\n$ tree -L 4 crypto-config\ncrypto-config\n|-- ordererOrganizations\n|   `-- example.com\n|       |-- ca\n|       |   |-- 293def0fc6d07aab625308a3499cd97f8ffccbf9e9769bf4107d6781f5e8072b_sk\n|       |   `-- ca.example.com-cert.pem\n|       |-- msp\n|       |   |-- admincerts/\n|       |   |-- cacerts/\n|       |   `-- tlscacerts/\n|       |-- orderers\n|       |   `-- orderer0.example.com/\n|       |   `-- orderer1.example.com/\n|       |   `-- orderer2.example.com/\n|       |-- tlsca\n|       |   |-- 2be5353baec06ca695f7c3b04ca0932912601a4411939bfcfd44af18274d5a65_sk\n|       |   `-- tlsca.example.com-cert.pem\n|       `-- users\n|           `-- Admin@example.com/\n`-- peerOrganizations\n    |-- org1.example.com\n    |   |-- ca\n    |   |   |-- 501c5f828f58dfa3f7ee844ea4cdd26318256c9b66369727afe8437c08370aee_sk\n    |   |   `-- ca.org1.example.com-cert.pem\n    |   |-- msp\n    |   |   |-- admincerts/\n    |   |   |-- cacerts/\n    |   |   `-- tlscacerts/\n    |   |-- peers\n    |   |   |-- peer0.org1.example.com/\n    |   |   `-- peer1.org1.example.com/\n    |   |-- tlsca\n    |   |   |-- 592a08f84c99d6f083b3c5b9898b2ca4eb5fbb9d1e255f67df1fa14c123e4368_sk\n    |   |   `-- tlsca.org1.example.com-cert.pem\n    |   `-- users\n    |       |-- Admin@org1.example.com/\n    |       `-- User1@org1.example.com/\n    `-- org2.example.com\n        |-- ca\n        |   |-- 86d97f9eb601868611eab5dc7df88b1f6e91e129160651e683162b958a728162_sk\n        |   `-- ca.org2.example.com-cert.pem\n        |-- msp\n        |   |-- admincerts/\n        |   |-- cacerts/\n        |   `-- tlscacerts/\n        |-- peers\n        |   |-- peer0.org2.example.com/\n        |   `-- peer1.org2.example.com/\n        |-- tlsca\n        |   |-- 4b87c416978970948dffadd0639a64a2b03bc89f910cb6d087583f210fb2929d_sk\n        |   `-- tlsca.org2.example.com-cert.pem\n        `-- users\n            |-- Admin@org2.example.com/\n            `-- User1@org2.example.com/\n```\n\n按照`crypto-config.yaml`中的定义，`crypto-config`目录下包括多级目录结构。其中`orderer-Organization`下包括构成`Orderer`组织（包括3个排序节点）的身份信息；`peerOrganizations`下为所有`Peer`节点组织（包括2个组织，4个节点）的相关身份信息。各个实体都含有`msp`和`tls`目录，分别包括对应的认证身份文件和`TLS`身份文件（公钥证书、私钥等）。\n\n对于排序节点来说，需要将`ordererOrganizations/example.com/Orderers/ordererX.example.com`目录下的内容（包括msp和tls两个子目录）**复制**到对应排序节点的配置路径(默认为/etc/hyperledger/fabric)下。\n\n对于`Peer`节点来说，则需要复制`peerOrganizations`下对应的身份证书文件。以`org1`的`peer0`为例，将`peerOrganizations/org1.example.com/peers/peer0.org1.example.com`目录下的内容（包括msp和tls）复制到Peer0节点的配置路径（默认为`/etc/hyperledger/fabric`)下。\n\n对于客户端节点来说，需要复制对应身份的用户目录，例如`Org1`的管理员身份为`peer-Organizations/org1.example.com/users/Admin@org1.example.com/`。\n\n## 生成系统通道初始区块\n系统通道是网络启动后的首个通道，负责管理网络整体配置。排序节点在启动后，可以使用初始区块来创建一个新的网络。\n\n初始区块中包括了排序服务的相关配置信息（如排序节点信息、块大小、最大通道数、默认策略等）和示例联盟配置。可以使用`configtxgen`工具生成。生成过程依赖`configtx.yaml`文件。\n\n`configtx.yaml`配置文件定义了整个网络中的相关配置和拓扑结构信息，用户可参考`sampleconfig/configtx.yaml`示例文件进行编写。这里采用如下内容：\n```yaml\nProfiles:\n    TwoOrgsOrdererGenesis:\n        <<: *ChannelDefaults\n        Capabilities:\n            <<: *ChannelCapabilities\n        Orderer:\n            <<: *OrdererDefaults\n            Organizations:\n                - *OrdererOrg\n            Capabilities:\n                <<: *OrdererCapabilities\n        Consortiums:\n            SampleConsortium:\n                Organizations:\n                    - *Org1\n                    - *Org2\n    TwoOrgsChannel:\n        Consortium: SampleConsortium\n        <<: *ChannelDefaults\n        Capabilities:\n            <<: *ChannelCapabilities\n        Application:\n            <<: *ApplicationDefaults\n            Organizations:\n                - *Org1\n                - *Org2\n            Capabilities:\n    <<: *ApplicationCapabilities\nOrganizations:\n    - &OrdererOrg\n        Name: OrdererOrg\n        SkipAsForeign: false\n        ID: OrdererMSP\n        MSPDir: msp\n        Policies:\n            Readers:\n                Type: Signature\n                Rule: \"OR('OrdererMSP.member')\"\n            Writers:\n                Type: Signature\n                Rule: \"OR('OrdererMSP.member')\"\n            Admins:\n                Type: Signature\n                Rule: \"OR('OrdererMSP.admin')\"\n        OrdererEndpoints:\n            - \"orderer0.example.com:7050\"\n            - \"orderer1.example.com:7050\"\n            - \"orderer2.example.com:7050\"\n    - &Org1\n        Name: Org1MSP\n        SkipAsForeign: false\n        ID: Org1MSP\n        MSPDir: msp\n        Policies:\n            Readers:\n                Type: Signature\n                Rule: \"OR('Org1MSP.admin', 'Org1MSP.peer', 'Org1MSP.client')\"\n            Writers:\n                Type: Signature\n                Rule: \"OR('Org1MSP.admin', 'Org1MSP.client')\"\n            Admins:\n                Type: Signature\n                Rule: \"OR('Org1MSP.admin')\"\n            Endorsement:\n                Type: Signature\n                Rule: \"OR('Org1MSP.member')\"\n        AnchorPeers:\n            - Host: peer0.org1.example.com\n              Port: 7051\n    - &Org2\n        ……\nCapabilities:\n    Channel: &ChannelCapabilities\n        V2_0: true\n    Orderer: &OrdererCapabilities\n        V2_0: true\n    Application: &ApplicationCapabilities\n        V2_0: true\nApplication: &ApplicationDefaults\n    ACLs: &ACLsDefault\n        _lifecycle/CheckCommitReadiness: /Channel/Application/Writers\n        _lifecycle/CommitChaincodeDefinition: /Channel/Application/Writers\n        _lifecycle/QueryChaincodeDefinition: /Channel/Application/Readers\n        _lifecycle/QueryChaincodeDefinitions: /Channel/Application/Readers\n        lscc/ChaincodeExists: /Channel/Application/Readers\n        lscc/GetDeploymentSpec: /Channel/Application/Readers\n        lscc/GetChaincodeData: /Channel/Application/Readers\n        lscc/GetInstantiatedChaincodes: /Channel/Application/Readers\n        qscc/GetChainInfo: /Channel/Application/Readers\n        qscc/GetBlockByNumber: /Channel/Application/Readers\n        qscc/GetBlockByHash: /Channel/Application/Readers\n        qscc/GetTransactionByID: /Channel/Application/Readers\n        qscc/GetBlockByTxID: /Channel/Application/Readers\n        cscc/GetConfigBlock: /Channel/Application/Readers        \n        peer/Propose: /Channel/Application/Writers\n        peer/ChaincodeToChaincode: /Channel/Application/Readers\n        event/Block: /Channel/Application/Readers\n        event/FilteredBlock: /Channel/Application/Readers\n    Organizations:\n    Policies:\n        LifecycleEndorsement:\n            Type: ImplicitMeta\n            Rule: \"MAJORITY Endorsement\"\n        Endorsement:\n            Type: ImplicitMeta\n            Rule: \"MAJORITY Endorsement\"\n        Readers:\n            Type: ImplicitMeta\n            Rule: \"ANY Readers\"\n        Writers:\n            Type: ImplicitMeta\n            Rule: \"ANY Writers\"\n        Admins:\n            Type: ImplicitMeta\n            Rule: \"MAJORITY Admins\"\n    Capabilities:\n        <<: *ApplicationCapabilities\nOrderer: &OrdererDefaults\n    OrdererType: etcdraft\n    Addresses:\n        - orderer0.example.com:7050\n        - orderer1.example.com:7050\n        - orderer2.example.com:7050\n    BatchTimeout: 2s\n    BatchSize:\n        MaxMessageCount: 500\n        AbsoluteMaxBytes: 10 MB\n        PreferredMaxBytes: 2 MB\n    MaxChannels: 0\n    EtcdRaft:\n        Consenters:\n            - Host: orderer0.example.com\n              Port: 7050\n              ClientTLSCert: crypto-config/ordererOrganizations/example.com/orderers/orderer0.example.com/tls/server.crt\n              ServerTLSCert: crypto-config/ordererOrganizations/example.com/orderers/orderer0.example.com/tls/server.crt\n            - Host: orderer1.example.com\n              Port: 7050\n              ClientTLSCert: crypto-config/ordererOrganizations/example.com/orderers/orderer1.example.com/tls/server.crt\n              ServerTLSCert: crypto-config/ordererOrganizations/example.com/orderers/orderer1.example.com/tls/server.crt\n            - Host: orderer2.example.com\n              Port: 7050\n              ClientTLSCert: crypto-config/ordererOrganizations/example.com/orderers/orderer2.example.com/tls/server.crt\n              ServerTLSCert: crypto-config/ordererOrganizations/example.com/orderers/orderer2.example.com/tls/server.crt\n        Options:\n  TickInterval: 500ms\n            ElectionTick: 10\n            HeartbeatTick: 1\n            MaxInflightBlocks: 5\n            SnapshotIntervalSize: 16 MB\n    Organizations:\n    Policies:\n        Readers:\n            Type: ImplicitMeta\n            Rule: \"ANY Readers\"\n        Writers:\n            Type: ImplicitMeta\n            Rule: \"ANY Writers\"\n        Admins:\n            Type: ImplicitMeta\n            Rule: \"MAJORITY Admins\"\n        BlockValidation:\n            Type: ImplicitMeta\n            Rule: \"ANY Writers\"\n    Capabilities:\n        <<: *OrdererCapabilities\nChannel: &ChannelDefaults\n    Policies:\n        Readers:\n            Type: ImplicitMeta\n            Rule: \"ANY Readers\"\n        Writers:\n            Type: ImplicitMeta\n            Rule: \"ANY Writers\"\n        Admins:\n            Type: ImplicitMeta\n            Rule: \"MAJORITY Admins\"\n    Capabilities:\n        <<: *ChannelCapabilities\n```\n\n该配置文件中定义了两个模板：`TwoOrgsOrderGenesis`和`TwoOrgsChannel`。其中前者定义了系统通道配置，可以用来创建系统通道的初始区块文件；后者定义了应用通道配置，可以用来新建应用通道。排序服务的共识类型指定为`Raft`模式。\n\n通过如下命令指定使用`TwoOrgsOrdererGenesis模板，来生成系统通道初始化区块文件：\n```shell\nexport SYS_CHANNEL=testchainid\nexport ORDERER_GENESIS_PROFILE=TwoOrgsOrdererGenesis\nexport ORDERER_GENESIS=orderer.genesis.block\nconfigtxgen \\\n    -configPath ./ \\\n    -channelID ${SYS_CHANNEL} \\\n    -profile ${ORDERER_GENESIS_PROFILE} \\\n    -outputBlock ${ORDERER_GENESIS}\n```\n将所生成的初始区块文件复制到排序节点`ORDERER_GENERAL_BOOTSTRAPFILE`路径（默认为`/etc/hyperledger/fabric`)下，供启动排序节点使用。\n\n# 生成新建应用通道交易\n新建应用通道需要先生成配置交易文件，其中包括属于该通道的组织结构信息，这些信息会写入该应用通道的初始区块中。\n\n同样需要`configtx.yaml`配置文件和`configtxgen`工具，注意这里使用`TwoOrgsChannel`模板。\n\n采用如下命令来生成新建通道交易文件，通道中包括两个初始成员：`Org1`和`Org2`:\n```shell\nexport APP_CHANNEL=businesschannel\nexport APP_CHANNEL_PROFILE=TwoOrgsChannel\nconfigtxgen \\\n    -configPath ./ \\\n    -channelID ${APP_CHANNEL} \\\n    -profile ${APP_CHANNEL_PROFILE} \\\n    -outputCreateChannelTx ${APP_CHANNEL}.tx\n```\n\n> 注意:\n> 状态数据库如果选择`CouchDB`类型，应用通道名称只能包括小写的ASCII字符、点或中划线，并且首字符为字母，总长度不超过249个字符。该限制详情可参考`FAB-2487`。\n\n# 生成锚节点配置更新文件\n锚节点用来辅助发现通道内多个组织之间的节点，修改锚节点需要发送更新通道配置交易。\n\n同样需要`configtx.yaml`配置文件，为每个组织都生成配置文件，注意需要指定对应的组织身份。`outputAnchorPeersUpdates`子命令在2.x版本中计划弃用，届时用户需要使用通道配置更新命令完成：\n```shell\nexport UPDATE_ANCHOR_ORG1_TX=Org1MSPanchors.tx\nexport UPDATE_ANCHOR_ORG2_TX=Org2MSPanchors.tx\nconfigtxgen \\\n    -configPath ./ \\\n    -channelID ${APP_CHANNEL} \\\n    -profile ${APP_CHANNEL_PROFILE} \\\n    -asOrg Org1MSP \\\n    -outputAnchorPeersUpdate ${UPDATE_ANCHOR_ORG1_TX}\n\nconfigtxgen \\\n    -configPath ./ \\\n    -channelID ${APP_CHANNEL} \\\n    -profile ${APP_CHANNEL_PROFILE} \\\n    -asOrg Org2MSP \\\n    -outputAnchorPeersUpdate ${UPDATE_ANCHOR_ORG2_TX}\n```\n\n# 启动排序节点\n首先，检查配置路径（默认为`/etc/hyperledger/fabric`）下所需文件是否就绪：\n- 配置文件`orderer.yaml`（可参考sampleconfig/orderer.yaml), 包括排序节点配置信息。\n- msp文件目录、tls文件目录，用来存放身份证书文件和私钥文件。\n- 系统通道初始区块文件，用来启动系统通道。\n\n排序节点配置可通过配置文件或环境变量方式指定，部分常见配置如下：\n![排序节点配置](《区块链原理、设计与应用》阅读摘录-0002/orderer-config.jpeg)\n\n之后，用户可以采用如下命令来启动排序节点。启动成功后可以看到本地输出开始提供服务的消息，此时`Orderer`采用指定的初始区块文件成功创建了系统通道，代码如下：\n```\n$ orderer start\n[orderer/common/server] prettyPrintStruct -> INFO 002 Orderer config values:\n    General.LedgerType = \"file\"\n    General.ListenAddress = \"0.0.0.0\"\n    General.ListenPort = 7050\n    General.TLS.Enabled = true\n...\n[orderer/common/server] Start -> INFO 007 Beginning to serve requests\n...\n```\n\n# 启动Peer节点\n首先，检查配置路径（默认为`/etc/hyperledger/fabric)下所需文件是否就绪：\n- 配置文件`core.yaml`（可以参考sampleconfig/core.yaml),指定Peer节点配置。\n- msp文件目录、tls文件目录，用于存放身份证书文件和私钥文件。\n\nPeer节点配置可通过配置文件或环境变量方式进行指定，常见设置如下：\n![Peer节点配置](《区块链原理、设计与应用》阅读摘录-0002/peer-config.jpeg)\n\n配置完成后，用户可以采用如下命令在多个服务器上分别启动Peer服务：\n```\n$ peer node start\nUTC [ledgermgmt] initialize -> INFO 002 Starting peer:\n  Version: 2.0.0\n  Commit SHA: development build\n  Go version: go1.13.4\n  OS/Arch: linux/amd64\n  Chaincode:\n    Base Docker Namespace: hyperledger\n    Base Docker Label: org.hyperledger.fabric\n    Docker Namespace: hyperledger\"\n...\nUTC [nodeCmd] serve -> INFO 01e Started peer with ID=[name:\"peer0.org1.\nexample.com\" ], network ID=[dev], address=[peer0.org1.example.com:7051]\n...\n```\n启动成功后可以看到本地输出的日志消息。\n此时，Peer节点已经启动起来，会尝试通过gossip发现邻居节点。\n\n# 创建通道\n网络启动后只有排序节点维护的系统通道，还未创建应用通道。客户端需要发送请求给Orderer创建应用通道，以让Peer节点加入使用。默认情况下，只有联盟中成员组织的管理员身份才可以创建应用通道。\n\n例如，使用Org1的**管理员身份**来创建新的应用通道，需要指定msp的ID、msp文件所在路径、排序服务地址、应用通道名称和新建通道交易文件，如果启用了TLS,还需要指定排序服务的TLSCA的证书位置，示例代码如下：\n```shell\nAPP_CHANNEL=businesschannel\nTIMEOUT=30\nCORE_PEER_LOCALMSPID=\"Org1MSG\" \\\nCORE_PEER_MSPCONFIGPATH=/etc/hyperledger/fabric/crypto-config/peerOrgnizations/org1.example.com/users/Admin@org1.example.com/msg \\\npeer channel create \\\n    -o orderer0.example.com:7070 \\\n    -c ${APP_CHANNEL} \\\n    -f ./$APP_CHANNEL.tx \\\n    --timeout \"${TIMEOUT}s\" \\\n    --tls \\\n    --cafile /etc/hyperledger/fabric/crypto-config/ordererOrganizations/example.com/orderers/orderer0.example.com/msp/tlscacerts/tlsca.example.com-cert.pem\n```\n通道创建成功后，会在本地生成其初始区块文件（businesschannel.block），其中带有通道的初始配置信息和排序服务信息等。只有拥有该文件的Peer节点可能加入对应的通道中。\n\n# 加入通道\n应用通道的成员组织的Peer都可以加入通道中。在客户端使用**管理员身份**依次让组织Org1和Org2中的所有节点都加入新的应用通道。操作需要指定所操作的Peer的地址，以及通道的初始区块。\n\n以Org1中的Peer0节点为例，可以执行如下操作：\n```shell\nCORE_PEER_LOCALMSPID=\"Org1MSP\" \\\nCORE_PEER_MSPCONFIGPATH=/etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp \\\nCORE_PEER_ADDRESS=peer0.org1.example.com:7051 \\\npeer channel join \\\n-b ${APP_CHANNEL}.block\n```\n\n此时，所操作的Peer（如果成为组织的Gossip Leader）会自动连接到应用通道指定的排序服务，开始接收区块。\n\n# 更新锚节点配置\n锚节点（作为组织内成员代表）负责与其它组织节点进行信息交换。通道配置内会记录各组织的锚节点列表信息，Peer通过访问其它组织的锚节点来获取其它组织内的Peer信息。\n\n使用通道配置更新文件，组织管理员可以更新通道指定配置。例如，在客户端使用Org1的管理员身份来更新锚节点，如下：\n```shell\nCORE_PEER_LOCALMSPID=\"Org1MSP\" \\\nCORE_PEER_MSPCONFIGPATH=/etc/hyperledger/fabric/crypto-config/peerOrganizations/org1.example.com/users/Amdin@org1.example.com/msp \\\npeer channel update \\\n-o orderer0.example.com:7050 \\\n-c ${APP_CHANNEL} \\\n-f ${UPDATE_ANCHOR_ORG1_TX} \\\n--tls \\\n--cafile /etc/hyperledger/fabric/crypto-config/ordererOrganizations/example.com/orderers/orderer0.example.com/msp/tlscacerts/tlsca.example.com-cert.pem\n```\n\n锚节点配置更新后，同一通道内不同组织之间的Peer也可以进行Gossip通信，共同维护通道帐本。后续，用户可以通过智能合约使用通道帐本。","tags":["Hyperledger","Fabric","启动配置文件"],"categories":["区块链","Fabric","阅读摘录"]},{"title":"《区块链原理、设计与应用》阅读摘录-0001","url":"/2023/01/12/《区块链原理、设计与应用》阅读摘录-0001/","content":"\n# 网络基本结构\nFaric网络中存在四种不同角色的服务节点，彼此协作完成整个区块链系统的记账功能。\n- 背书节点(Endorser Peer):一些特殊的Peer节点，对交易提案（Transaction Proposal）进行检查，执行智能合约，计算交易执行结果（读写集合）并对其进行背书。\n- 记帐节点(Committer Peer):负责维护账本的Peer节点，检查排序后交易结果的合法性，并更新到本地账本。目前所有Peer默认都是记账节点。\n- 排序节点(Orderer):负责接收交易，并对网络中所有交易进行排序，整理为区块结构。记账节点会从排序节点拉取新区块并提交到本地账本。\n- 证书节点(CA):提供标准的PKI服务，负责对网络中所有的证书进行管理，包括签发和撤销。不参与网络中的交易过程。\n\n角色划分是Fabric设计的一个特色。根据性能和安全需求，不同的节点可以由不同组织分别管理，共同构建联盟链。\n\n此外，网络支持多个账本绑定对应通道(Channel)。每个通道内的成员可以共享账本，不同通道的账本彼此隔离。客户端可以向通道发送交易，经过共识后被通道内的Peer节点接收并更新到本地账本。\n\n# Fabric中的配置辅助工具\n- cryptogen(本地生成组织结构和身份文件)\n- configtxgen(生成配置区块和配置交易)\n- configtxlator(解析转换配置信息)\n- discover(拓扑探测)\n- idemixgen(Idemix证书生成)\n\n# fabric项目相关的docker镜像\n这些镜像都在hyperledger仓库中，它们之间的相互依赖关系如下图：\n![Fabric Docker 镜像](《区块链原理、设计与应用》阅读摘录-0001/FabricDockerImages.jpeg)\n\n根据不同用途，Docker镜像可以大致分为三类：核心镜像、辅助镜像和第三方镜像。\n- 核心镜像\n   \n   提供Fabric网络运行的核心功能，目前包括`fabric-peer`、`fabric-orderer`、`fabric-ca`、`fabric-baseos`、`fabric-ccenv`、`fabric-javaenv`、`fabric-nodeenv`共7个镜像，如下图：\n   ![images-01](《区块链原理、设计与应用》阅读摘录-0001/images-01.jpeg)\n   ![images-02](《区块链原理、设计与应用》阅读摘录-0001/images-02.jpeg)\n- 辅助镜像\n  \n  提供支持功能，目前包括`fabric-baseimage`、`fabric-tools`镜像，如下图\n  ![images-03](《区块链原理、设计与应用》阅读摘录-0001/images-03.jpeg)\n\n- 第3方镜像\n  \n  主要是由一些第3方开源软件提供支持功能，目前包括`fabric-couchdb`、`fabric-kafka`、`fabric-zookeeper`3个镜像。如下图：\n  ![images-04](《区块链原理、设计与应用》阅读摘录-0001/images-04.jpeg)\n\n# 从源码生成Docker镜像\n可以通过如下命令在本地快速生成`fabric-baseos`、`fabric-peer`、`fabric-orderer`、`fabric-ccenv`、`fabric-tools`等多个Docker镜像：\n```shell\nmake docker\n```\n\n# 用本地方式启动Fabric网络\n启动一个Fabric网络主要包括如下步骤：\n- **规划初始网络拓扑**。根据联盟的需求规划拓扑信息，包括联盟成员、排序服务集群、应用通道初始成员等；\n- **准备启动配置文件**。包括网络中组织结构和对应的身份证书（可使用`cryptogen`工具或`fabric-ca`完成）、系统通道的初始配置区块文件（可使用`configtxgen`工具完成）。\n- **启动排序节点**。使用系统通道的初始区块文件启动排序服务，排序服务启动后自动按照指定配置创建系统通道。\n- **启动Peer节点**。不同的组织按照预置角色分别启动Peer节点。\n- **创建通道**。客户端使用新建应用通道的配置更新交易文件，向系统通道发送交易，创建新的应用通道。\n- **加入通道**。`Peer`节点利用初始区块加入所创建的应用通道。\n主要步骤如下图：\n![启动步骤](《区块链原理、设计与应用》阅读摘录-0001/bootstrap.jpeg)\n\n# 规划初始网络拓扑\n示例网络拓扑如下图所示，包括3个`Orderer`节点和4个`Peer`节点，以及1个客户端操作节点（负责生成相关启动文件，在网络启动后作为客户端执行命令）。\n\n其中，`Orderer`服务采用`Raft`模式，所有节点都加入新建的`businesschannel`中。4个`Peer`节点分属两个组织:`Org1`和`Org2`，也都是应用通道成员。每个组织中的peer0节点作为锚节点负责与其它组织节点分享信息。\n![示例拓扑](《区块链原理、设计与应用》阅读摘录-0001/topology.jpeg)\n","tags":["Hyperledger","Fabric","网络结构"],"categories":["区块链","Fabric","阅读摘录"]},{"title":"Fabric开发模式运行","url":"/2023/01/10/Fabric开发模式运行/","content":"基本抄袭自[Goland/Vscode调试Hyperledger Fabric 2.0源码、单机网络（傻瓜式调试）](https://blog.51cto.com/u_14834727/3031542)\n# 引言\nfabric代码修改后，想要在本地调试，搭建调试环境觉得都挺麻烦的。官方文档结合谷歌，记录一下`solo`模式的一个方案。目前官方最新版的fabric代码已经不支持`solo`模式了。所以，本文适合支持`solo`模式的`Fabric`版本。\n\n## 目标：\n- 启动一个`peer`和一个`orderer`\n- 使用fabric/sampleconfig下的配置文件（一个组织SampleOrg）,生成创世块和通道配置\n- 创建通道`myc`, `peer` 加入通道\n- 用`fabric-sample`中的`fabcar`作为例子，打包、安装、审核、提交链码，再初始化账本，创建一辆`car`,查询所有`car`。\n- 所有命令执行都使用`debug`模式，无需手动输入任何`peer`命令。\n- 可调试链码\n\n# 准备工作\n\n## fabric代码\n拉取代码后，在代码目录下创建配置文件目录\n    ```shell\n    cd fabric\n    mkidr -p dev-network/config\n    ```\n## 拷贝配置文件、外部构建程序、链码demo\n    ```shell\n    cp -r sampleconfig/* dev-network/\n    cp -r integration/externalbuilders dev-network/\n    cp -r $GOPATH/src/github.com/hyperledger/fabric-samples/chaincode $GOPATH/src/github.com/hyperledger/fabric/dev-network/\n    ```\n## 拷贝完后dev-network目录结构如下:\n    ```\n    ├── chaincode\n    │   ├── abac\n    │   ├── abstore\n    │   ├── fabcar\n    │   ├── marbles02\n    │   ├── marbles02_private\n    │   └── sacc\n    ├── config\n    ├── configtx.yaml\n    ├── core.yaml\n    ├── externalbuilders\n    │   ├── binary\n    │   └── golang\n    ├── msp\n    │   ├── admincerts\n    │   ├── cacerts\n    │   ├── config.yaml\n    │   ├── keystore\n    │   ├── signcerts\n    │   ├── tlscacerts\n    │   └── tlsintermediatecerts\n    └── orderer.yaml\n    ```\n## 修改peer配置文件dev-network/core.yaml\n找到fileSystemPath，修改存储路径\n```yaml\npeer:\n    fileSystemPath: $GOPATH/src/github.com/hyperledger/fabric/dev-network/production/peer\n```\n\n使用docker跑链码配置（不支持调试chaincode）：peer会调用docker api执行构建、运行链码等操作。\n找到vm,修改endpoint和docker配置（请根据实际情况，修改成你自己docker配置）**这个没验证过**\n```yaml\nvm:\n    endpoint: tcp://192.168.99.100:2376\n    docker:\n        tls:\n            enabled: true\n            ca:\n                file: /Users/USER/.docker/machine/machines/demo/ca.pem\n            cert:\n                file: /Users/USER/.docker/machine/machines/demo/cert.pem\n            key:\n                file: /Users/USER/.docker/machine/machines/demo/key.pem\n```\n\n外部跑链码配置（支持调试chaincode)\n```yaml\nchaincode:\n    externalBuilders:\n    - path: $GOPATH/src/github.com/hyperledger/fabric/dev-network/externalbuilders/golang\n    name: external-golang\n    environmentWhitelist:\n    - GOPROXY\n    - GOCACHE\n    - GOPATH\n```\n\n>注意：package的时候label标签需要以-external结尾，eg:--label fabcarv1-external，如果需要修改默认的规则，请修改dev-network/externalbuilders/golang/bin/detect脚本\n```shell\nif [[ \"$(jq -r .label \"$2/metadata.json\")\" != *-external* ]]; then\n    >&2 echo \"only golang chaincode named with an '-external' suffix is supported\"\n    exit 1\nfi\n```\n\n## 修改orderer配置文件dev-network/orderer.yaml\n\n    修改创世块文件位置（OPT，可不修改，后面01 orderer调试配置中有环境变量ORDERER_GENERAL_GENESISMETHOD和ORDERER_GENERAL_GENESISFILE指定了创世块的位置）\n    ```yaml\n    General:\n        BootstrapFile: $GOPATH/src/github.com/hyperledger/fabric/dev-network/config/orderer.block\n    ```\n    修改账本数据目录\n    ```yaml\n    FileLedger:\n        Location: $GOPATH/src/github.com/hyperledger/fabric/dev-network/production/orderer\n    ```\n## 生成创世块和通道配置\n    ```shell\n    cd dev-netwok\n    # 创世块\n    $GOPATH/src/github.com/hyperledger/fabric/build/bin/configtxgen -profile SampleDevModeSolo -channelID sys-channel -outputBlock ./config/orderer.block\n    # 通道配置\n    $GOPATH/src/github.com/hyperledger/fabric/build/bin/configtxgen -profile SampleSingleMSPChannel -outputCreateChannelTx ./config/myc.tx -channelID myc\n    ```\n## 导入项目\n  - 用goland打开`$GOPATH/src/github.com/hyperledger/fabric`目录，会在当前目录下自动生成`.idea`目录\n  - 修改golang项目配置\n    ```shell\n    cd $GOPATH/src/github.com/hyperledger/fabric\n    vim .idea/workspace.xml\n    ```\n  - 在`workspace.xml`中的`project`节点下添加RunManager组件（用于调试或运行peer 和orderer等相关命令）\n    ```xml\n    <component name=\"RunManager\" selected=\"Go Build.14 chaincode  fabcar QueryAllCars\">\n        <configuration name=\"01 orderer\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <envs>\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n            <env name=\"ORDERER_GENERAL_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"ORDERER_GENERAL_GENESISFILE\" value=\"config/orderer.block\" />\n            <env name=\"ORDERER_GENERAL_GENESISMETHOD\" value=\"file\" />\n            <env name=\"ORDERER_GENERAL_LISTENADDRESS\" value=\"0.0.0.0\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"$PROJECT_DIR$/cmd/orderer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"02 peer\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <parameters value=\"node start --peer-chaincodedev=true\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"peer\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"192.168.2.5:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n            <env name=\"GOCACHE\" value=\"$USER_HOME$/Library/Caches/go-build\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"$PROJECT_DIR$/cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"03 channel create \" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <parameters value=\"channel create -c myc -f dev-network/config/myc.tx -o 127.0.0.1:7050\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"04 channel join \" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <parameters value=\"channel join -b myc.block\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"05 chaincode package (docker )\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"lifecycle chaincode package fabcar.tar.gz --path $PROJECT_DIR$/dev-network/chaincode/fabcar/go --lang golang --label fabcarv1\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"05 chaincode package (externalbuilder)\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"lifecycle chaincode package fabcar.tar.gz --path $PROJECT_DIR$/dev-network/chaincode/fabcar/go --lang golang --label fabcarv1-external\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"06 chaincode install\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"lifecycle chaincode install fabcar.tar.gz\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"07 chaincode queryinstalled\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"lifecycle chaincode queryinstalled\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"08 chaincode approve (externalbuilder)\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"lifecycle chaincode approveformyorg --channelID myc --name fabcar --version 1.0 --init-required --package-id fabcarv1-external:71e92900aae6b5ed64d53f83940608c9235cd41decf370b346f4833cf3b83345 --sequence 1 --waitForEvent\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"08 chaincode approve （docker）\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"lifecycle chaincode approveformyorg --channelID myc --name fabcar --version 1.0 --init-required --package-id fabcarv1:759e143166fb106f7f150c1e99ee7236eb57fd328b6d9d43b004afbeca9aa475 --sequence 1 --waitForEvent\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"09 chaincode checkcommitreadiness\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"lifecycle chaincode checkcommitreadiness --channelID myc --name fabcar --version 1.0 --init-required --sequence 1\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"10 chaincode commit\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"lifecycle chaincode commit --channelID myc --name fabcar --version 1.0 --sequence 1 --init-required --waitForEvent\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"11 chaincode querycommit\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"lifecycle chaincode querycommitted --channelID myc --output json\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"12 chaincode  fabcar initLedger\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"chaincode invoke -C myc -n fabcar --isInit -c &quot;{\\&quot;function\\&quot;:\\&quot;initLedger\\&quot;,\\&quot;Args\\&quot;:[\\&quot;\\&quot;]}&quot;\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"13 chaincode  fabcar create car\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"chaincode invoke -C myc -n fabcar -c &quot;{\\&quot;function\\&quot;:\\&quot;CreateCar\\&quot;,\\&quot;Args\\&quot;:[\\&quot;CAR9\\&quot;,\\&quot;BYD\\&quot;,\\&quot;唐dm\\&quot;,\\&quot;Red\\&quot;,\\&quot;Pld\\&quot;]}&quot;\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"14 chaincode  fabcar QueryAllCars\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"chaincode invoke -C myc -n fabcar -c &quot;{\\&quot;function\\&quot;:\\&quot;QueryAllCars\\&quot;,\\&quot;Args\\&quot;:[\\&quot;\\&quot;]}&quot;\" />\n        <envs>\n            <env name=\"CORE_PEER_LOCALMSPID\" value=\"SampleOrg\" />\n            <env name=\"CORE_PEER_ID\" value=\"cli\" />\n            <env name=\"CORE_PEER_ADDRESS\" value=\"127.0.0.1:7051\" />\n            <env name=\"FABRIC_CFG_PATH\" value=\"dev-network\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"cmd/peer/main.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <configuration name=\"15 chaincode debug fabcar\" type=\"GoApplicationRunConfiguration\" factoryName=\"Go Application\">\n        <module name=\"fabric\" />\n        <working_directory value=\"$PROJECT_DIR$/dev-network/chaincode/fabcar/go\" />\n        <useCustomBuildTags value=\"true\" />\n        <parameters value=\"-peer.address=192.168.2.5:7052\" />\n        <envs>\n            <env name=\"CORE_CHAINCODE_ID_NAME\" value=\"fabcarv1-external:71e92900aae6b5ed64d53f83940608c9235cd41decf370b346f4833cf3b83345\" />\n            <env name=\"CORE_PEER_TLS_ENABLED\" value=\"false\" />\n        </envs>\n        <kind value=\"FILE\" />\n        <filePath value=\"fabcar.go\" />\n        <package value=\"github.com/hyperledger/fabric\" />\n        <directory value=\"$PROJECT_DIR$/\" />\n        <method v=\"2\" />\n        </configuration>\n        <list>\n        <item itemvalue=\"Go Build.01 orderer\" />\n        <item itemvalue=\"Go Build.02 peer\" />\n        <item itemvalue=\"Go Build.03 channel create \" />\n        <item itemvalue=\"Go Build.04 channel join \" />\n        <item itemvalue=\"Go Build.05 chaincode package (docker )\" />\n        <item itemvalue=\"Go Build.05 chaincode package (externalbuilder)\" />\n        <item itemvalue=\"Go Build.06 chaincode install\" />\n        <item itemvalue=\"Go Build.07 chaincode queryinstalled\" />\n        <item itemvalue=\"Go Build.08 chaincode approve （docker）\" />\n        <item itemvalue=\"Go Build.08 chaincode approve (externalbuilder)\" />\n        <item itemvalue=\"Go Build.09 chaincode checkcommitreadiness\" />\n        <item itemvalue=\"Go Build.10 chaincode commit\" />\n        <item itemvalue=\"Go Build.11 chaincode querycommit\" />\n        <item itemvalue=\"Go Build.12 chaincode  fabcar initLedger\" />\n        <item itemvalue=\"Go Build.13 chaincode  fabcar create car\" />\n        <item itemvalue=\"Go Build.14 chaincode  fabcar QueryAllCars\" />\n        <item itemvalue=\"Go Build.15 chaincode debug fabcar\" />\n        </list>\n    </component> \n    ```\n    如果没问题的话，在goland中的 Run/Debug Configurations框中会出现下图：\n    ![Run/Debug Configurations](Fabric开发模式运行/fabric-debug.jpg)\n\n>vscode的调试配置不想抄了，顶部链接的原文中去看吧\n\n# 开始调试\n\n    依次运行01~14配置，在需要的地方设置断点，观察控制台变化\n  - 将配置02 peer中环境变量CORE_PEER_ADDRESS的值修改成你网卡ip地址（不能使用127.0.0.1之类的回环地址），否则链码无法连接到peer链码服务\n  - 将配置02 peer中环境变量GOCACHE的值修改成go env GOCACHE获取的值，否则externalbuilder无法build\n  - 05 chaincode package 有两个配置，需要调试链码请跑externalbuilder\n  - 执行06 chaincode install或07 chaincode queryinstalled 后需记录下Package ID，执行08 chaincode approve替换package-id的值,链码和标签修改都会导致package-id发生变化\n  - 如果使用docker跑链码，执行10 chaincode commit后，执行docker ps查看链码容器是否启动，如果没有启动链码无法调用；如果使用externalbuilder跑链码，执行ps -ef | grep fabcarv1-external检查链码进程是否启动\n\n>调试链码相关的也不想抄了，看顶部链接的原文吧，我只是想能调试运行帮助阅读fabric源码而已","tags":["Solo"],"categories":["区块链","Fabric"]},{"title":"Linux-权限解析","url":"/2023/01/09/Linux-权限解析/","content":"\n# 权限简介\nLinux系统上对文件的权限有着严格的控制，如果想对某个文件执行某种操作，必须具有对应的权限方可执行成功。Linux下文件的`权限类型`一般包括：读，写，执行。对应字母为：r、w、x。\nLinux下`权限粒度`有：拥有者、群组、其它组三种。每个文件都可以针对三个粒度，设置不同的rwx(读写执行)权限。通常情况下，一个文件只能归属于一个用户和组， 如果其它的用户想有这个文件的权限，则可以将该用户加入具备权限的群组，一个用户可以同时归属于多个组。\nLinux上通常使用chmod命令对文件的权限进行设置和更改。\n\n# 更改文件权限\n`chmod`命令\n## 命令格式\n```shell\nchmod [可选项] <mode> <file...>\n```\n## 示例\n设置所有用户可读取`a.conf`\n```shell\nchmod a+r a.conf    # a表示所有（用户、群组、其它组），+r表示读取权限\n```\n或\n```shell\nchmod ugo+r a.conf   # ugo3个字母分别表示用户，群组、其它组，+r表示读取权限\n```\n\n设置`b.sh`只有拥有者（即`u`)有读写、执行权限\n```shell\nchmod u+rwx b.sh \n```\n\n设置文件`a.conf`与`c.xml`权限为拥有者与其所属同一个群组可读写，其它组可读不可写\n```shell\nchmod a+r,ug+w,o-w a.conf c.xml\n```\n\n设置当前目录下的所有档案与子目录皆设为任何人可读写\n```shell\nchmod -R a+rw *\n```\n---\n## 数字权限使用格式\n在这种使用方式中，首先我们需要了解数字如何表示权限。 首先，我们规定数字`4`、`2`和`1`表示读、写、执行权限，即`r=4`，`w=2`，`x=1` 。此时其他的权限组合也可以用其他的八进制数字表示出来，\n\n如：\n\nrwx = 4 + 2 + 1 = 7\n\nrw = 4 + 2 = 6\n\nrx = 4 +1 = 5\n\n即\n\n若要同时设置 rwx (可读写运行） 权限则将该权限位 设置 为 4 + 2 + 1 = 7\n\n若要同时设置 rw- （可读写不可运行）权限则将该权限位 设置 为 4 + 2 = 6\n\n若要同时设置 r-x （可读可运行不可写）权限则将该权限位 设置 为 4 +1 = 5\n\n上面我们提到，每个文件都可以针对三个粒度，设置不同的rwx(读写执行)权限。即我们可以用用三个`8进制数字`分别表示`拥有者`、`群组`、`其它组`( u、 g 、o)的权限详情，并用chmod直接加三个`8进制`数字的方式直接改变文件权限。语法格式为：\n```shell\nchmod <abc> file...\n```\n```\n其中a,b,c各为一个数字，分别代表User、Group、及Other的权限。相当于简化版的\nchmod u=权限,g=权限,o=权限 file...\n而此处的权限将用8进制的数字来表示User、Group、及Other的读、写、执行权限\n```\n\n## 示例\n设置所有人可以读写及执行\n```shell\nchmod 777 a.sh # (等价于  chmod u=rwx,g=rwx,o=rwx a.sh 或  chmod a=rwx a.sh)\n```\n\n设置拥有者可读写，其他人不可读写执行\n```shell\nchmod 600 a.sh (等价于chmod u=rw,g=---,o=--- a.sh 或 chmod u=rw,go-rwx a.sh)\n```\n\n| 权限 | 8进制值 | 描述 |\n| -- | -- | -- |\n| --- | 0 | 没有任何权限 |\n| --x | 1 | 只有执行权限 |\n| -w- | 2 | 只有写入权限 |\n| -wx | 3 | 有写入和执行权限 |\n| r-- | 4 | 有读取权限 |\n| r-x | 5 | 有读取和执行权限 |\n| rw- | 6 | 有读取和写入权限 |\n| rwx | 7 | 有全部权限 |\n\n> 注：权限rwx3个“位”，值分别是4，2，1 对应的二进制值为 100，010，001。设计成这样的值方便进行“位或”操作（其实就相当于+）。用这样的设计，在进行位或操作时，就能形成不会重复的结果分别用来表示不同的组合。","tags":["权限","权限类型","权限粒度"],"categories":["Linux"]},{"title":"重读《JAVA与模式》笔记系列-00005","url":"/2023/01/08/重读《JAVA与模式》笔记系列-00005/","content":"\n# 前言\n以抽象方式耦合是依赖倒转原则的关键。由于抽象耦合关系总要涉及具体类从抽象类继承，并且需要保证任何引用到基类的地方都可以改换成其子类，因此里氏代换原则是依赖倒转原则的基础。\n\n在抽象层次上的耦合虽然有灵活性，但也带来了额外的复杂性。在某些情况下，如果一个具体类发生变化的可能性非常小，那么抽象耦合能发挥的好处便十分有限，这时使用具体耦合反而会更好。\n\n依赖倒转原则是`OO`设计的核心原则，设计模式的研究和应用是以依赖倒转原则为指导原则的。下面就举几个设计模式的例子加以说明。\n\n# 工厂方法模式\n正如前面所谈到的，应当使消费一个对象的客户端只依赖于对象的抽象类型，而不是它的具体类型。但是`Java`语言要求在将一个（具体）类实例化的时候，必须调用这个具体类的构造子，所以`Java`语言给出的类的实例化方法无法做到只依赖于抽象类型。\n\n但是设计模式给出了解决这个问题的可行方案，其中最重要的方案就是工厂模式。工厂方法模式是几个工厂模式中最为典型的一个，下图所示就是工厂方法模式的简略类图。\n![工厂方法模式简略类图](重读《JAVA与模式》笔记系列-00005/FactoryMethod.jpg)\n\n工厂模式将创建一个类的实例的过程封装起来，消费这个实例的客户端仅仅得到实例化的结果，以及这个实例的抽象类型。当然，任何方法都无法回避`Java`语言所要求的`new`关键字和直接调用具体类的构造子的做法。简单工厂模式将这个违反“开-闭”原则以及依赖倒转原则的做法封装到一个类里面，而工厂方法模式将这个违反原则的做法推迟到了具体工厂角色中，如下图所示：\n![工厂方法模式简略类图](重读《JAVA与模式》笔记系列-00005/FactoryMethod1.jpg)\n\n这样，通过适当地封装，工厂模式可以净化大部分的结构，而将违反原则的做法孤立到易于控制的地方。\n\n# 模版方法模式\n在模版方法模式里面，有一个抽象类将重要的宏观逻辑以`具体方法`以及`具体构造子`的形式实现，然后声明一些抽象方法来迫子类实现剩余的具体细节上的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对**剩余的逻辑**有不同的实现。模版方法模式支持依赖倒转原则，如下图所示。\n![模版方法模式简略类图](重读《JAVA与模式》笔记系列-00005/TemplateMethod.jpg)\n\n具体子类不能影响抽象类的宏观逻辑，而抽象逻辑的改变则会导致细节逻辑的改变。\n\n# 迭代子模式\n迭代子模式用一个工厂方法向客户端提供一个聚集的内部迭代功能，客户端得到的是一个`Iterator`抽象类型，并不知道迭代子的具体实现以及聚集对象的内部结构。迭代子模式的简略类图如下图所示。\n\n![迭代子模式简略类图](重读《JAVA与模式》笔记系列-00005/Iterator1.jpg)\n\n这样一来，聚集的内部结构的改变就不会波及到客户端，从而实现了对抽象接口的依赖，如下图所示。\n![迭代子模式简略类图](重读《JAVA与模式》笔记系列-00005/Iterator2.jpg)","categories":["设计模式","设计原则的体现"]},{"title":"Web开发基础-知识点-1","url":"/2023/01/06/Web开发基础-知识点-1/","content":"\n# 什么是反向代理\n`反向代理`是位于`Web服务器`前面的服务器，其将`客户端`（例如`Web浏览器`）请求转发到这些`Web服务器`。反向代理通常用于帮助提高安全性、性能和可靠性。为了更好地理解反向代理的工作原理以及它可以提供的好处，我们来首先定义什么是`代理服务器`。\n\n# 什么是代理服务器？\n`转发代理`，通常称为`代理`、`代理服务器`或`Web代理`，是位于一组客户端计算机之前的服务器。当这些计算机向`Internet`上的站点和服务发出请求时，代理服务器将拦截这些请求，然后代表客户端与`Web服务器`进行通信，起到中间设备的作用。\n\n例如，典型的转发代理通信中涉及3台计算机：\n- A：这是用户的家用计算机\n- B：这是一个转发代理服务器\n- C：这是网站的源站（用于存储网站数据）\n\n![转发代理](Web开发基础-知识点-1/forward-proxy-flow.svg)\n\n在标准的互联网通信中，`计算机A`将直接与`计算机C`保持联系，`客户端`将请求发送到`源服务器`，并且`源服务器`将响应`客户端`。当存在转发代理时，`A` 将请求发送到 `B`，`B` 随后将请求转发给 `C`。`C` 将向 `B` 发送响应，而 `B` 则将响应转发给 `A`。\n\n为什么要将这个多余的中间设备添加到 Internet 活动中？使用转发代理可能有几个原因：\n- 为避免浏览限制: 一些政府、学校和其他组织使用防火墙来使用户访问受限版本的互联网。转发代理可用于绕过这些限制，因为它们使用户可以连接到代理，而不是直接连接到他们正在访问的站点。\n- 阻止访问某些内容: 相对的，也可以设置代理以阻止特定用户群访问某些站点。例如，学校网络可能配置为通过启用内容筛选规则的代理连接到 Web，以拒绝转发来自 Facebook 和其他社交媒体网站的响应。\n- 保护自己的在线身份—: 在某些情况下，常规互联网用户希望增加在线匿名性，但在其他情况下，互联网用户居住在政府可能对政治异议者施加严重后果的地方。在网络论坛或社交媒体上批评政府可能会导致这些用户受到罚款或监禁。如果持不同政见者使用转发代理连接到他们发布政治敏感评论的网站，则用于发表评论的`IP地址`将更难追溯到持不同政见者。仅`代理服务器`的`IP地址`将对他人可见。\n\n# 反向代理有何不同?\n反向代理是位于一个或多个`Web服务器`前面的服务器，拦截来自`客户端`的请求。这与转发代理不同:在转发代理中，`代理`位于`客户端`的前面。使用`反向代理`，当`客户端`将请求发送到网站的`源服务器`时，`反向代理服务器`会在网络边缘拦截这些请求。然后，`反向代理服务器`将向`源服务器`发送请求并从`源服务器`接收响应。\n\n`转发代理`和`反向代理`之间的区别非常细微，但非常重要。简单概括而言，`转发代理`位于客户端的前面，确保没有源站直接与该特定客户端通信；而`反向代理服务器`位于源站前面，确保没有客户端直接与该源站通信。\n\n这一次，所涉及的计算机包括：\n- D：任意数量的用户家用计算机\n- E：这是反向代理服务器\n- F：一台或多台源站\n  \n![反向代理](Web开发基础-知识点-1/reverse-proxy-flow.svg)\n\n通常，来自`D`的所有请求都将直接发送到`F`，而`F`会直接将响应发送到`D`。使用`反向代理`，来自`D`的所有请求都将直接发送给`E`，而`E`会将其请求发送到`F`并从`F`接收响应，然后将适当响应传递给`D`。\n\n下面是反向代理的一些好处：\n- 负载均衡: 一个每天吸引数百万用户的热门网站可能无法使用单个源服务器处理所有传入站点流量。但该站点可以分布在不同服务器的池中，让所有服务器都处理同一站点的请求。在这种情况下，反向代理可以提供一种负载均衡解决方案，在不同服务器之间平均分配传入流量，以防止单个服务器过载。如果某台服务器完全无法运转，则其他服务器可以代为处理流量。\n- 防范攻击: 配备反向代理后，网站或服务无需透露其源服务器的`IP地址`。这使得攻击者更难利用针对性攻击，例如`DDoS`攻击。这时候，攻击者只能针对反向代理。\n- 全局服务器负载平衡(GSLB): 在这种负载均衡形式中，一个网站可以分布在全球各地的多个服务器上，反向代理会将客户端发送到地理位置上最接近它们的服务器。这样可以减少请求和响应传播的距离，从而最大程度地减少加载时间。\n- 缓存: 反向代理还可以缓存内容，从而提高速度。例如，如果巴黎的用户访问使用反向代理而`Web服务器`位于洛杉矶的网站，则该用户实际上可能连接到巴黎本地的`反向代理服务器`，然后该本地`反向代理服务器`必须与洛杉矶的`源服务器`进行通信。之后，`代理服务器`可以缓存（或临时保存）响应数据。随后浏览该站点的巴黎用户将从巴黎`反向代理服务器`处获取本地缓存的响应，从而享受到更快的性能。\n- SSL加密: 加密和解密每个客户端的`SSL（或 TLS）`通信对于源服务器可能需要耗费大量计算资源。可以配置由反向代理解密所有传入请求并加密所有传出响应，腾出源服务器上的宝贵资源。\n  \n","tags":["转发代理","反向代理"],"categories":["Web开发","基础知识"]},{"title":"Golang学习-知识点-1","url":"/2023/01/04/Golang学习-知识点-1/","content":"\n# 前言\nGolang名言：使用通信来共享内存，而不是使用共享内存来通信。Golang中有`sync`包提供了传统方式的锁机制。但更推荐使用`channel`来解决并发问题。\n\n# channel的用法\n## 什么是channel\n`channel`是`goroutine`之间用来接收或发送消息的安全消息队列。`channel`就像是它的字面意思：通道。它就是两个`goroutine`之间用来同步资源的一个通道。\n![channel示意图](Golang学习-知识点-1/1.jpg)\n\n```go\nfunc main() {\n\tch := make(chan int, 1) // 创建一个类型为int,缓冲区大小为1的channel\n\tch <-2 // 将2发送到channel中\n\tn, ok := <-ch // n从channel中接收数据\n\tif ok {\n\t\tfmt.Println(n) // 2\n\t}\n\tclose(ch) // 关闭channel\n}\n```\n\n## 使用时的注意点\n- 向一个`nil channel`发送消息会一直阻塞\n\n    Code:\n    ```go\n    package main\n\n    import (\n        \"fmt\"\n        \"time\"\n    )\n\n    func main() {\n        var ch chan int\n\n        go send(ch)\n        <-ch\n        time.Sleep(time.Second * 1)\n    }\n\n    func send(ch chan int) {\n        fmt.Println(\"Sending value to channnel start\")\n        ch <- 1\n        fmt.Println(\"Sending value to channnel finish\")\n    }\n    ```\n    Output:\n    ```\n    Sending value to channnel start\n    fatal error: all goroutines are asleep - deadlock!\n    goroutine 1 [chan receive (nil chan)]:\n    goroutine 18 [chan send (nil chan)]:\n    ```\n    分析：上述代码只是声明了channel，它的默认初始值为nil, 在一个goroutine中向这个 nil channel 发送消息，这个goroutine 就会一直阻塞,而在main函数中(主routine)中想从channel中获取这个消息也是会被阻塞住，所以整个进行就相当于处理死锁状态。\n\n- 向一个已关闭的`channel`发送消息会引发运行时`panic`\n- `channel`关闭后不可以继续向它发送消息，但可以继续从它接收消息\n- 当`channel`关闭后并且缓冲区为空时，继续从它接收消息会得到一个对应类型的零值\n\n# unbuffered channels与buffered channels\n- `unbuffered channel`是缓冲区大小为0的`channel`，这种`channel`的接收者会阻塞直至接收到消息；发送者会阻塞直至接收到消息，这种机制可以用于两个`goroutine`进行状态同步。\n- `buffered channel`拥有缓冲区，当缓冲区已满时，发送者会阻塞，当缓冲区为空时，接收者会阻塞。\n  \n引用[The Nature Of Channels In Go](https://www.ardanlabs.com/blog/2014/02/the-nature-of-channels-in-go.html)中的两张图来说明`Unbuffered channels`与`Buffered channels`\n\n## Unbuffered channels\n![Unbuffered channels](Golang学习-知识点-1/2.png)\n\n\n## Buffered channels\n![Buffered channels](Golang学习-知识点-1/3.png)\n\n### unbuffered channel示例\n让我们构建一个示例程序，它使用四个 goroutine 和一个通道来模拟接力赛。比赛中的参赛者将被称为“ Goroutines”，通道将被用来在每个参赛者之间交换接力棒。这是一个典型的例子，说明了如何在 goroutines 之间传递资源，以及通道如何控制与之交互的 goroutines 的行为。\n\n```go\nfunc Runner(baton chan int) {\n\tvar newRunner int\n\n\t// Wait to receive the baton\n\trunner := <-baton\n\n\t// Start running around the track\n\tfmt.Printf(\"Runner %d Running With Baton\\n\", runner)\n\n\t// New runner to the line\n\tif runner != 4 {\n\t\tnewRunner = runner + 1\n\t\tfmt.Printf(\"Runner %d To The Line\\n\", newRunner)\n\t\tgo Runner(baton)\n\t}\n\n\t// Running around the track\n\ttime.Sleep(100 * time.Millisecond)\n\n\t// Is the race over\n\tif runner == 4 {\n\t\tfmt.Printf(\"Runner %d Finished, Race Over\\n\", runner)\n\t\treturn\n\t}\n\n\t// Exchange the baton for the next runner\n\tfmt.Printf(\"Runner %d Exchange With Runner %d\\n\", runner, newRunner)\n\tbaton <- newRunner\n}\n\nfunc main() {\n\t// Create an unbufferd channel\n\tbaton := make(chan int)\n\n\t// First runner to his mark\n\tgo Runner(baton)\n\n\t// Start the race\n\tbaton <- 1\n\n\t// Give the runners time to race\n\ttime.Sleep(500 * time.Millisecond)\n}\n```\n运行结果：\n```\nRunner 1 Running With Baton\nRunner 2 To The Line\nRunner 1 Exchange With Runner 2\nRunner 2 Running With Baton\nRunner 3 To The Line\nRunner 2 Exchange With Runner 3\nRunner 3 Running With Baton\nRunner 4 To The Line\nRunner 3 Exchange With Runner 4\nRunner 4 Running With Baton\nRunner 4 Finished, Race Over\n```\n\n## channel的遍历\n### 阻塞型的遍历方式\n```go\nfunc main() {\n\tci := make(chan int, 5)\n\tfor i := 1; i <= 5; i++ {\n\t\tci <- i\n\t}\n\tclose(ci)\n\t\n\tfor i := range ci {\n\t\tfmt.Println(i)\n\t}\n}\n```\n>值得注意的是：在遍历channel前，如果channel没有关闭，遍历会被阻塞，会出现deadlock的错误；如果在遍历时channel已经关闭，那么会遍历完数据后退出遍历；也就是说for range的遍历方式是阻塞型的遍历方式。\n\n### 非阻塞型的遍历方式\n`select`可用于非阻塞式消息发送、接收及多路选择\n```go\nfunc main() {\n\tci := make(chan int, 2)\n\tfor i := 1; i <= 2; i++ {\n\t\tci <- i\n\t}\n\tclose(ci)\n\n\tcs := make(chan string, 2)\n\tcs <- \"hi\"\n\tcs <- \"golang\"\n\tclose(cs)\n\n\tciClosed, csClosed := false, false\n\tfor {\n\t\tif ciClosed && csClosed {\n\t\t\treturn\n\t\t}\n\t\tselect {\n\t\tcase i, ok := <-ci:\n\t\t\tif ok {\n\t\t\t\tfmt.Println(i)\n\t\t\t} else {\n\t\t\t\tciClosed = true\n\t\t\t\tfmt.Println(\"ci data fetching finished\")\n\t\t\t}\n\t\tcase s, ok := <-cs:\n\t\t\tif ok {\n\t\t\t\tfmt.Println(s)\n\t\t\t} else {\n\t\t\t\tcsClosed = true\n\t\t\t\tfmt.Println(\"cs data fetching finished\")\n\t\t\t}\n\t\tdefault:\n\t\t\tfmt.Println(\"wating...\")\n\t\t}\n\t}\n}\n```\n>`select`中有`case`代码块，用于`channel`发送或接收消息，任意一个`case`代码块准备好时，执行其对应内容；多个`case`代码块准备好时，随机选择一个`case`代码块并执行；所有`case`代码块都没有准备好，则等待；还可以有一个`default`代码块，所有`case`代码块都没有准备好时执行default代码块。这里的所谓的没有准备好，指的就是channel没有关闭。当执行了close()函数后，就是所谓的准备好了。","tags":["channel"],"categories":["Golang","基础"]},{"title":"重读《JAVA与模式》笔记系列-00004","url":"/2023/01/02/重读《JAVA与模式》笔记系列-00004/","content":"\n实现“开-闭”原则的关键是抽象化，并且从抽象化导出具体化实现。如果说“开-闭”原则是面向对象设计的目标的话，依赖倒置原则就是这个面向对象设计的主要机制。\n\n# 为何而“倒转”\n传统的过程性系统的设计办法倾向于使高层次依赖于低层次的模块；抽象层次依赖于具体层次。倒转原则是要把这个错误的依赖关系倒转过来，这就是“依赖倒转原则”的来由。\n\n抽象层依赖于具体层次的含义是什么呢？抽象层次包含的是应用系统的商务逻辑和宏观的、对整个系统来说重要的战略性决定，是必然性的体现；而具体层次则含有一些次要的与实现有关的算法和逻辑，以及战术性的决定，带有相当大的偶然性选择。具体层次的代码是会经常有变动的，不能避免出现错误。抽象层次依赖于具体层次，使许多具体层次的细节的算法变化立即影响到抽象层次的宏观商务逻辑，导致微观决定宏观，战术决定战略，偶然决定必然。如下图所示：\n![错误的层次依赖关系](重读《JAVA与模式》笔记系列-00004/1.jpg)\n\n依赖倒转原则(Dependence Inversion Principle或简称为DIP)，就是要把错误的依赖关系再倒转过来，如下图：\n![依赖倒转的关系图](重读《JAVA与模式》笔记系列-00004/2.jpg)\n>依赖倒转原则是COM/CORBA/JavaBean以及EJB等构建设计模型背后的基本原则。\n\n# 复用与可维护性的“倒转”\n从复用的角度来看，高层次的模块是设计者应当复用的。但是在传统的过程性设计中，复用却侧重于具体层次模块的复用，比如算法的复用、数据结构的复用、函数库的复用等，都不可避免是具体层次模块里面的复用。较高层次的结构依赖于较低层次的结构，较低层次的结构又进一步依赖于更低层次的结构，如此继续，直到依赖于每一行的代码。较低层次上的修改，会造成较高层次的修改，直到高层次逻辑的修改。\n\n同样，传统的做法也强调具体层次上的可维护性，包括一个函数、数据结构等的可维护性，而不是高级层次上的可维护性。\n\n从复用的意义上讲，既然抽象层次含有一个应用系统最重要的宏观商务逻辑，是做战略性判断和决定的地方，那么抽象层次就应当是较为稳定的，应当是复用的重点。由于现有的复用侧重于具体模块和细节的复用，因此“倒转”一词则是指复用应当将复用的重点放在抽象层次上。如果抽象层次的模块相对独立于具体层次的模块的话，那么抽象层次的模块的复用便是相对较为容易的了。\n\n# 依赖倒转原则\n## 依赖（或者耦合）关系\n- 零耦合(Nil Coupling)关系：如果两个类没有耦合关系，就称之为零耦合。\n- 具体耦合(Concrete Coupling)关系：具本性耦合发生在两个具体的（可实例化的）类之间，经由一个类对另一个具体类的直接引用造成\n- 抽象耦合(Abstract Coupling)关系：抽象耦合关系发生在一个具体类和一个抽象类（或者Java接口）之间，使两个必须发生关系的类之间存有最大的灵活性。\n\n# 什么是依赖倒转原则\n简单地说，依赖倒转原则(Dependency Inversion Principle)要求客户端依赖于抽象耦合。依赖倒转原则的表述是：\n- 表述1：抽象不应该依赖于细节；细节应当依赖于抽象。(Abstractions should not depend upon details.Details should depend upon abstractions)\n- 表述2：要针对接口编程，不要针对实现编程。（Program to an interface, not an implementation)\n\n针对接口编程的意思就是说，应当使用Java接口和Java抽象类进行变量的类型声明、参量的类型声明、方法的返还类型声明，以及数据类型的转换等。\n\n不要针对实现编程的意思就是说，不应当使用Java具体类进行变量的类型声明、参量的类型声明、方法的返还类型声明，以及数据类型的转换等。\n\n<font color=red>**要保证做到这一点，一个具体类应当只实现接口和抽象类中声明过的方法，而不应当给出多余的方法。**</font>\n\n倒转依赖关系强调一个系统内的实体之间关系的灵活性。基本上，如果设计师希望遵守“开-闭”原则，那么倒转依赖原则便是达到要求的途径。\n\n# 变量的静态类型和真实类型\n变量被声明时的类型叫做变量的静态类型(Static Type)，有些地方把静态类型叫做明显类型(Apparent Type)，变量所引用的对象的真实类型叫做变量的实际类型(Actual Type)。例如：\n```java\nList employees = new Vector();\n```\n`Vector`是一个具体类（实际类型），而`List`是一个接口（静态类型）。\n\n# 引用对象的抽象类型\n在很多情况下，一个Java程序需要引用一个对象。这个时候，如果这个对象有一个抽象类型的话，应当使用这个抽象类型作为变量的静态类型。这就是针对接口编程的含义。\n\n","tags":["依赖倒置原则","DIP"],"categories":["设计模式","设计原则的体现"]},{"title":"重读《JAVA与模式》笔记系列-00003","url":"/2022/12/31/重读《JAVA与模式》笔记系列-00003/","content":"\n# 设计原则在常用设计模式中的体现\n\n## 策略模式对“开-闭”原则的支持\n策略模式讲的是，如果有一组算法，那么就将每一个算法封装起来，使得它们可以互换。策略模式就是从对可变性的封装原则出发，达到“开-闭”原则的范例\n\n{% mermaid %}\n\nclassDiagram\nclass DiscountStrategy {\n    <<abstract>>\n-price:single\n-copies:int\n+calculateDiscount():single\n}\n\nclass NoDiscountStrategy {\n    -price:single\n    -copies:int\n    +calculateDiscount():single\n}\n\nclass FlatRateStrategy {\n    -price:single\n    -copies:int\n    -amount:single\n    +calculateDiscount():single\n}\n\nclass PercentageStrategy {\n    -price:single\n    -copies:int\n    -percent:single\n    +calculateDiscount():single\n}\n\nNoDiscountStrategy --|> DiscountStrategy\nFlatRateStrategy --|> DiscountStrategy\nPercentageStrategy --|> DiscountStrategy\n\n{% endmermaid %}\n\n\n## 简单工厂模式\n“开-闭”原则要求系统允许新的产品加入系统中而无需对现有代码进行修改。在简单工厂模式中，这对于产品消费角色是成立的，而对于工厂模式是不成立的。简单工厂模式结构如下图：\n![简单工厂模式](重读《JAVA与模式》笔记系列-00003/SimpleFactory.jpg)\n\n## 工厂方法模式\n在工厂方法模式中，具体的工厂类都有共同的接口，它们“生产”出很多处于同一等级结构中的产品对象。使得这个系统可以加入新的产品类型（增加产品的具体工厂）。工厂方法模式的简略类图如下：\n![工厂方法模式](重读《JAVA与模式》笔记系列-00003/FactoryMethod.jpg)\n\n## 抽象工厂模式\n抽象工厂模式封装了产品对象家族的可变性，从而一方面可以使系统动态地决定将哪一个产品族的产品对象实例化，另一方面可以将新的产品引进到已有系统中而不必修改已有的系统。抽象工厂模式的简略图如下：\n![抽象工厂模式](重读《JAVA与模式》笔记系列-00003/AbstractFactory.jpg)\n\n## 建造模式\n建造模式封装了建造一个有内部结构的产品对象的过程，因此这样的系统是向产品内部表象的改变开放的。\n![抽象工厂模式](重读《JAVA与模式》笔记系列-00003/Build.jpg)\n\n## 桥梁模式\n桥梁模式是“对可变性的封装原则”的极好例子。在桥梁模式中，具体实现化类代表不同的实现逻辑，但是所有的具体实现化类又有共同的接口。新的实现逻辑可以通过创建新的具体实现化类加入到系统里面。桥梁模式的简略类图如下：\n![桥梁模式](重读《JAVA与模式》笔记系列-00003/Bridge.jpg)\n\n## 门面模式\n假设一个系统开始的时候与某一个子系统耦合在一起，后来又不得不换成另外一个子系统，那么门面模式便可以发挥门面模式和适配器模式两种作用，将新的子系统仍然与本系统耦合在一起。这样一来，使用门面模式便可以改变子系统内部功能而不会影响到客户端。门面模式的简略类图如下：\n![门面模式](重读《JAVA与模式》笔记系列-00003/Facade.jpg)\n\n## 迭代子模式\n迭代子模式将访问聚集元素的逻辑封装起来，并且使它独立于聚集对象的封装。这就提供了聚集存储逻辑与迭代逻辑独立演变的空间，使系统可以在无需修改消费迭代子的客户端的情况下，对聚集对象的内部结构进行功能扩展。迭代子模式的简略类图如下：\n![迭代子模式](重读《JAVA与模式》笔记系列-00003/Iterator.jpg)\n\n>当学习设计模式的时候，要学会问一个问题：这个设计模式可以对什么样的变换开放，以及它做到这一点所付出的代价是什么。通过这样的思考，可以更加透彻地了解这种模式对“开-闭”原则的支持程度，以及这种设计模式本身。","categories":["设计模式","设计原则的体现"]},{"title":"Golang项目Swagger接口文档","url":"/2022/12/21/Golang项目Swagger接口文档/","content":"\n# 安装swagger\n[swagger github地址](https://github.com/swaggo/swag/blob/master/README.md)\n>go1.17版本后，使用go install 安装swag\n```shell\ngo install github.com/swaggo/swag/cmd/swag@latest\n```\n\n>验证是否安装成功（会在$GOPATH/bin)目录下生成swag可执行文件\n```shell\nswag -v\n```\n\n# 对gin框架的支持\n```shell\ngo get -u github.com/swaggo/gin-swagger\ngo get -u github.com/swaggo/files\n```\n\n# 注解\n## API接口的注解\n| 注解 | 描述 |\n| -- | -- |\n| @Summary | 摘要 |\n| @Produce | API可以产生的MIME类型列表。我们可以把MIME类型简单地理解为响应类型，如JSON/XML/HTML等 |\n| @Param | 参数格式，从左到右分别为：参数名、入参类型、数据类型、是否必填和注释 |\n| @Success | 响应成功，从左到右分别为：状态码、参数类型、数据类型和注释 |\n| @Failure | 响应失败，从左到右分别为：状态码、参数类型、数据类型和注释 |\n| @Router | 路由，从左到右分别为：路由地址和HTTP方法 |\n\n## 例子\n```go\n// @Summary 获取多个标签\n// @Produce json\n// @Param name query string false \"标签名称\" maxlength(100)\n// @Param state query int false \"状态\" Enums(0, 1) default(1)\n// @Param page query int false \"页码\"\n// @Param page_size query int false \"每页数量\"\n// @Success 200 {object} model.TagSwagger \"成功\"\n// @Failure 400 {object} errcode.Error \"请求错误\"\n// @Failure 500 {object} errcode.Error \"内部错误\"\n// @Router /api/v1/tags [get]\nfunc (t Tag) List(c *gin.Context) {\n\n}\n\n// @Summary 新增标签\n// @Produce json\n// @Param name body string true \"标签名称\" minlength(3) maxlength(100)\n// @Param state body int false \"状态\" Enums(0, 1) default(1)\n// @Param created_by body string false \"创建者\" minlength(3) maxlength(100)\n// @Success 200 {object} model.Tag \"成功\"\n// @Failure 400 {object} errcode.Error \"请求错误\"\n// @Failure 500 {object} errcode.Error \"内部错误\"\n// @Router /api/v1/tags [post]\nfunc (t Tag) Create(c *gin.Context) {\n\n}\n\n// @Summary 更新标签\n// @Produce json\n// @Param id path int true \"标签ID\"\n// @Param name body string false \"标签名称\" minlength(3) maxlength(100)\n// @Param state body int false \"状态\" Enums(0, 1) default(1)\n// @Param modified_by body string true \"修改者\" minlength(3) maxlength(100)\n// @Success 200 {array} model.Tag \"成功\"\n// @Failure 400 {object} errcode.Error \"请求错误\"\n// @Failure 500 {object} errcode.Error \"内部错误\"\n// @Router /api/v1/tags/{id} [put]\nfunc (t Tag) Update(c *gin.Context) {\n\n}\n\n// @Summary 删除标签\n// @Produce json\n// @Param id path int true \"标签ID\"\n// @Success 200 {string} string \"成功\"\n// @Failure 400 {object} errcode.Error \"请求错误\"\n// @Failure 500 {object} errcode.Error \"内部错误\"\n// @Router /api/v1/tags/{id} [delete]\nfunc (t Tag) Delete(c *gin.Context) {\n\n}\n```\n\n# main 方法\n既然接口方法本身有了注解，那么针对这个项目，能不能写注解呢？如果有很多个项目，如何知道这个项目具体是哪个呢？实际上是可以识别出来的，只需针对main方法写入如下注解即可：\n```go\n// @title 博客系统\n// @version 1.0\n// @description Go 编程之旅：一起用Go做项目\n// @termsOfService https://github.com/go-programming-tour-book\nfunc main() {\n\n}\n\n```\n\n# 生成\n```shell\nswag init\n```","tags":["swagger","swaggo","接口文档"],"categories":["Golang","库","swaggo"]},{"title":"重读《JAVA与模式》笔记系列-00002","url":"/2022/12/17/重读《JAVA与模式》笔记系列-00002/","content":"\n# 什么是“开-闭”原则\n“开-闭”原则讲的是：一个软件实体应当对扩展开放，对修改关闭。\n>Software entities should be open for extension, but closed for modification.\n\n这个原则说的是，在设计一个模块的时候，应当使这个模块可以在不被修改的前提下被扩展。换言之，应当可以在不必修改源代码的情况下改变这个模块的行为。\n\n满足“开-闭”原则的设计可以给一个软件系统两个无可比拟的优越性：\n- 通过扩展已有的软件系统，可以提供新的行为，以满足对软件的新需求，使变化中的软件系统中有一定的适应性和灵活性。\n- 已有的软件模块，特别是最重要的抽象层模块不能再修改，这就使变化中的软件系统有一定的稳定性和延续性。\n\n# 抽象化是关键\n解决问题的关键在于抽象化。面向对象的编程语言里面，可以给系统定义出一个一劳永逸、不再更改的抽象设计，此设计允许有无穷无尽的行为在实现层被实现。这个抽象层预见了所有的可能扩展，因此，在任何扩展情况下都不会改变。这就使得系统的抽象层不需修改，从而满足了“开-闭”原则的第二条：对修改关闭。\n\n同时，由于从抽象层导出一个或多个新的具体类可以改变系统的行为，因此系统的设计对扩展是开放的，这就满足了“开-闭”原则的第一条。\n\n# 对可变性的封装原则\n“开-闭”原则如果从另外一个角度讲述，就是所谓的“对可变性的封装原则”（Principle of Encapsulation of Variation，常常略写做EVP).\"\n\n可变性原则的思路：考虑的不是什么会导致设计改变，而是考虑你允许什么发生变化而不让这一变化导致重新设计。\n\n[SHALL01]将这一思想用一句话总结为：找到一个系统的可变因素，将它封装起来，并将它命名为“对可变性的封装原则”，对可变性的封装原则意味着两点：\n- 一种可变性不应当散落在代码的很多角落里，而应当被封装到一个对象里面。同一种可变性的不同表象意味着同一继承等级结构中的具体子类。\n- 一种可变性不应当与另一种可变性混合在一起。即类图中的继承结构一般都不会超过两层。不然就意味着将两种不同的可变性混合在了一起。\n\n>显然，”对可变性的封装原则“从工程的角度讲解了如何实现”开-闭“原则。\n\n# 与其它设计原则的关系\n做到”开-闭“原则不是一件容易的事，但是也是有很多规律可循的。这些规律也同样以设计原则的身份出现，但是它们都是”开-闭“原则的手段和工具，是附属于”开-闭“原则的。\n\n## 里氏代换原则\n**里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。**\n\n里氏代换原则是对”开-闭“原则的补充。正如前面所谈到的，实现”开-闭“原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体体现，所以里氏代换原则是对实现抽象化的具体步骤的规范。\n\n一般而言，违反里氏代换原则的，也违背”开-闭“原则，反过来并不一定成立。\n\n## 依赖倒转原则\n**依赖倒转原则讲的是，要依赖于抽象，不要依赖于实现。**\n\n看上去和”开-闭”原则有很大的相似之处，实际上，它们之间的关系是目标和手段的关系。“开-闭”原则是目标，而达到这一目标的手段是依赖倒转原则。\n\n换言之，要想实现“开-闭”原则，就应当坚持依赖倒转原则，违反依赖倒转原则，就不可能达到“开-闭”原则的要求。\n\n## 合成/聚合复用原则\n**合成/聚合复用原则讲的是，要尽量使用合成/聚合，而不是继承关系达到复用的目的。**\n\n合成/聚合复用原则是与里氏代换原则相辅相成的，两者又都是对实现“开-闭”原则的具体步骤的规范。\n\n遵守合成/聚合复用原则是实现“开-闭”原则的必要条件；违反了这一原则就无法使系统实现“开-闭”原则这一目标。\n\n## 迪米特法则\n**迪米特法则讲的是，一个软件实体应当与尽可能少的其它实体发生相互作用。**\n\n当一个系统面临功能扩展时，其中会有一些模块，它们需要修改的压力比其它一些模块要大。最后的结果可能是这些模块需要修改或者不需要修改。但是不论是哪一种情况，如果这些模块是相对孤立的，那么它们就不会将修改的压力传递给其它的模块。\n\n这就是说，一个遵守迪米特原则设计出来的系统在功能需要扩展时，会相对更容易地做到对修改的半闭。也就是说，迪米特法则是一条通向“开-闭”原则的道路。\n\n## 接口隔离原则\n**接口隔离原则讲的是，应当为客户端提供尽可能小的单独接口，而不要提供大的总接口。**\n\n显然，接口隔离原则与广义的迪米特法则都是对一个软件实体与其它的软件实体的通信的限制。广义的迪米特法则要求尽可能限制通信的宽度和深度。接口隔离原则所限制的是通信的宽度，也就是说，通信应当尽可能地窄。\n\n遵循隔离原则与迪米特法则，会使一个软件系统在功能扩展的过程当中，不会将修改的压力传递到其它对象。\n\n","tags":["开闭原则","OCP"],"categories":["设计模式","基本概念"]},{"title":"重读《JAVA与模式》笔记系列-00001","url":"/2022/12/16/重读《JAVA与模式》笔记系列-00001/","content":"\n# 类图中的关系\n在类与类之间，会有连线指明它们之间的关系，类和类、类和接口、接口和接口之间可以建立以下几种关系：一般化关系、关联关系、聚合关系、合成关系和依赖关系，这几种关系都是静态的。\n\n## 一般化关系\n一般化(Generalization)关系表示类与类之间的继承关系，接口与接口之间的继承关系，或类对接口的实现关系。一般化的关系是从子类指向父类的，或从实现接口的类指向被实现的接口，与继承或实现的方向相反，如下图所示：\n\n\n{% mermaid %}\n\nclassDiagram\nclass Interface1 {\n\t<<interface>>\n}\nInterface1 <|.. Class1\nInterface1 <|.. Class2\n\nParentClass <|-- ChildClass1\nParentClass <|-- ChildClass2\n\n{% endmermaid %}\n\n## 关联关系\n关联(Association)关系是类与类之间的联接，它使一个类知道另一个类的属性和方法。关联可以是双向的，也可以是单向的。双向的关联可以有两个箭头或者没有箭头。单向的关联有一个箭头，表示关联的方向，如下图所示。单向的关联更为普遍，通常不鼓励使用双向的关联。\n\n{% mermaid %}\n\nclassDiagram\nDriver --> Car : Drives\nclass Dirver {\n    -car : Car \n}\n\n{% endmermaid %}\n\n关联关系是使用实例变量实现的，比如上面的`Driver`类中，就出现了下个类型为`Car`的实例变量，这个变量实现了这两个类之间的关联关系。每一个关联都有一个名字，在上面的例子里，关联的名字是`Drives`。\n\n在每一个关联的端点，还可以有一个基数(Multiplicity)，表明这一端的类可以有几个实例。比如，唐僧和他的徒弟形成一个关联关系，在这个关系里面，唐僧只能有一个，而徒弟可以有好几个，如下图所示。\n\n{% mermaid %}\n\nclassDiagram\n唐僧 \"1\" --> \"*\" 徒弟\n\n徒弟 <|-- 悟空 \n徒弟 <|-- 悟能\n徒弟 <|-- 悟净\n\n{% endmermaid %}\n>唐僧和徒弟之间的箭头应该是 1 --> * （一对多的关系）\n\n>唐僧类中应包含徒弟的集合，形成关联关系\n\n| 基数 | 含义 |\n| -- | -- |\n| 0..1 | 0个或者1个实例 |\n| 0..* | 对实例的数目没有限制（可以是0）|\n| 1 | 只有一个实例 |\n| 1..* | 至少有一个实例 |\n\n一个关联关系往往可以进一步确定为聚合关系或者合成关系。比如，唐僧与他的徒弟的关系就可以 进一步确定为聚合关系。\n\n# 聚合关系\n聚合（Aggregation)关系是关联关系的一种，是强的关联关系。聚合是整体和个体之间的关系。\n\n{% mermaid %}\n\nclassDiagram\nCar \"1\" o--> \"1\" Engine\nCar \"0\" o--> \"0..*\" Tire\nclass Car {\n    -engine : Engine \n}\n\n{% endmermaid %}\n\n# 合成关系\n合成(Composition)关系是关联关系的一种，是比聚合关系强的关系。它要求普通的聚合关系中代表整体的对象负责代表部分的对象的生命周期，合成关系是不能共享的。\n\n代表整体的对象需要负责保持部分对象的存活，在一些情况下负责将代表部分的对象湮灭掉。代表整体的对象可以将代表部分的对象传递给另一个对象，由后者负责此对象的生命周期。换言之，代表部分的对象在每一个时刻只能与一个对象发生合成关系，由后者排他地负责其生命周期。聚合关系和合成关系的类图如下图所示。\n\n{% mermaid %}\n\nclassDiagram\n\nclass MonkeyKing{\n    -limb : Limb[] \n    -staff : GoldRingedStaff \n}\nMonkeyKing \"1\" *--> \"4\" Limb\nMonkeyKing \"1\" o--> \"1\" GoldRingedStaff\n\n{% endmermaid %}\n\n在上面的类图中，显示了美猴王（MonkeyKing）以及他的四肢（Limb）和他的金箍棒（GoldRingedStaff)之间的关系。可以看出，MonkeyKing与GoldRingedStaff之间是聚合关系；而MonkeyKing与Limb之间的关系要比前者更强，是合成关系，因为美猴王的四肢完全由美猴王自己负责，并且不能共享。\n\n如果不能确定一个关系是不是合成关系，可以将之设置为聚合关系，甚至关联关系。\n\n# 依赖关系\n依赖（Dependency)也是类与类之间的连接，**依赖总是单向的**。依赖关系表示一个类依赖于另一个类的定义。一个人（Person）可以买车（Car）和房子（House），Person类依赖于Car类和House类，如下图所示。\n\n{% mermaid %}\n\nclassDiagram\nPerson ..> Car : Buys\nPerson ..> House : Buys\nPerson : +buy(...) void\nPerson : +buy(...) void\n\n{% endmermaid %}\n\n用golang代码表达一下上面的类图就是：\n\n```go\ntype Car struct {\n\n}\n\ntype House struct {\n\n}\n\ntype Person struct {\n\n}\n\nfunc (p *Person) BuyCar()  {\n\n}\n\nfunc (p *Person) BuyHouse()  {\n\n}\n```\n\n一般而言，依赖关系体现为局部变量、方法的参数，以及对静态方法的调用。换言之，一个类A的某一个局部变量的类型是另一个类B，那么类A就依赖于类B。如果一个方法的参数是另一个类B的实例，那么这个方法所在的类A依赖于类B。\n\n如果类B出现在类A的实例变量中，那么类A与类B的关系就超越了依赖关系，而变成了某一种关联关系。\n\n\n","tags":["设计模式","类图中的关系","关联关系","聚合关系","合成关系","依赖关系"],"categories":["设计模式","基本概念"]},{"title":"汇编中常见指令机器码","url":"/2022/12/16/汇编中常见指令机器码/","content":"\n# pop和push\n\n| pop机器码 | 含义 | push机器码 | 含义 |\n| -- | -- | -- | -- |\n| 5f | pop edi | 57 | push edi |\n| 5e | pop esi | 56 | push esi |\n| 5d | pop ebp | 55 | push ebp |\n| 5c | pop esp | 54 | push esp |\n| 5b | pop ebx | 53 | push ebx |\n| 5a | pop edx | 52 | push edx |\n| 59 | pop ecx | 51 | push ecx |\n| 58 | pop eax | 50 | push eax |\n\n\n# call \n```x86asm\ncall (short) eax\n; 1.将当前指令的下一条指令的地址压栈\n; 2.JMP到eax这个地址\n```\n\n```x86asm\ncall (long) eax\n; 1.将CS压栈\n; 2.将当前指令的下一条指令的地址压栈\n; 3.JMP到eax这个地址\n```\n\n# retn 和 retf\n```x86asm\nretn\n; 1.将当前的ESP中指向的地址出栈\n; 2.JMP到这个地址\n```\n\n```x86asm\nretn k\n; 1.将当前的ESP中指向的地址出栈\n; 2.JMP到这个地址\n; 3.弹出栈顶的k个字节的数据\n```\n\n```x86asm\nretf\n; 1.将当前的ESP中指向的地址出栈给EIP\n; 2.将当前的ESP中指向的地址出栈给CS\n; 3.JMP到这个地址\n```\n\n# jmp\n\n```x86asm\n; jmp 短跳\n\\xeb\\xf6: jmp short $-8 ;(其中$指代当前EIP)\n\n; 在Asm2MachineCode(x86)中如果要尝试jmp short $-8,是不可能实现的，但是我们可以：\n; 1. ImageBase (hex) 设置为0012ff60 (此处为当前的EIP地址)\n; 2. jmp short 0012FF58\n```\n\n```x86asm\n; jmp长跳\n\\xE9\\x2B\\xFF\\xFF\\xFF\\xFF: jmp 0x0012FF30\n\n; 在Asm2MachineCode(x86)中如果要尝试jmp short $-8，是不可能实现的，但是我们可以：\n; 1. ImageBase（hex）设置为0012ff58 (此处为当前的EIP地址)\n; 2. jmp 0012FE88\n```\n\n# cmp\n```x86asm\ncmp op1, op2\n```\n\n```\nZF=1 这个简单，说明两个操作数相等\n\n当无符号时：\nCF=1 则说明了有进位或借位，cmp是进行的减操作，故可以看出为借位，所以，此时oprd1<oprd2\nCF=0 则说明了无借位，但此时要注意ZF是否为0，若为0，则说明结果不为0，故此时oprd1>oprd2\n\n当有符号时：\n若SF=0，OF=0 则说明了此时的值为正数，没有溢出，可以直观的看出，oprd1>oprd2\n若SF=1，OF=0 则说明了此时的值为负数，没有溢出，则为oprd1<oprd2\n若SF=0，OF=1 则说明了此时的值为正数，有溢出，可以看出oprd1<oprd2\n若SF=1，OF=1则说明了此时的值为负数，有溢出，可以看出oprd1>oprd2\n\n最后两个可以作出这种判断的原因是，溢出的本质问题：\n两数同为正，相加，值为负，则说明溢出\n两数同为负，相加，值为正，则说明溢出\n故有，正正得负则溢出，负负得正则溢出\n```\n\n# leave\nleave在32位汇编下相当于\n```x86asm\nmove esp, ebp\npop ebp\n```\n\n# les\nLES( load ES)指令的功能是：把内存中指定位置的双字操作数的低位字装入指令中指定的寄存器、高位字装入ES寄存器。\n```x86asm\nLES DSET，SRC\nLES REG，MEM\n; DEST为destination(目的地址)，SRC为source(源地址)；\n; REG为register(CPU寄存器)，MEM为memory(内存地址)。\n```\n\n```\nDEST=WORD PTR[SRC]\n\nES=WORD PTR[SRC+2]\n\nDEST赋值为SRC处双字的低位；\n\nES赋值为SRC处双字的高位；\n```\n\n# 比较\n```\nA（above）大于、B（below）小于、E（equal）等于，用于比较无符号数\n\nG（great）大于、L（less than）小于、E（equal）等于，用于比较带符号数\n\n其实这些地方也是漏洞点，有时候比较没有对是否有符号进行确定，所以可能会出问题。\n```\n\n# lods/stos\n```\nlodsb指令，将esi指向的地址处的数据取出来赋给AL寄存器, esi=esi+1；\n\nlodsw指令则取得是一个字。\n\nlodsd指令，取得是双字节，即mov eax，[esi]，esi=esi+4；\n\nstosb指令，将AL寄存器的值取出来赋给edi所指向的地址处。mov [edi]，AL；edi=edi+1；\n\nstosw指令去的是一个字。\n\nstosd指令，取得是双字节，mov [edi]，eax；edi=edi+4；\n```","tags":["汇编","指令","机器码"],"categories":["汇编","指令"]},{"title":"cobra基本命令","url":"/2022/12/15/cobra基本命令/","content":"\n# 基本命令使用\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"github.com/spf13/cobra\"\n\t\"strings\"\n)\n\nfunc main() {\n\t// 定义一个命令\n\techoCmd := cobra.Command {\n\t\t//命令名称\n\t\tUse: \"echo\",\n\t\t// 命令执行过程，功能就是直接打印出命令行中的输入参数\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tfmt.Println(strings.Join(args, \" \"))\n\t\t},\n\t}\n\t// 执行命令\n\techoCmd.Execute()\n}\n\n```\n\n# cobra中的Cmd结构体\n```go\ntype Command struct {\n\t// 单行的描述信息，描述这个命令的作用，这段话的第一个单词会被作为命令的名称， 这个只能于子命合有意义，\n\t// 对于根命令没有意义\n\tUse string\n\n\t// Alias 可以用来给子命令定义别名，除了使用 Use 中的第一个单词作为子命令外，你还可以使用这个 Alias\n\t// 里面定义的任何一个名称作为子命令名称\n\tAliases []string\n\n\t// 当输入的命令和真正的命令名或别名不匹配时，会在SuggestFor数组中去匹配，始果匹配到了，然后提示是否\n\t// 需要输入xxx命令, 也就是说SuggestFor数组中预先设置一些和命令名或别名相似度较高的字符串，\n\t// 在用户误输入时可以用来提醒他\n\tSuggestFor []string\n\n\t// 在子命令的help信息中打印出来一串简短的命令描述\n\tShort string\n\n\t// 在子命令的help信息中打印出来一串较详细的命令描述，可以多行\n\tLong string\n\n\t// Example 用来定义子命令使用的具体示例，可以在里面定义多行不同的命令使用样例，供用户参考，这一点在\n\t// Kubectl 命令中体现的非常明显，因为 Kubectl 命令很复杂，参数也很多，样例会极大方便用户\n\tExample string\n\n\t// ValidArgs 是一组可用在 Bash 补全中的合法的Non-Flag参数\n\tValidArgs []string\n\n\t// Args 表示期望的参数\n\tArgs PositionalArgs\n\n\t// ArgAliases 是 ValidArgs 的一组别名\n\t// 这些参数不会在 Bash 补全中提示给用户，但是如果手动输入的话，也是允许的\n\tArgAliases []string\n\n\t// BashCompletionFunction 是 Bash 自动补全生成器使用的自定义函数\n\tBashCompletionFunction string\n\n\t// Deprecated 不为空的时候，在命令执行时都会提示命令已废弃，并且输出这段文字\n\tDeprecated string\n\n\t// Hidden 参数设置为 true 的时候，将无法在命令帮助列表中看到这个命令，但是实际这个命令仍然是可用的，一般用于\n\t// 对命令做向下兼容的处理，在未来的版本中如果这个命令会废弃，那么先让它隐藏起来会比直接删除较好\n\tHidden bool\n\n\t// Annotations 定义一些键值对，应用可以用这些注解来分组命令，主要用于标注上面的分组\n\tAnnotations map[string]string\n\n\t// Version 定义这个命令的版本。当 Version 值不为空，且命令没有定义 version 选项的时候，会自动给这个命令增加一个\n\t// boolean 类型，名称为 version 的选项。如果指定这个选项，就会输出这里 Version 的值。\n\tVersion string\n\n\t// 下面的这组 Run 函数执行顺序为：\n\t// * PersistentPreRun()\n\t// * PreRun()\n\t// * Run()\n\t// * PostRun()\n\t// * PersistentPostRun()\n\t// 所有的函数传入的参数都相同，都是命令名称之后的参数\n\n\t// PersistentPreRun 这个命令的子命令都将继承并执行这个函数\n\tPersistentPreRun func(cmd *Command, args []string)\n\t// PersistentPreRunE 和 PersistentPreRun 一样，但是遇到错误时可以返回一个错误\n\t// 一旦这个函数返回的 error 不为 nil，那么执行就中断了。所以你可以在这个函数里面\n\t// 做诸如权限验证等等全局性的工作\n\tPersistentPreRunE func(cmd *Command, args []string) error\n\n\t// PreRun 这个命令的子命令不会继承和运行这个函数\n\tPreRun func(cmd *Command, args []string)\n\t// PreRunE 和 PreRun 一样，但是遇到错误时可以返回一个错误\n\t// 一旦这个函数返回的 error 不为 nil，那么执行就中断了。所以你可以在这个函数里面\n\t// 做一些和该命令相关的输入参数检测之类的工作\n\tPreRunE func(cmd *Command, args []string) error\n\n\t// Run 命令核心工作所在的函数，大多数情况下只实现这个命令即可\n\tRun func(cmd *Command, args []string)\n\t// RunE 和 Run 一样，但是遇到错误时可以返回一个错误\n\t// 一旦这个函数返回的 error 不为 nil，那么执行就中断了。\n\tRunE func(cmd *Command, args []string) error\n\n\t// PostRun 在 Run 函数执行之后执行\n\tPostRun func(cmd *Command, args []string)\n\t// PostRunE 在 PostRun 之后执行，但是可以返回一个错误\n\t// 一旦这个函数返回的 error 不为 nil，那么执行就中断了。\n\tPostRunE func(cmd *Command, args []string) error\n\n\t// PersistentPostRun 在 PostRun 之后执行，这个命令的子命令都将继承并执行这个函数\n\tPersistentPostRun func(cmd *Command, args []string)\n\t// PersistentPostRunE 和 PersistentPostRun 一样，但是可以返回一个错误\n\t// 一旦这个函数返回的 error 不为 nil，那么执行就中断了。\n\tPersistentPostRunE func(cmd *Command, args []string) error\n\n\t// SilenceErrors 设置为 true 时可以在命令执行过程中遇到任何错误时，不显示错误\n\tSilenceErrors bool\n\n\t// SilenceUsage 设置为 true 时可以在命令执行遇到输入错误时，不显示使用方法（正确的使用方式）\n\tSilenceUsage bool\n\n\t// DisableFlagParsing 设置为 true 时将禁用选项解析功能，这样命令之后所有的内容\n\t// 都将作为参数传递给命令\n\tDisableFlagParsing bool\n\n\t// DisableAutoGenTag 在生成命令文档的时候是否显示 gen tag(\"Auto generated by spf13/cobra...\")\n\tDisableAutoGenTag bool\n\n\t// DisableFlagsInUseLine 设置为 true 的时候，将不会在命令帮助信息或者文档中显示命令支持的选项\n\tDisableFlagsInUseLine bool\n\n\t// DisableSuggestions 禁用命令提示\n\tDisableSuggestions bool\n\n\t// SuggestionsMinimumDistance 定义显示命令提示的最小的 Levenshtein 距离\n\tSuggestionsMinimumDistance int\n\n\t// TraverseChildren 在执行该命令子命令前，解析所有父命令的选项\n\tTraverseChildren bool\n\n\t// FParseErrWhitelist 定义可以被忽略的解析错误\n\tFParseErrWhitelist FParseErrWhitelist\n\n\t// commands is the list of commands supported by this program.\n\tcommands []*Command\n\t// parent is a parent command for this command.\n\tparent *Command\n\t// Max lengths of commands' string lengths for use in padding.\n\tcommandsMaxUseLen         int\n\tcommandsMaxCommandPathLen int\n\tcommandsMaxNameLen        int\n\t// commandsAreSorted defines, if command slice are sorted or not.\n\tcommandsAreSorted bool\n\t// commandCalledAs is the name or alias value used to call this command.\n\tcommandCalledAs struct {\n\t\tname   string\n\t\tcalled bool\n\t}\n\n\t// args is actual args parsed from flags.\n\targs []string\n\t// flagErrorBuf contains all error messages from pflag.\n\tflagErrorBuf *bytes.Buffer\n\t// flags is full set of flags.\n\tflags *flag.FlagSet\n\t// pflags contains persistent flags.\n\tpflags *flag.FlagSet\n\t// lflags contains local flags.\n\tlflags *flag.FlagSet\n\t// iflags contains inherited flags.\n\tiflags *flag.FlagSet\n\t// parentsPflags is all persistent flags of cmd's parents.\n\tparentsPflags *flag.FlagSet\n\t// globNormFunc is the global normalization function\n\t// that we can use on every pflag set and children commands\n\tglobNormFunc func(f *flag.FlagSet, name string) flag.NormalizedName\n\n\t// output is an output writer defined by user.\n\toutput io.Writer\n\t// usageFunc is usage func defined by user.\n\tusageFunc func(*Command) error\n\t// usageTemplate is usage template defined by user.\n\tusageTemplate string\n\t// flagErrorFunc is func defined by user and it's called when the parsing of\n\t// flags returns an error.\n\tflagErrorFunc func(*Command, error) error\n\t// helpTemplate is help template defined by user.\n\thelpTemplate string\n\t// helpFunc is help func defined by user.\n\thelpFunc func(*Command, []string)\n\t// helpCommand is command with usage 'help'. If it's not defined by user,\n\t// cobra uses default help command.\n\thelpCommand *Command\n\t// versionTemplate is the version template defined by user.\n\tversionTemplate string\n}\n```\n\n# 加强版例子\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"github.com/spf13/cobra\"\n\t\"strings\"\n)\n\nfunc main() {\n\trootCmd := cobra.Command{\n\t\t// 定义默认输出帮助信息\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tcmd.Help()\n\t\t},\n\t}\n\t// 定义子命令\n\techoCmd := cobra.Command{\n\t\t// 子命令描述，第一个单词作为子命令的名称\n\t\tUse: \"echo inputs\",\n\t\t// 子命令别名，可以使用任何一个别名替代上面的echo来运行子命令\n\t\tAliases: []string{\n\t\t\t\"copy\",\n\t\t\t\"repeat\",\n\t\t},\n\t\t// 命令提示，默认情况如果输入子命令不存在会提示 unknown cmd.\n\t\t// 但是如果定义了SuggestFor 的情况下，如果输入的命令不存在，会去SuggestFor\n\t\t// 里面查找是否有切尔西的字符串，如果有，则提示是否期望输入的是 echo 命令\n\t\tSuggestFor: []string{\n\t\t\t\"ech\", \"cp\", \"rp\",\n\t\t},\n\t\tDisableSuggestions: true,\n\t\tSuggestionsMinimumDistance: 2,\n\t\tDisableFlagsInUseLine: true,\n\t\t// 简单扼要概括下命令用途\n\t\tShort: \"echo is a command to echo command line inputs\",\n\t\t// 想说什么就在这里说吧，越详细越好，可以用``来跨行输入\n\t\tLong: `echo is a command to echo command line inputs.\nIt is a very simple command used to display how to implement command line tools\nusing cobra, which is a very famous library to build command line interface tools.\n`,\n\t\t// 当你新版本废弃这个命令的时候，可以先隐藏，让用户优先使用替代品或者看不到，\n\t\t// 但是处于向下兼容目的，这个命令仍然是可以用的，只是在帮助列表里面看不到\n\t\t//Hidden: true,\n\t\t// 当你需要废弃这个命令的时候设置。废弃的意思意味着未来版本可能删除这个命令。\n\t\t// 标注为废弃的命令在执行的时候，都会打印命令已废弃的提示信息以及这个设置的提示信息。\n\t\t//Deprecated: \"will be deleted in version 2.0\",\n\t\t// 注解，用于代码层面的命令分组，不会显示在命令行输出中\n\t\tAnnotations: map[string]string{\n\t\t\t\"group\": \"user\",\n\t\t\t\"require-auth\": \"none\",\n\t\t},\n\t\tSilenceErrors: true,\n\t\t//SilenceUsage: true,\n\t\t// Version 定义版本\n\t\tVersion: \"1.0.0\",\n\t\t// 是否禁用选项解析\n\t\t//DisableFlagParsing: true,\n\t\t//PersistentPreRun: func(cmd *cobra.Command, args []string) {\n\t\t//\tfmt.Println(\"haha! let me check echo\")\n\t\t//},\n\t\tPersistentPostRunE: func(cmd *cobra.Command, args []string) error {\n\t\t\t//return errors.New(\"invalid parameter\")\n\t\t\treturn nil\n\t\t},\n\t\t// 子命令执行过程\n\t\t//Run: func(cmd *cobra.Command, args []string) {\n\t\t//\tfmt.Println(strings.Join(args, \" \"))\n\t\t//},\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\n\t\t\tfmt.Println(strings.Join(args, \" \"))\n\t\t\treturn nil\n\t\t},\n\t\tPostRun: func(cmd *cobra.Command, args []string) {\n\t\t\tfmt.Println(\"i am post run\")\n\t\t},\n\t}\n\n\t// 把子命令添加到根命令下面\n\trootCmd.AddCommand(&echoCmd)\n\t// 执行根命令\n\trootCmd.Execute()\n}\n```","tags":["cobra"],"categories":["Golang","库","cobra"]},{"title":"Druid-程序骨架","url":"/2022/12/11/Druid-程序骨架/","content":"\n# Cargo.toml\n```toml\n[package]\nname = \"druid-gui-app\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n\n[dependencies]\ndruid = { git = \"https://github.com/linebender/druid.git\" }\ntracing = { version = \"0.1.22\" }\n\n[[bin]]\nname = \"druid-gui-app\"\npath = \"./src/main.rs\"\n\n[[bin]]\nname = \"example\"\npath = \"./previews/example.rs\"\n```\n>有两个[[bin]]，example可以用来编写一些示例用来预览效果，另外一个是真正的需要编写的程序。分别用下面的命令运行\n```shell\ncargo run --bin example # 运行示例程序\ncargo run --bin druid-gui-app # 运行主程序\n```\n\n# main.rs\n```rust\n#![windows_subsystem = \"windows\"]\n\nuse druid::widget::prelude::*;\nuse druid::widget::{Align, BackgroundBrush, Button, Controller, ControllerHost, Flex, Label, Padding, TextBox};\nuse druid::Target::Global;\nuse druid::{commands as sys_cmds, AppDelegate, AppLauncher, Application, Color, Command, Data, DelegateCtx, Handled, LocalizedString, Menu, MenuItem, Target, WindowDesc, WindowHandle, WindowId, WidgetExt, lens};\nuse tracing::{\n    info, warn, error,\n};\n\n///可以定义多个这样的结构体，用来自定义数据和组件进行一个“绑定”\n///把这个结构体和组件的data变量进行一个关联\n#[derive(Data, Clone)]\nstruct AppData {\n    data: String,\n}\n\n///程序入口函数\npub fn main() {\n    // window 绑定菜单栏\n    // let window = WindowDesc::new(ui_builder()).menu(make_menu);\n    let window = WindowDesc::new(ui_builder()).window_size((900.,600.)).title(\"窗口标题\").menu(make_menu);\n    AppLauncher::with_window(window)\n        .log_to_console()\n        .delegate(Delegate { windows: vec![] })\n        .launch(AppData {\n            data: String::new(),\n        })\n        .unwrap();\n}\n\n///\n///构建主界面\n///\nfn ui_builder() -> impl Widget<AppData> {\n    let data = lens!(AppData, data);\n    let text = TextBox::new().lens(data).expand().controller(ContextMenuController {});\n    text\n}\n\n/// 定义这个结构体，实现 Controller Trait，可以在实现对相关部件的事件处理\nstruct ContextMenuController;\n\n///保存程序中所有的窗口的ID到Vec\nstruct Delegate {\n    windows: Vec<WindowId>, \n}\n\n///\n///Controller 是一种管理子组件、重写或自定义其事件处理或更新行为的类型\n///这里Hook主界面的的那个TexBox组件的事件，然后进行相应的处理\n///\nimpl<W: Widget<AppData>> Controller<AppData, W> for ContextMenuController {\n    fn event(\n        &mut self,\n        child: &mut W,\n        ctx: &mut EventCtx,\n        event: &Event,\n        data: &mut AppData,\n        env: &Env,\n    ) {\n        match event {//事件匹配\n            Event::MouseDown(ref mouse) if mouse.button.is_right() => {//这个语法...比较丝滑, 但和其它语言确实不太一样\n                ctx.show_context_menu(make_context_menu(), mouse.pos);\n            }\n            _ => child.event(ctx, event, data, env),\n        }\n    }\n}\n\n///这里是Hook顶层事件，可以Hook顶层事件进行自定义处理，可以取出cmd的值，判断是什么事件\nimpl AppDelegate<AppData> for Delegate {\n    fn command(\n        &mut self,\n        ctx: &mut DelegateCtx,\n        _target: Target,\n        cmd: &Command,\n        data: &mut AppData,\n        _env: &Env,\n    ) -> Handled {\n        info!(\"u can handle system command here...\");\n        Handled::No\n    }\n\n    fn window_added(\n        &mut self,\n        id: WindowId,\n        _handle: WindowHandle,\n        _data: &mut AppData,\n        _env: &Env,\n        _ctx: &mut DelegateCtx,\n    ) {\n        info!(\"Window added, id: {:?}\", id);\n        self.windows.push(id);\n    }\n\n    fn window_removed(\n        &mut self,\n        id: WindowId,\n        _data: &mut AppData,\n        _env: &Env,\n        _ctx: &mut DelegateCtx,\n    ) {\n        info!(\"Window removed, id: {:?}\", id);\n        if let Some(pos) = self.windows.iter().position(|x| *x == id) {\n            self.windows.remove(pos);\n        }\n        if self.windows.len() == 0 {\n            Application::global().quit(); // 这里如果所有窗口都已关闭，那就退出APP\n        }\n    }\n}\n\n///主菜单的构建\n#[allow(unused_assignments)]\nfn make_menu(_: Option<WindowId>, data: &AppData, _: &Env) -> Menu<AppData> {\n    let mut base = Menu::empty();\n    #[cfg(target_os = \"macos\")]\n    {\n        // base = druid::platform_menus::mac::menu_bar();\n    }\n    #[cfg(any(\n    target_os = \"windows\",\n    target_os = \"freebsd\",\n    target_os = \"linux\",\n    target_os = \"openbsd\"\n    ))]\n    {\n        base = base.entry(druid::platform_menus::win::file::default());\n    }\n    base = base.entry(MenuItem::new(\"新建\").on_activate(|_ctx, data: &mut AppData, _env| {\n        info!(\"appdata:{}\", data.data);\n    }));\n    base\n}\n\n///主界面中的TextBox组件的右键菜单的构建\nfn make_context_menu() -> Menu<AppData> {\n    Menu::empty()\n        .entry(\n            MenuItem::new(\"右键菜单1\")\n                .on_activate(|_ctx, data: &mut AppData, _env| {\n                    info!(\"可以在这里添加右键菜单1的响应事件\");\n                }),\n        )\n}    \n```\n","tags":["Rust","GUI"],"categories":["Rust","GUI"]},{"title":"C++ GUI--imgui库使用样板CMakefile","url":"/2022/12/08/Cpp-GUI-imgui库使用样板CMakefile/","content":"\n# imgui\n\n先上链接：[github地址](https://github.com/ocornut/imgui)\n\n`imgui`是一个轻量级，但是小而全的一个`cpp`界面库。作者应该是游戏开发行业的，这个库用来实现开发游戏还是比较适合的。虽然它是跨平台的，但是例子代码全是用`visual studio`的工程。在mac或linux下还不能做到完全的开箱即用。所以在网上搜索了一番，找到了一个[CMakeFile.txt](https://github.com/tashaxing/imgui_cmake_starter)可以跨平台的，我在`Mac`下尝试编译了一下，完全可以，非常感谢！\n\n但是它的工程中使用的imgui不是最新的，我就拉取了一下imgui代码，替换掉它这个工程中的imgui，然后目录结构也稍作了一下调整。CMakeFile也稍相应地作了一下调整。\n\n# CMakeFile.txt\n```makefile\ncmake_minimum_required(VERSION 3.0)\n\nproject(imgui_cmake_starter)\n\n# add header path\ninclude_directories(\n\t${CMAKE_CURRENT_SOURCE_DIR}/3rd/imgui\n\t${CMAKE_CURRENT_SOURCE_DIR}/3rd/imgui/backends\n)\n\nif (APPLE)\n    # for <GLFW/glfw3.h>\n    include_directories(\n        /usr/local/include\n        /opt/local/include\n        /opt/homebrew/include\n    )\nendif()\n\n# set common source\nfile(GLOB SRC\n    ./3rd/imgui/*.h\n    ./3rd/imgui/*.cpp\n)\n\n# set specific source and other option for platform\nif (WIN32)\n    file (GLOB PLATFORM_SRC\n        ./3rd/imgui/backends/imgui_impl_win32.*\n        ./3rd/imgui/backends/imgui_impl_dx12.*\n        ./src/win/main.cpp\n    )\nelseif (UNIX)\n    # support both mac and linux\n    add_definitions(-DIMGUI_IMPL_OPENGL_LOADER_GL3W)\n\n    include_directories(\n        ${CMAKE_CURRENT_SOURCE_DIR}/3rd/imgui/examples/libs/gl3w # for GL/gl3w.h\n    )\n\n    file (GLOB PLATFORM_SRC\n        ./3rd/imgui/examples/libs/gl3w/GL/gl3w.*\n        ./3rd/imgui/backends/imgui_impl_glfw.*\n        ./3rd/imgui/backends/imgui_impl_opengl3.*\n        ./src/unix/main.cpp\n    )\nendif()\n\n# add link path\nif (APPLE)\n    link_directories(\n        /usr/local/lib\n        /opt/homebrew/lib\n#       这下面根据需要添加lib路径\n#       /opt/local/lib\n    )\nendif()\n\n# specify the C++ standard\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_CXX_STANDARD_REQUIRED True)\n\n# generate binary\nadd_executable(${PROJECT_NAME} ${SRC} ${PLATFORM_SRC})\n\n# link lib, should install glfw first or prebuild lib and embed in project\nif (WIN32)\n    target_link_libraries(${PROJECT_NAME}\n        d3d12.lib\n        d3dcompiler.lib\n        dxgi.lib\n    )\nelseif (APPLE)\n    # mac: brew install glfw3\n    find_library(OPENGL_LIBRARY OpenGL REQUIRED)\n    find_library(COCOA_LIBRARY Cocoa REQUIRED)\n    find_library(IOKIT_LIBRARY IOKit REQUIRED)\n    find_library(COREVID_LIBRARY CoreVideo REQUIRED)\n    message(${COCOA_LIBRARY})\n    message(${IOKIT_LIBRARY})\n    message(${COREVID_LIBRARY})\n\n    target_link_libraries(${PROJECT_NAME}\n        ${OPENGL_LIBRARY}\n        ${COCOA_LIBRARY}\n        ${IOKIT_LIBRARY}\n        ${COREVID_LIBRARY}\n        glfw # use this lib name\n    )\nelseif (UNIX AND NOT APPLE)\n    # linux: sudo apt install libglfw3-dev\n    target_link_libraries(${PROJECT_NAME}\n        GL\n        glfw # use this lib name\n        dl\n    )\nendif()\n\n```\n\n>以上的CMakeFile.txt文件内容我稍作调整：imgui我git pull了最新的代码下来，放在了工程目录下的3rd目录下面；我使用mac编译这个工程最到两个小问题，稍作记录\n\n## 问题1\n- 问题描述：我拉取的imgui版本使用的语法需要C++11标准的支撑，如果版本编译器的C++标准较低则会出现编译问题\n- 解决办法：在CMakeFile.txt中指定C++标准\n    ```\n    # specify the C++ standard\n    set(CMAKE_CXX_STANDARD 11)\n    set(CMAKE_CXX_STANDARD_REQUIRED True)\n    ```\n\n## 问题2\n- 问题描述：我拉取的imgui代码目录`imgui/examples/libs/gl3w` 是不存在的，编译时`main.cpp`中以下语句会报错\n\n    ```cpp\n\n    #include <GL/gl3w.h>    \n\n    ```\n- 问题解决：缺什么补什么，就缺一个目录及几个文件，给它配齐就好\n\n# 跨平台玩耍起来\n以上部分已经完成了，[代码](https://github.com/Lost-Temple/imgui-starter)\n要用imgui进行跨平台开发桌面应用啥的，直接拉取代码后当作个脚手架就可以开干了。\n","tags":["cmake","c++","cpp","mac","跨平台"],"categories":["C++","GUI"]},{"title":"Fabric SDK相关","url":"/2022/12/05/Fabric-SDK相关/","content":"\n# Fabric SDK 介绍\n`Fabric`的`Peer`节点和`Orderer`节点都提供了基于`gRPC`协议的接口，用于和`Peer`节点与`Orderer`节点进行命令/数据交互。为了简化开发，为开发人员开发应用程序提供操作`Fabric`区块链网络的API，Fabric官方提供了多种语言版本的SDK。\nFabric提供了多种语言版本的SDK：\n- [fabric-sdk-java](https://github.com/hyperledger/fabric-sdk-java)\n- [fabric-sdk-go](https://github.com/hyperledger/fabric-sdk-go)\n- [fabric-sdk-node](https://github.com/hyperledger/fabric-sdk-node)\n- [fabric-sdk-py](https://github.com/hyperledger/fabric-sdk-py)\n\n`Fabric`区块链应用可以通过SDK访问`Fabric`区块链网络中的多种资源，包括账本、交易、链码、事件、权限管理等。应用程序代表用户与`Fabric`区块链网络进行交互，`Fabric SDK API`提供了如下功能：\n- 创建通道\n- 将`Peer`节点加入通道\n- 在`Peer`节点安装链码\n- 在通道实例化链码\n- 通过链码调用交易\n- 查询交易或区块的账本\n\n# Fabric SDK 安装\n```shell\ngo get -u github.com/hyperledger/fabric-sdk-go\n```\n\n# Fabric Go SDK 源码结构\n```\ntotal 624\n-rw-r--r--   1 mao  staff   170K Aug 15 14:45 CHANGELOG.md\n-rw-r--r--   1 mao  staff   108B Aug 15 14:45 CODEOWNERS\n-rw-r--r--   1 mao  staff   577B Aug 15 14:45 CODE_OF_CONDUCT.md\n-rw-r--r--   1 mao  staff   661B Aug 15 14:45 CONTRIBUTING.md\n-rw-r--r--   1 mao  staff    11K Aug 15 14:45 LICENSE\n-rw-r--r--   1 mao  staff   910B Nov  2 08:36 MAINTAINERS.md\n-rw-r--r--   1 mao  staff    33K Aug 15 14:45 Makefile\n-rw-r--r--   1 mao  staff   7.3K Aug 15 14:45 README.md\n-rw-r--r--   1 mao  staff   1.0K Aug 15 14:45 SECURITY.md\ndrwxr-xr-x   4 mao  staff   128B Aug 15 14:45 ci\n-rw-r--r--   1 mao  staff   143B Aug 15 14:45 ci.properties\n-rw-r--r--   1 mao  staff   2.3K Aug 15 14:45 doc.go\n-rw-r--r--   1 mao  staff   1.2K Aug 15 14:45 go.mod\n-rw-r--r--   1 mao  staff    45K Aug 15 14:45 go.sum\n-rwxr-xr-x   1 mao  staff   1.6K Aug 15 14:45 golangci.yml\ndrwxr-xr-x   3 mao  staff    96B Aug 15 14:45 internal\ndrwxr-xr-x  11 mao  staff   352B Aug 15 14:45 pkg\ndrwxr-xr-x   5 mao  staff   160B Aug 15 14:45 scripts\ndrwxr-xr-x   7 mao  staff   224B Aug 15 14:45 test\ndrwxr-xr-x   3 mao  staff    96B Aug 15 14:45 third_party\n```\n\n- `pkg/fabsdk`: Fabric SDK的主要包、允许基于配置创建上下文。上下文由客户端软件包使用。\n- `pkg/client/channel`: 提供通道交易相关功能\n- `pkg/client/event`: 提供通道事件相关功能\n- `pkg/client/ledger`: 启用对通道底层账本的查询相关功能\n- `pkg/client/resmgmt`: 提供资源管理功能，例如安装链码\n- `pkg/client/msp`: 启用身份管理相关功能\n\n# Fabric SDK功能模块\n## API\n对于应用开发者来说，插件化的API可以支持SDK提供的关键接口的可选实现。对于每个接口，都有内置的默认实现，也可以灵活自定义。\n\n## fabric-client\n`fabric-client`模块提供API与基于`Hypreledger Fabric`区块链网络的核心组件（即`peer`，`order`和`事件流`）进行交互，主要功能如下：\n- 创建`channel`\n- 请求`Peer`节点加入通道\n- 在`Peer`节点中安装链码\n- 在通道中实例化链码\n- 通过调用链码来调用事务\n- 多种查询\n- 监听事件\n\n## fabric-ca-client\n`fabric-ca-client`模块提供与可选组件`fabric-ca`进行交互的API，`fabric-ca`提供成员管理服务。`fabric-ca-client`模块主要功能如下：\n- 注册新用户\n- 注册用户以获得由`Fabric CA`签名的注册证书\n- 通过注册ID撤销现有用户或撤消证书\n- 可定制的持久化存储","tags":["通道","链码","Peer","Orderer","gRPC"],"categories":["区块链","Fabric"]},{"title":"x64寄存器","url":"/2022/12/04/x64寄存器/","content":"\n| 64位寄存器 | 低32位 | 低16位 | 低8位 |\n| -- | -- | -- | -- |\n|rax　|　　　eax　|　　　ax　　|　　  al|\n|rcx　|　　　ecx　|　　　cx　　|　　  cl|\n|rdx　|　　　edx　|　　　dx　　|　　  dl|\n|rbx　　|　　ebx　　|　　bx　　　|　  bl|\n|rsp　　|　　esp　　　|　sp　　　|   spl |\n|rbp　　|　　ebp　　|　　bp　　　|   bpl|\n|rsi　　|　　esi　　|　　si　　　|　 sil|\n|rdi　　|　　edi　　|　　di　　　　| dil|\n|r8　　　|　 r8d    |  r8w     |  r8b|\n|r9　　　|　 r9d 　　|　r9w　　　|　 r9b|\n|r10  　|　 r10d 　　| r10w  　　| r10b|\n|r11   |　　r11d 　　| r11w    |  r11b|\n|r12　　|　 r12d　　　| r12w  　|　r12b|\n|r13  　|　 r13d 　　　|r13w    | r13b|\n|r14   |   r14d    |  r14w    |  r14b|\n|r15   |   r15d    |  r15w    |  r15b|\n\n>此外还有rip， xmm0~xmm15的多媒体用寄存器，rflags。","tags":["寄存器","x64"],"categories":["汇编","指令"]},{"title":"NOP指令","url":"/2022/12/03/NOP指令/","content":"\n>Jdk9 源码有一段关于NOP汇编指令的注释，摘抄记录一下\n\n# Intel[源码链接](http://hg.openjdk.java.net/jdk9/jdk9/hotspot/file/31e4d11eab11/src/cpu/x86/vm/assembler_x86.cpp#l2792)\n```\n    // Using multi-bytes nops \"0x0F 0x1F [address]\" for Intel\n    //  1: 0x90\n    //  2: 0x66 0x90\n    //  3: 0x66 0x66 0x90 (don't use \"0x0F 0x1F 0x00\" - need patching safe padding)\n    //  4: 0x0F 0x1F 0x40 0x00\n    //  5: 0x0F 0x1F 0x44 0x00 0x00\n    //  6: 0x66 0x0F 0x1F 0x44 0x00 0x00\n    //  7: 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00\n    //  8: 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00\n    //  9: 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00\n    // 10: 0x66 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00\n    // 11: 0x66 0x66 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00\n\n    // The rest coding is Intel specific - don't use consecutive address nops\n\n    // 12: 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00 0x66 0x66 0x66 0x90\n    // 13: 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00 0x66 0x66 0x66 0x90\n    // 14: 0x66 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00 0x66 0x66 0x66 0x90\n    // 15: 0x66 0x66 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00 0x66 0x66 0x66 0x90\n```\n\n# AMD[源码链接](http://hg.openjdk.java.net/jdk9/jdk9/hotspot/file/31e4d11eab11/src/cpu/x86/vm/assembler_x86.cpp#l2876)\n```\n    // Using multi-bytes nops \"0x0F 0x1F [address]\" for AMD.\n    //  1: 0x90\n    //  2: 0x66 0x90\n    //  3: 0x66 0x66 0x90 (don't use \"0x0F 0x1F 0x00\" - need patching safe padding)\n    //  4: 0x0F 0x1F 0x40 0x00\n    //  5: 0x0F 0x1F 0x44 0x00 0x00\n    //  6: 0x66 0x0F 0x1F 0x44 0x00 0x00\n    //  7: 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00\n    //  8: 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00\n    //  9: 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00\n    // 10: 0x66 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00\n    // 11: 0x66 0x66 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00\n\n    // The rest coding is AMD specific - use consecutive address nops\n\n    // 12: 0x66 0x0F 0x1F 0x44 0x00 0x00 0x66 0x0F 0x1F 0x44 0x00 0x00\n    // 13: 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00 0x66 0x0F 0x1F 0x44 0x00 0x00\n    // 14: 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00\n    // 15: 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00\n    // 16: 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00\n    //     Size prefixes (0x66) are added for larger sizes\n```","tags":["汇编","指令"],"categories":["汇编","指令"]},{"title":"Golang单元测试和基准测试","url":"/2022/12/02/Golang单元测试和基准测试/","content":"\n# 单元测试\n- 测试需要用到的断言，依赖\n`github.com/stretchr/testify`\n\n- 编写单元测试，文件命名带`_test.go`\n`helloworld_test.go`\n```go\nimport \"testing\"\nfunc TestHelloWorld(t *testing.T) {\n    t.Log(\"hello world\")\n}\n```\n- 测试所有用例\n```shell\ngo test -v helloworld_test.go\n```\n- 指定用例\n``` shell\ngo test -v -run TestHelloWorld helloworld_test.go\n```\n- 测试文件夹下所有的测试用例\n```shell\ngo test -v ./directory\n```\n\n# 基准测试\n- 非并发方式\n`benchmark_test.go`\n```go\nfunc Benchmark_Add(b *testing.B) {\n    var n int\n    for i := 0; i < b.N; i++ {\n        n++\n    }\n}\n```\n>**注：b.N 由基准测试框架提供。测试代码需要保证函数可重入性及无状态，也就是说，测试代码不使用全局变量等带有记忆性质的数据结构。避免多次运行同一段代码时的环境不一致，不能假设 N 值范围。**\n\n- 并发方式\n```go\nfunc Benchmark_Dosomething(b *testing.B) {\n\tb.SetParallelism(8)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\tDosomething()\n\t\t}\n\t})\n}\n```\n>**注：SetParallelism用来设置协程数量**\n\n# 基准测试脚本编写\n```shell\n#!/bin/sh\ngo test -bench=. -run=none \\\n  -benchtime=300s \\\n  -benchmem -memprofile=mem.pprof \\\n  -cpuprofile=cpu.pprof \\\n  -cpu=8 \\\n  -timeout=0 \\\n  -blockprofile=block.pprof ./directory/\n```\n\n>**基准测试默认10分钟，如果测试总时长超过10分钟，测试的进程会被kill掉，所以指定timeout=0表示不限时长**\n\n# go基准测试源码中`benchmark.go`\n有这么一个核心方法\n```go\n// launch launches the benchmark function. It gradually increases the number\n// of benchmark iterations until the benchmark runs for the requested benchtime.\n// launch is run by the doBench function as a separate goroutine.\n// run1 must have been called on b.\nfunc (b *B) launch() {\n\t// Signal that we're done whether we return normally\n\t// or by FailNow's runtime.Goexit.\n\tdefer func() {\n\t\tb.signal <- true\n\t}()\n\n\t// Run the benchmark for at least the specified amount of time.\n\tif b.benchTime.n > 0 { // 这里表示测试时是使用了次数限制，例如指定了参数-benchtime=1000x表示执行1000次\n\t\t// We already ran a single iteration in run1.\n\t\t// If -benchtime=1x was requested, use that result.\n\t\t// See https://golang.org/issue/32051.\n\t\tif b.benchTime.n > 1 {\n\t\t\tb.runN(b.benchTime.n)\n\t\t}\n\t} else { // 这个分支表示指定的是时间限制（区别于次数限制），例如指定了参数-benchtime=5s给示每个用例执行5s（这里会根据实际情况运行，而非精确的5s）\n\t\td := b.benchTime.d\n        // 注意下面循环条件中的n的值的上限\n\t\tfor n := int64(1); !b.failed && b.duration < d && n < 1e9; {\n\t\t\tlast := n\n\t\t\t// Predict required iterations.\n\t\t\tgoalns := d.Nanoseconds()\n\t\t\tprevIters := int64(b.N)\n\t\t\tprevns := b.duration.Nanoseconds()\n\t\t\tif prevns <= 0 {\n\t\t\t\t// Round up, to avoid div by zero.\n\t\t\t\tprevns = 1\n\t\t\t}\n\t\t\t// Order of operations matters.\n\t\t\t// For very fast benchmarks, prevIters ~= prevns.\n\t\t\t// If you divide first, you get 0 or 1,\n\t\t\t// which can hide an order of magnitude in execution time.\n\t\t\t// So multiply first, then divide.\n\t\t\tn = goalns * prevIters / prevns\n\t\t\t// Run more iterations than we think we'll need (1.2x).\n\t\t\tn += n / 5\n\t\t\t// Don't grow too fast in case we had timing errors previously.\n\t\t\tn = min(n, 100*last)\n\t\t\t// Be sure to run at least one more than last time.\n\t\t\tn = max(n, last+1)\n\t\t\t// Don't run more than 1e9 times. (This also keeps n in int range on 32 bit platforms.)\n\t\t\tn = min(n, 1e9)\n\t\t\tb.runN(int(n))\n\t\t}\n\t}\n\tb.result = BenchmarkResult{b.N, b.duration, b.bytes, b.netAllocs, b.netBytes, b.extra}\n}\n```\n\n>在基准测试时，如果设定的是时间限制，即每个测试用例执行多少时间。因为每次执行的时间都不可能完全一致，所以用例的执行次数到底应该为多少次，这个值是会被估算出来的，估算的过程就是在以下的循环中。\n```go\nfor n := int64(1); !b.failed && b.duration < d && n < 1e9; {\n    // 每一次循环，我们称之为以下过程的一轮，每一轮总的分为2个步骤\n    // 1.估算一下n，n即是接下来用例需要执行多少次？\n    // 2.估算好后，调用b.runN(int(n)) n的值为多少，用例这一轮就被调用了多少次\n}\n```\n\n- 明确了大体的流程后，我们来分析一下细节：\n  - n的上限问题\n    >设定的用例执行时间还没到，但是用例执行次数已到，那就只有提前结束循环，也就意味着没法再驱动b.runN(int(n))的调用；也就会出现还没到设定时间，用例提前结束了。说明用例执行较快。这种情况换执行次数限定比较合适？\n\n  - n的估算中有一个公式的问题\n\n    `n = goalns * prevIters / prevns`\n\n    - `goalns`是用例执行的目标时间，单位ns\n    - `prevIters`是`上一轮`用例的执行次数\n    - `prevens`是`上一轮`用例的执行时间，单位ns\n\n    >那么问题来了：如果goalns的值较大（设置了比较长的用例测试时间，上一轮的测试次数也较大，但是上一轮的用例测试时间很短，那根据公式，估算出来的n可能很大，可能比int64的区间范围要大，溢出后就会变成一个负值。\n    >变成负值之后,n的增长逻辑就不一样了，分析一下：\n    >n += n / 5  -> n还是负值\n    >n = min(n, 100*last) -> n的值还是n\n    >n = max(n, last+1) -> 变为上一轮估算的值+1 == (last + 1)\n    >n = min(n, 1e9) -> n == (last + 1)\n    >同理，每一轮估算，估算值都是以1步进，问题就出现了：从n值溢出开始，假设这个时候last的值为 1e8，那n的值变化规率为100000001, 100000002, 100000003, ...,这样如果想让\bn达到1e9，要`1e9 - 1e8` 轮, 而且每轮要执行用例n次。注意：这只是一个估算的过程，还没真正开始做基准测试呢...这个估算执行次数的过程就已经很消耗时间了,最终有可能超过10min，因为go benchmark的默认执行时间就是10min，这个时候测试进程会被强杀，并提示执行超时的错误。\n\n# 基准测试问题重现方法\n- 写一个耗时很短的用例\n- 设置一个较长的用例测试时间（不用太长，比如200s就行，只要想办法让n值溢出即可）\n- 执行一下...就等着10min钟以后吧\n\n# 解决办法\n- 1. 上面提到的n溢出问题，虽然觉得benchmark.go里面的代码确实有点问题，可以把n的数据类型再改大一些如float64，在方法中增加判断溢出后进行特殊处理。\n- 2. 出现这种情况，说明被测试的用例做长时间测试的必要性值得商榷\n\n# 另外\n>func (b *B) launch() 是非并行模式下会被调用的方法；同样在并行模式下，调用的是func (b *B) RunParallel(body func(*PB)) 应该同样存在类似问题。\n","tags":["unit test","benchmark test"],"categories":["Golang","测试"]},{"title":"centos 多gcc版本环境","url":"/2022/11/30/centos-多gcc版本环境/","content":"# 背景\n- 在本地PC使用`Jetbrains gateway`新建ssh远程开发, 打开服务器上的代码进行开发\n- CentOS 系统中的`gcc`和`g++`版本太低。不支持`c++11`标准，需要安装新的开发环境\n- CLion 项目中的`CMakeList.txt`需要配置能编译`c++11标准`的`gcc`和`g++`\n    \n# 编译工具安装\n```shell\n    sudo yum install centos-release-scl-rh\n    sudo yum install devtoolset-11-gcc-c++\n```\n> 安装完成后，执行以下命令可以切换到新的编译环境\n```shell\n    sudo scl enable devtoolset-11 bash\n```\n> 可以查看devtoolset-11相关工具的版本及它们的路径\n```shell\n    g++ --version\n    gcc --version\n```\n```shell\n    which g++\n    which gcc\n```\n\n# 开发工具中的配置修改\n> 需要指定编译器路径(**根据自己编译器路径进行修改**)\n```\n    SET(CMAKE_C_COMPILER \"/opt/rh/devtoolset-11/root/usr/bin/gcc\")\n    SET(CMAKE_CXX_COMPILER \"/opt/rh/devtoolset-11/root/usr/bin/g++\")\n```\n\n# 调用动态库需要注意的点\n> 在加载`so`库的模块相应的`.h`文件中要 #include <dlfcn.h>\n> 在CMakefile.txt里面添加编译选项，如：\n> TARGET_LINK_LIBRARIES(projName dl)\n> 其中`projName`为项目的名称","tags":["c++","cenos","CLion","Jetbrains gateway","远程开发"],"categories":["Linux"]},{"title":"CGO内存踩坑记录","url":"/2022/11/24/CGO内存踩坑记录/","content":"\n# 应用场景\n\n将 Go 内存中的字符串或字节切片传入 C 语言函数的应用场景。\n\n# 里面的坑\n\n假设一个极端场景：我们将一块位于某 `goroutine` 的栈上的` Go `语言内存传入了 `C `语言函数后，在此` C `语言函数执行时，如果 `goroutinue `的栈因为空间不足的原因发生了**扩展**，也就是导致了原来的 `Go `语言内存被移动到了新的位置。但是这时` C `语言函数并不知道该 `Go `语言内存已经移动了位置，仍然用之前的地址来操作该内存——也就是**“野指针”**。不是必现，要看内存中的数据是否发生移动。\n\n以上操作本质上看是一种**“传引用”**，可以借助 C 语言内存稳定的特性（谁`malloc`就由谁来`free`，代码编写者自己对内存进行管理），在 C 语言空间先开辟同样大小的内存，然后将 Go 的内存填充到 C 的内存空间（**复制了一个副本过去**）。下面的例子是这种思路的具体实现：\n\n# 例1\n\n```go\npackage main\n\n/*\n#include <stdlib.h>\n#include <stdio.h>\n\nvoid printString(const char* s) {\n    printf(\"%s\", s);\n}\n*/\nimport \"C\"\nimport \"unsafe\"\n\nfunc printString(s string) {\n    cs := C.CString(s) // 这里会在C的内存空间里面开辟一块空间，把GO中的字符串s的值拷贝过去\n    defer C.free(unsafe.Pointer(cs)) // 这里用defer 进行延迟操作，释放这块在C里面开辟的空间，不然就是内存泄漏\n\n    C.printString(cs)\n}\n\nfunc main() {\n    s := \"hello\"\n    printString(s)\n}\n```\n\n这种方式虽然解决了问题，但是，写法有点啰嗦，还要自己手动`C.free`。最主要的是：性能效率有损失，因为要从`GO`环境把内存复制到`C`语言环境内存中。\n\n# 例2\n\n```go\npackage main\n\n/*\n#include<stdio.h>\n\nvoid printString(const char* s, int n) {\n    int i;\n    for(i = 0; i < n; i++) {\n        putchar(s[i]);\n    }\n    putchar('\\n');\n}\n*/\nimport \"C\"\n\nfunc printString(s string) {\n    p := (*reflect.StringHeader)(unsafe.Pointer(&s)) // 把字符串的内存地址赋值给了p\n    C.printString((*C.char)(unsafe.Pointer(p.Data)), C.int(len(s))) // 传入参数\n}\n\nfunc main() {\n    s := \"hello\"\n    printString(s)\n}\n```\n\n现在的处理方式更加直接，且避免了分配额外的内存，而且CGO会保证在C函数调用期间（从C语言函数被调用到C语言函数调用结束），传入的指针指向的这块GO语言开辟的内存不会被移动。注意：~~**`CGO只会保证在C函数调用期间`**。~~ 在网上有看到这个说法，但是我实践中似乎有出入。我实践中就是用这个用法，结果GG了，我实践中它好像也不能保证这一点，这个后续再研究研究。\n\n就算CGO会保证在C函数调用期间保证内存不会被移动，这里还有有一个容易踩的坑：\n\n```go\n// 错误的代码\np := (*reflect.StringHeader)(unsafe.Pointer(&s)) // 把字符串的内存地址赋值给了p\ntmp := uintptr(p)\nptr := (*reflect.StringHeader)(unsafe.Pointer(tmp))\nC.printString((*C.char)(unsafe.Pointer(ptr.Data)), C.int(len(s))) // 传入参数\n```\n\n因为 tmp 并不是指针类型(它只是表示内存地址，但并没有指针的**语义**，指针和内存地址还是有点差别的，差别在于指针是有数据类型的，是和指向的内存中的数据进行了“绑定的”，而内存地址仅仅是地址而已)。在它获取到` Go `对象地址之后`s`对象可能会被移动，但是因为不是`tmp`没有指针语义，所以不会被` Go` 语言运行时更新成新内存的地址(`s`对象新的移动后的位置）。在`tmp`中保持 `Go` 对象的地址，和在` C` 语言环境保持` Go` 对象的地址的效果是一样的：如果原始的` Go `对象内存发生了移动，Go 语言运行时并不会同步更新它们。这样就还是会触发一开始的那个问题。\n\n所以，还是慎用例2的方法吧\n\n**续：**我去看了`StringHeader`的数据结构和`SliceHeader`数据结构\n\n```go\n// StringHeader is the runtime representation of a string.\n// It cannot be used safely or portably and its representation may\n// change in a later release.\n// Moreover, the Data field is not sufficient to guarantee the data\n// it references will not be garbage collected, so programs must keep\n// a separate, correctly typed pointer to the underlying data.\ntype StringHeader struct {\n\tData uintptr\n\tLen  int\n}\n\n// SliceHeader is the runtime representation of a slice.\n// It cannot be used safely or portably and its representation may\n// change in a later release.\n// Moreover, the Data field is not sufficient to guarantee the data\n// it references will not be garbage collected, so programs must keep\n// a separate, correctly typed pointer to the underlying data.\ntype SliceHeader struct {\n\tData uintptr\n\tLen  int\n\tCap  int\n}\n```\n\n看到`Data`的类型是`uintptr`就感觉不妙了...这里自己实现一个可能能解决问题，我能想到的，go标准库的开发者会想不吗？肯定是有什么原因的。所以，还是最好不用`StringHeader`了。\n\n```go\ntype StringHeader struct {\n\tData unsafe.Pointer\n\tLen  int\n}\n```\n\n","tags":["CGO","内存"],"categories":["Golang","CGO"]},{"title":"Rust学习-知识点-7","url":"/2022/11/20/Rust学习-知识点-7/","content":"\n[前方高能，过份帅气](https://github.com/usagi/rust-memory-container-cs)\n\n![rust-memory-container-cs-3840x2160-dark-back.png](https://s2.loli.net/2022/11/20/iIUBf4FDuCOs7jq.png)\n","tags":["内存","memory"],"categories":["Rust","基础"]},{"title":"Rust学习-知识点-6","url":"/2022/11/19/Rust学习-知识点-6/","content":"\n# 语句和表达式\n\n- 函数体由一系列语句组成\n- 函数可以由一个表达式结束（这种情况下，表达式的值为函数的返回值）\n- `rust`是基于表达式的语言\n- 语句是执行一些动作的指令\n- 表达式会计算产生一个值\n\n```rust\nfn main() {\n  let x = 0;\n  let y = {\n    let x = 1; // 我就是第5行\n    x + 1\n  };\n}\n```\n\n**注：第5行， x + 1 后面的无`;`。这里`x + 1`就是一个表达式，它的计算结果就返回赋值给了`y`。**\n\n那如果`x + 1`后面加上`;`呢？即：\n\n```rust\nfn main() {\n  let x = 0;\n  let y = {\n    let x = 1; // 我就是第5行\n    x + 1;\n  };\n}\n```\n\n这个编译出是可以通过的，这个时候`y`的数据类型是`空的元组`类型，也就是`()`； 类似的：`rust`中没有显示指定函数返回值的，那这个函数返回值类型为`()`。就相当于`c++`里面的返回类型为`void`的函数\n\n看下面一个例子：\n\n```rust\nfn main() {\n  let mut counter = 0;\n  let result = loop {\n    counter += 1;\n    if counter == 10 {\n      break counter * 2; // 第6行\n    }\n  };\n}\n```\n\n`loop`为死循环，一个死循环赋值给了`result`, 是不是有点费解，这里就要理解第6行的代码的意思了。这里面使用了`break`语句。\n\n`break count * 2;`的意思就是跳出循环，并返回`break`后面的表达式的值。这里有人会疑惑，刚才不是说表达式是不带`;`的吗？那现在`counter * 2;`这里不是有`;`吗？`break counter * 2;` 是个语句，它是需要`;`的。所以这里的`;`是整个语句的分号，这个语句是用`break`跳出循环并返回表达式`counter * 2`，没毛病。\n\n**每天进步一点点，学海无涯！**\n","tags":["loop","break","语句","表达式"],"categories":["Rust","基础"]},{"title":"Golang调用C语言编写的动态库","url":"/2022/11/18/Golang调用C语言编写的动态库/","content":"\n# 用C语言编写一个动态库\n## 编写C语言头文件`sample_so.h`\n\n在头文件中声明函数\n\n```c\nint export_func_add(int a, int b);\n```\n\n## 编写函数的实现代码`sample_so.c`\n\n在源文件中实现函数\n\n```c\n#include \"sample_so.h\"\n\nint export_func_add(int a, int b)\n{\n  return a + b;\n}\n```\n\n# 编译生成动态链接库\n\n```shell\ngcc -c -fPIC -o sample_so.o sample_so.c # 先生成.o文件\ngcc -shared -o libsample_so.so sample_o.o # 再生成.so文件\n```\n\n# golang 调用动态库\n\n## 先用c语言编写一个动态库的` 调用代理`（名字瞎取的）\n\n`loadso.h`\n\n```c\nint call_export_func(int a, int b);\n```\n\n`loadso.c`\n\n```c\n#include \"loadso.h\"\n#include <dlfcn.h>\n\nchar dllname[] = \"/path/of/the/so/sample_so.so\";\n\nint call_export_func(int a, int b) {\n    void* handle;\n    typedef int(*FPTR)(int, int);\n\n    handle = dlopen(dllname, 1);\n    if(handle == 0) {\n        return -1;\n    }\n\n    FPTR fptr = (FPTR)dlsym(handle, \"export_func_add\");\n\n    int result = (*fptr)(a, b);\n    return result;\n}\n```\n\n**注：实际上就是明确了动态库中的函数的签名后（就是函数参数类型，函数返回类型），然后定义对应的函数指针，根据函数名获取到这个函数，用函数指针指向它，接着就可以使用这个函数指针调用这个函数了**\n\n## 编写golang代码\n\n```go\npackage main\n\n/*\n#include \"loadso.h\"\n#cgo LDFLAGS: -ldl\n*/\nimport \"C\"\nimport \"fmt\"\n\nfunc main() {\n        var a int = 20\n        var b int = 20\n        fmt.Printf(\"%d + %d = %d\\n\", a, b, C.export_func_add(C.int(a), C.int(b)))\n}\n```\n\n**注：看到最顶上的代码注释了吗？这个注释会被编译器进行解析，不是一般意义上的代码注释，个人感觉挺奇葩的。还有紧接着的一行`import \"C\"`, 注意要紧接着，这也挺反人类的**\n","tags":["c语言","golang","so库","动态链接库"],"categories":["Golang","CGO"]},{"title":"Fabric源码系列-003","url":"/2022/11/12/Fabric源码系列-003/","content":"\n# `BCCSP`接口\n\n`BCCSP`接口定义了以下方法，其实对密码学中的函数进行了一个功能分类：\n\n- `KeyGen`：密钥生成，包含对称和非对称加密\n- `KeyDeriv`：密钥派生\n- `KeyImport`：密钥导入，从文件、内存、数字证书中导入\n- `GetKey`：获取密钥\n- `Hash`：计算摘要\n- `GetHash`：获取摘要计算实例\n- `Sign`：数字签名\n- `Verify`：签名验证\n- `Encrypt`：数据加密，包含对称和非对称加密\n- `Decrypt`：数据解密，包含对称和非对称加密\n\n# SW\n\n## CSP\n\n`fabric/bccsp/sw/impl.go`\n\n`CSP`是一个`SW WRAPPER`，**调用`BCCSP`中定义的方法的总的入口就是`CSP`**, `CSP`利用反射调用真正的实现\n\n```GO\ntype CSP struct {\n\tks bccsp.KeyStore\n\n\tKeyGenerators map[reflect.Type]KeyGenerator\n\tKeyDerivers   map[reflect.Type]KeyDeriver\n\tKeyImporters  map[reflect.Type]KeyImporter\n\tEncryptors    map[reflect.Type]Encryptor\n\tDecryptors    map[reflect.Type]Decryptor\n\tSigners       map[reflect.Type]Signer\n\tVerifiers     map[reflect.Type]Verifier\n\tHashers       map[reflect.Type]Hasher\n}\n```\n\n**结构体可以使用反射调用`BCCSP`接口的具体实现，`KeyGenerators` 生成的如果`非临时KEY`，就会被保存在`KeyStore`中\n\n`SW`中包含了`AES`、`ECDSA`、`HASH(SHA256)`、`RSA`, 对应于BCCSP接口中定义的方法，有以下实现：\n\n- `KeyGen:` `fabric/bccsp/sw/keygen.go`\n\n  包含了`ECDSA`、`AES`2种密钥的生成\n\n  - `ecdsaKeyGenerator`\n  - `aesKeyGenerator`\n  \n- `KeyDeriv:` `fabric/bccsp/sw/keyderiv.go`\n\n  包含了`ECDSA`的公钥、私钥派生，`AES`的私钥派生 3种\n  - `ecdsaPublicKeyKeyDeriver`\n  - `ecdsaPrivateKeyKeyDeriver`\n  - `aesPrivateKeyKeyDeriver`\n\n- `KeyImport:` `fabric/bccsp/sw/keyimport.go`\n  包含了:\n  \n  - `aes256ImportKeyOptsKeyImporter`\n  - `hmacImportKeyOptsKeyImporter`\n  - `ecdsaPKIXPublicKeyImportOptsKeyImporter`\n  - `ecdsaPrivateKeyImportOptsKeyImporter`\n  - `ecdsaGoPublicKeyImportOptsKeyImporter`\n  - `x509PublicKeyImportOptsKeyImporter`\n\n- `GetKey:` `KeyStore`的`GetKey`的调用，这里没有反射调用\n\n- `Hash:` `fabric/bccsp/sw/hash.go`\n  - `hasher `结构体实现了`Hash`方法\n- `GetHash:` `fabric/bccsp/sw/hash.go`\n  - `hasher `结构体实现了`GetHash`方法\n\n- `Sign:` `fabric/bccsp/sw/ecdsa.go`\n  - `ecdsaSigner`结构体实现了此方法，在`fabric 1.4`版中好像`rsaSigner`结构体也实现了此方法\n\n- `Verify:` `fabric/bccsp/sw/ecdsa.go`\n  - `ecdsaPrivateKeyVerifier` 结构体中实现了此方法\n  - `ecdsaPublicKeyKeyVerifier`结构体中实现了此方法\n\n- `Encrypt:` `fabric/bccsp/sw/aes.go`\n  - `aescbcpkcs7Encryptor` 结构体\n- `Decrypt:` `fabric/bccsp/sw/aes.go`\n  - `aescbcpkcs7Encryptor` 结构体\n","tags":["sw","软实现"],"categories":["区块链","Fabric"]},{"title":"Fabric源码系列-002","url":"/2022/11/12/Fabric源码系列-002/","content":"\n# BCCSP 接口\n\n**以下内容从[太彬年久失修的博客](https://lessisbetter.site/)盗版而来**\n\n`BCCSP`是`Block Chain Crypto Service Provider`的缩写。在Fabric中，BCCSP被抽象成为一个接口。\n\n`bccsp`模块提供密码学服务，它包含的具体功能有：对称加密和非对称加密的密钥生成、导入、导出，数字签名和验证，对称加密和解密、摘要计算。\n\n`bccsp`使用了依赖倒置原则（Dependence Inversion Principle）：依赖抽象而不依赖具体实现，这样的好处就是可以把具体的密码学实现（实现BCCSP接口）当成插件进行使用。\n\nbccsp模块中当前有2种密码实现，它们都是bccsp中的密码学插件：`SW`和`PKCS11`，`SW`代表的是国际标准加密的软实现，`SW`是`software`的缩写，`PKCS11`代指硬实现。\n\n![BCCSP.png](https://s2.loli.net/2022/11/12/SYeZ7wR48ajJUGh.png)\n\n> 扩展阅读：\n>\n> PKCS11是PKCS系列标准中的第11个，它定义了应用层和底层加密设备的交互标准，比如过去在电脑上，\n> 插入USBKey用网银转账时，就需要走USBKey中的硬件进行数字签名，这个过程就需要使用PCKS11。\n\n密码学通常有软实现和硬实现，软实现就是常用的各种加密库，比如Go中`crypto`包，硬实现是使用加密机提供的一套加密服务。软实现和硬实现的重要区别是，密码算法的安全性强依赖随机数，软实现利用的是OS的伪随机数，而硬实现利用的是加密机生成的随机数，所以硬实现的安全强度要高于软实现。\n\n## SW介绍\n\nSW是国际标准加密的软实现插件，它包含了ECDSA算法、RSA算法、AES算法，以及SHA系列的摘要算法。\n\n`BCCSP`接口定义了以下方法，其实对密码学中的函数进行了一个功能分类：\n\n- `KeyGen`：密钥生成，包含对称和非对称加密\n- `KeyDeriv`：密钥派生\n- `KeyImport`：密钥导入，从文件、内存、数字证书中导入\n- `GetKey`：获取密钥\n- `Hash`：计算摘要\n- `GetHash`：获取摘要计算实例\n- `Sign`：数字签名\n- `Verify`：签名验证\n- `Encrypt`：数据加密，包含对称和非对称加密\n- `Decrypt`：数据解密，包含对称和非对称加密\n\n```go\n// BCCSP is the blockchain cryptographic service provider that offers\n// the implementation of cryptographic standards and algorithms.\ntype BCCSP interface {\n\n\t// KeyGen generates a key using opts.\n\tKeyGen(opts KeyGenOpts) (k Key, err error)\n\n\t// KeyDeriv derives a key from k using opts.\n\t// The opts argument should be appropriate for the primitive used.\n\tKeyDeriv(k Key, opts KeyDerivOpts) (dk Key, err error)\n\n\t// KeyImport imports a key from its raw representation using opts.\n\t// The opts argument should be appropriate for the primitive used.\n\tKeyImport(raw interface{}, opts KeyImportOpts) (k Key, err error)\n\n\t// GetKey returns the key this CSP associates to\n\t// the Subject Key Identifier ski.\n\tGetKey(ski []byte) (k Key, err error)\n\n\t// Hash hashes messages msg using options opts.\n\t// If opts is nil, the default hash function will be used.\n\tHash(msg []byte, opts HashOpts) (hash []byte, err error)\n\n\t// GetHash returns and instance of hash.Hash using options opts.\n\t// If opts is nil, the default hash function will be returned.\n\tGetHash(opts HashOpts) (h hash.Hash, err error)\n\n\t// Sign signs digest using key k.\n\t// The opts argument should be appropriate for the algorithm used.\n\t//\n\t// Note that when a signature of a hash of a larger message is needed,\n\t// the caller is responsible for hashing the larger message and passing\n\t// the hash (as digest).\n\tSign(k Key, digest []byte, opts SignerOpts) (signature []byte, err error)\n\n\t// Verify verifies signature against key k and digest\n\t// The opts argument should be appropriate for the algorithm used.\n\tVerify(k Key, signature, digest []byte, opts SignerOpts) (valid bool, err error)\n\n\t// Encrypt encrypts plaintext using key k.\n\t// The opts argument should be appropriate for the algorithm used.\n\tEncrypt(k Key, plaintext []byte, opts EncrypterOpts) (ciphertext []byte, err error)\n\n\t// Decrypt decrypts ciphertext using key k.\n\t// The opts argument should be appropriate for the algorithm used.\n\tDecrypt(k Key, ciphertext []byte, opts DecrypterOpts) (plaintext []byte, err error)\n}\n```\n\n\n\n## 可插拔国密\n\nFabric支持国密并非仅仅在bccsp中增加1个国密实现这么简单，还需要让数字证书支持国密，让数字证书的操作符合X.509。各语言的标准库`x509`都是适配标准加密的，并不能直接用来操作国密证书。\n\n在数字证书支持国密后，还可能需要进一步考虑，是否需要TLS证书使用国密数字证书，让通信过程使用国密算法。\n\n另外，国密的实现有很多版本，如果需要适配不同的国密实现，就需要保证国密的可插拔和可扩展。\n","tags":["BCCSP","SW","PKCS11","依赖倒置原则","密码学插件","Plugin"],"categories":["区块链","Fabric"]},{"title":"Fabric源码系列-001","url":"/2022/11/11/Fabric源码系列-001/","content":"\n# 源码总目录结构\n\n|  目录名   | 说明  |\n|  ----  | ----  |\n| bccsp | 全称是区块链密码服务提供者，用来提供区块链相关的算法标准和他们的实现 |\n| ccaas_builder  | 编译相关 |\n| ci  | 持续集成(CI)相关配置和脚本 |\n| cmd | 命令行操作相关入口代码 | \n| common  | 一些公共库（错误处理、日志处理、账本存储、策略以及各种工具等等） | \n| core | 核心库，组件的核心逻辑，针对每一个组件都有一个子目录（chaincode:与智能合约相关);(endorser:与背书节点相关）|\n| discovery | 服务发现模块相关代码 |\n| docs | 文档相关 |\n| gossip | 组织内部节点数据同步的通信协议，最终一致性算法，用于组织内部数据同步 |\n| images | Docker镜像打包，Docker镜像都是通过这个目录下的配置文件生成的 |\n| integration | 待迁移代码 |\n| internal | 内部代码，被cmd包等调用 |\n| msp | 成员服务管理（member service provider），在Fabric网络中会为每一个成员提供相应的证书，msp模块就是读取这些证书并做一些相应的处理 |\n| orderer | 排序节点的入口，用于消息的订阅与分发处理 |\n| pkg | 重写或实现了一些golang原生接口 |\n| protoutil | Proposal提案相关的工具包 |\n| release_notes | 发布笔记 |\n| sampleconfig | 配置示例 |\n| scripts | 脚本，包含启动脚本、检查脚本等 |\n| swagger | swagger文档生成配置 |\n| tools | 工具包，目前还是空的（release-2.4分支）|\n| vagrant | 包含了用 Vagrant 建立一个简单的开发环境所必需的脚本 |\n| vendor | 存放Go中使用的第三方包 |\n\n\n# 模块分类\n## 核心模块\n\n提供核心功能服务的代码，包括`core`、`orderer`两个代码包，这两个代码包涵盖了Orderder排序节点与Peer节点（包含Endorser背书节点与Committer记帐节点）的核心代码\n\n## 公共模块\n\n为核心模块和其它模块提供基础支持服务，包括`bccsp` `common` `gossip` `msp` `protoutil`等目录代码。其中`gossip`消息模块为`peer`节点提供安全、可靠、可扩展的P2P数据分发协义。`commom`公共功能模块包括帐本数据存储模块、安全服务模块、通道配置等，为其它模块提供底层存储机制、安全机制、异步通信机制等。\n\n## 辅助模块\n\n为其它模块提供辅助工具、运行环境、测试用例、文档等，包括`ccaas_builder` `ci` `docs` `release_notes` `swagger`等\n\n","tags":["fabric","源码"],"categories":["区块链","Fabric"]},{"title":"Fabric-通过samples了解fabric（三）","url":"/2022/11/07/Fabric-通过samples了解fabric（三）/","content":"\n**注：以下命令在`test-network`目录下执行**\n```shell\nexport PATH=${PWD}/../bin:$PATH         # peer 命令所在目录\nexport FABRIC_CFG_PATH=$PWD/../config/  # `core.yaml` 配置文件所在目录\n```\n\n# 部署`wasmcc`\n```shell\n./network.sh deployCC -ccn wasmcc -ccp /Users/mao/work/wasm/opensource/hyperledger/fabric-chaincode-wasm/wasmcc -ccv 1.0 -ccl go\n```\n\n\n# 调用`wasmcc`部署`wasm chaincode`\n\n首先准备好一个wasm文件，使用工具把wasm文件的二进制数据转成十六进制表示（字符串），\n然后通过以下命令部置这个`wasm chaincode`,**注：命令中的`wasm二进制数据的十六进制表示字符串`需要按实际的数据进行替换。这个把wasm字节码转为十六进制表示（字符串）的工具是[file-encoder](https://github.com/hyperledger-labs/fabric-chaincode-wasm/tree/main/tools/file-encoder)\n\n```shell\npeer chaincode invoke -o localhost:7050 --tls true --cafile ${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n wasmcc --peerAddresses localhost:7051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c '{\"Args\":[\"create\",\"balancewasm\",\"wasm二进制数据的十六进制表示字符串\",\"account1\",\"100\",\"account2\",\"1000\"]}'\n```\n\n# 调用命令查看目前已部署的`wasm chaincode`\n```shell\npeer chaincode query -C mychannel -n wasmcc -c '{\"Args\":[\"installedChaincodes\"]}'\n```\n\n# 通过`wasmcc`查询`wasm chaincode`中的`account1`的余额\n```shell\npeer chaincode query -C mychannel -n wasmcc -c '{\"Args\":[\"execute\",\"balancewasm\",\"query\",\"account1\"]}'\n```\n\n\n# 通过`wasmcc`调用`wasm chaincode`中的函数`invoke`\n```shell\npeer chaincode invoke -o localhost:7050 --tls true --cafile ${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n wasmcc --peerAddresses localhost:7051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c '{\"Args\":[\"execute\",\"balancewasm\",\"invoke\",\"account2\",\"account1\",\"10\"]}'\n``` \n\n# 通过工具`WASM Pusher`安装`wasm chaincode`\n`wasmcc`支持3种格式文件的安装，`.wasm`格式、`.zip`格式、`wasm`字节`十六进制表示`的字符串内容。\n使用命令如下：\n```shell\n./wasm-pusher -n balancewasm -w ../../sample-wasm-chaincode/chaincode_example02/rust/app_main.wasm -u User1 -a a,100,b,100\n```\n`WASM Pusher`[详见](https://github.com/hyperledger-labs/fabric-chaincode-wasm/tree/main/tools/wasm-pusher)\n\n","tags":["wasmcc","wasm chaincode","file-encoder","wasm pusher"],"categories":["区块链","Fabric"]},{"title":"Fabric-通过samples了解fabric（二）","url":"/2022/11/04/Fabric-通过samples了解fabric（二）/","content":"\n# network.sh 脚本命令\n\n```shell\n./network.sh help\nUsing docker and docker-compose\nUsage:\n  network.sh <Mode> [Flags]\n    Modes:\n      up - Bring up Fabric orderer and peer nodes. No channel is created\n      up createChannel - Bring up fabric network with one channel\n      createChannel - Create and join a channel after the network is created\n      deployCC - Deploy a chaincode to a channel (defaults to asset-transfer-basic)\n      down - Bring down the network\n\n    Flags:\n    Used with network.sh up, network.sh createChannel:\n    -ca <use CAs> -  Use Certificate Authorities to generate network crypto material\n    -c <channel name> - Name of channel to create (defaults to \"mychannel\")\n    -s <dbtype> - Peer state database to deploy: goleveldb (default) or couchdb\n    -r <max retry> - CLI times out after certain number of attempts (defaults to 5)\n    -d <delay> - CLI delays for a certain number of seconds (defaults to 3)\n    -verbose - Verbose mode\n\n    Used with network.sh deployCC\n    -c <channel name> - Name of channel to deploy chaincode to\n    -ccn <name> - Chaincode name.\n    -ccl <language> - Programming language of the chaincode to deploy: go, java, javascript, typescript\n    -ccv <version>  - Chaincode version. 1.0 (default), v2, version3.x, etc\n    -ccs <sequence>  - Chaincode definition sequence. Must be an integer, 1 (default), 2, 3, etc\n    -ccp <path>  - File path to the chaincode.\n    -ccep <policy>  - (Optional) Chaincode endorsement policy using signature policy syntax. The default policy requires an endorsement from Org1 and Org2\n    -cccg <collection-config>  - (Optional) File path to private data collections configuration file\n    -cci <fcn name>  - (Optional) Name of chaincode initialization function. When a function is provided, the execution of init will be requested and the function will be invoked.\n\n    -h - Print this message\n\n Possible Mode and flag combinations\n   up -ca -r -d -s -verbose\n   up createChannel -ca -c -r -d -s -verbose\n   createChannel -c -r -d -verbose\n   deployCC -ccn -ccl -ccv -ccs -ccp -cci -r -d -verbose\n\n Examples:\n   network.sh up createChannel -ca -c mychannel -s couchdb\n   network.sh createChannel -c channelName\n   network.sh deployCC -ccn basic -ccp ../asset-transfer-basic/chaincode-javascript/ -ccl javascript\n   network.sh deployCC -ccn mychaincode -ccp ./user/mychaincode -ccv 1 -ccl javascript\n```\n\n## 清除测试网中的所有容器\n\n```shell\n./network.sh down\n```\n\n## 启动测试网\n\n```shell\n./network.sh up\n```\n\n## 创建通道\n\n```shell\n./network.sh createChannel    # 不指定通道名，通道名默认为mychannel\n./network.sh createChannel -c channel1 # 指定通道名 channel1\n```\n\n## 安装链码\n\n```shell\n./network.sh deployCC -ccn basic -ccp ../asset-transfer-basic/chaincode-go -ccl go\n```\n\n- `-ccn`指定链码名称 `chain code name`\n- `-ccl` 指定编写链码的语言 `chain code language`\n- `-ccp` 指定链码所在的目录 `chain code path`\n- 其余的查看 `./network.sh help`\n\n这一步在linux下，比如ubuntu,我当时设置了goproxy是在`~/.zshrc` 和`/etc/profile`中设置的，没有在`/etc/bash.bashrc`中设置(这里设置的环境变量对所有用户有效)，因为是使用`sudo`来跑命令,所以在`~/.zshrc` 和`/etc/profile`中设置的在终端里面`go env`查看是正常的，但安装链码的命令执行时还是下载依赖超时，因为根本没有使用`goproxy`。\n\n还有加`sudo`后找不到`go`的坑,需要在`~/.zshrc`中添加\n\n```PLAINTEXT\nalias sudo='sudo env PATH=$PATH LD_LIBRARY_PATH=$LD_LIBRARY_PATH'\n```\n\n## 与fabric网络交互\n\n**确保当前是在`test-network`目录**\n\n```shell\nexport PATH=${PWD}/../bin:$PATH\n```\n\n添加这个环境变量是为了下面调用`peer`命令系统能找到`peer`指令，除了`peer`指令，还有其它一些指令，如下：\n\n```shell\n-rwxr-xr-x@ 1 mao  staff    15M Oct 26 23:58 configtxgen\n-rwxr-xr-x@ 1 mao  staff    14M Oct 26 23:58 configtxlator\n-rwxr-xr-x@ 1 mao  staff    11M Oct 26 23:58 cryptogen\n-rwxr-xr-x@ 1 mao  staff    16M Oct 26 23:58 discover\n-rwxr-xr-x@ 1 mao  staff    26M Jul  8 17:32 fabric-ca-client\n-rwxr-xr-x@ 1 mao  staff    32M Jul  8 17:33 fabric-ca-server\n-rwxr-xr-x@ 1 mao  staff    16M Oct 26 23:58 ledgerutil\n-rwxr-xr-x@ 1 mao  staff    26M Oct 26 23:58 orderer\n-rwxr-xr-x@ 1 mao  staff    12M Oct 26 23:58 osnadmin\n-rwxr-xr-x@ 1 mao  staff    33M Oct 26 23:58 peer\n```\n\n还需要将`fabric-samples`代码库中的`FABRIC_CFG_PATH`设置为指向其中的`core.yaml`文件：\n\n```shell\nexport FABRIC_CFG_PATH=$PWD/../config/\n```\n\n现在，可以设置环境变量，以允许作为Org1操作`peer` CLI：\n\n```shell\n# Environment variables for Org1\n\nexport CORE_PEER_TLS_ENABLED=true\nexport CORE_PEER_LOCALMSPID=\"Org1MSP\"\nexport CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\nexport CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp\nexport CORE_PEER_ADDRESS=localhost:7051\n```\n\n`CORE_PEER_TLS_ROOTCERT_FILE`和`CORE_PEER_MSPCONFIGPATH`环境变量指向Org1的`organizations`文件夹中的的加密材料。 如果您使用 `./network.sh deployCC -ccl go` 安装和启动 asset-transfer (basic) 链码，您可以调用链码（Go）的 `InitLedger` 方法来赋予一些账本上的初始资产（如果使用 typescript 或者 javascript，例如 `./network.sh deployCC -l javascript`，你会调用相关链码的 `initLedger` 功能）。 运行以下命令用一些资产来初始化账本：\n\n### 调用链码函数`InitLedger`\n\n```shell\npeer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile ${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c '{\"function\":\"InitLedger\",\"Args\":[]}'\n```\n\n**Mac M1**中试验有很多坑，有说go版本要1.13，有说是Mac中的Docker Desktop的锅，准备再搞个**Linux环境**来玩了\n\n### 查询\n\n```shell\npeer chaincode query -C mychannel -n basic -c '{\"Args\":[\"GetAllAssets\"]}'\n```\n\n","tags":["up","down","creatChannel","up createChannel","deployCC"],"categories":["区块链","Fabric"]},{"title":"Fabric-编译rust源码为wasm","url":"/2022/11/04/Fabric-编译rust源码为wasm/","content":"\n# 编译rust源码为wasm\n\n## 安装工具链\n\n可以使用以下两条命令：\n\n```shell\ncurl https://sh.rustup.rs -sSf | sh\ncurl https://rustwasm.github.io/wasm-pack/installer/init.sh -sSf | sh\n```\n\n也可以参考[官方安装向导](https://rustwasm.github.io/book/game-of-life/setup.html)\n\n## 创建`rust` `lib`工程\n\n```shell\ncargo new hello_world --lib\n```\n\n生成的`Cargo.toml`内容为：\n\n```toml\n[package]\nname = \"hello_world\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n\n[dependencies]\n\n```\n\n添加一些内容到`Cargo.toml`中去\n\n```toml\n[lib]\ncrate-type = [\"cdylib\"]\n\n[dependencies]\nwasm-bindgen = \"0.2\"\n```\n\n代码目录结构如下：\n\n```\n.\n├── Cargo.toml\n└── src\n   └── lib.rs\n```\n\n在`lib.rs`中编写`rust`代码实现函数，因为在wasmcc的特殊性，这里的编写的代码也具有一些特殊性：\n\n- 可以导入调用在wasmcc中实现的函数\n\n  ```rust\n  extern \"C\" {\n      fn __print(msg: *const u8, len: usize) -> i64;\n      fn __get_parameter(paramNumber: usize, result: *const u8) -> i64;\n      fn __get_parameter_size(paramNumber: usize) -> i64;\n      fn __get_state(msg: *const u8, len: usize, value: *const u8) -> i64;\n      fn __get_state_size(msg: *const u8, len: usize) -> i64;\n      fn __put_state(key: *const u8, key_len: usize, value: *const u8, value_len: usize) -> i64;\n      fn __delete_state(msg: *const u8, len: usize) -> i64;\n      fn __return_result(msg: *const u8, len: usize) -> i64;\n  }\n  ```\n\n  **这些函数可以在编写`rust`代码时直接调用，不需要自己实现，这些是相当在Host程序中实现，可以被 `wasm`代码调用的函数**\n\n  在rust的导出函数中,即wasm代码的对外接口中，可以调用上述的函数，如：\n\n  - 通过__get_parameter_size(0)可以取得第1个参数的长度__\n  - 通过__get_parameter可以取得参数的值，具体用法就是传入一个序号，一个vec!的指针\n\n- 实现`init`函数（必须实现，`wasmcc`的`create`函数用来创建 wasm chaincode时就会调用wasm代码中的`init`函数\n\n  ```rust\n  #[no_mangle]\n  pub extern \"C\" fn init(args: i64) -> i64 {\n  \t// ...\n  }\n  ```\n\n## 编译\n\n在`rust`工程的根目录下，运行命令：\n\n```shell\nwasm-pack build\n```\n\n如果成功的话，会在当前目录下生成`pkg/hello_world_bg.wasm`\n\n关于C语言编写代码，再编译成wasm，文档中说是需要安装clang8 和 llvm。[文档](https://github.com/hyperledger-labs/fabric-chaincode-wasm/tree/main/sample-wasm-chaincode)中是[Linux的几个发行版的环境](https://apt.llvm.org/)，由于我的是Mac M1芯片的环境，尝试了一下得到一些链接出错信息，原因是找不到`__print`、`__get_parameter`等几个函数的找不到实现部分，所以链接的时候出错，这个理论上说得通，能编译成功才是不能理解的。不知道文档中说的方法是怎么编译成功的，到时候有空用Linux环境试一下吧。\n","tags":["wasm","chaincode","rust","wasm-pack","build"],"categories":["区块链","Fabric"]},{"title":"Fabric-wasmcc介绍","url":"/2022/11/03/Fabric-wasmcc介绍/","content":"\n# wasmcc\n\n全称：`Hyperledger Fabric WASM Chaincode`，是由`hypterledger-labs`提供的一个链码。作用是可以把使用rust/C编写代码生成`wasm`字节码，把wasm字节码部署到`fabric`中，然后使用wasmcc作为代理调用wasm中的函数。fabric以此方式来支持`wasm chaincode`\n\n## 步骤\n- 1. `wasmcc`部署到`fabric`中，扮演`wasm`代码调用的统一入口，相当于wasm代码的调用代理。\n`wasmcc`的部署和其它的普通链码的部署方式一样，`wasmcc`没有实例化参数，通过peer cli部署的命令如下：\n```shell\npeer chaincode install -n wasmcc -v 1.0 -p github.com/chaincode/wasmer-chaincode-test/wasmcc\n```\n```shell\npeer chaincode instantiate -n wasmcc -v 1.0 -C <channel-name> -c '{\"Args\":[]}' -o <orderer-address> --tls --cafile <orderer-ca>\n```\n- 2. 通过调用`wasmcc`的 `create` 方法创建`wasm chaincode`\n- 3. **通过调用`wasmcc`的`execute`方法调用`wasm chaincode`**\n- 4. 通过调用`wasmcc`的`installedChaincodes`方法获取目前fabric上部署的所有`wasm chiancode`\n\n# wasmcc 代码解读\n\n## 基础结构(fabric 链码的基本结构)\n\n\n{% mermaid %}\nclassDiagram\nclass WASMChaincode {\n\t+Init(stub shim.ChaincodeStubInterface) Response\n\t+Invoke(stub shim.ChaincodeStubInterface) Response\n\t-create(stub shim.ChaincodeStubInterface, args []string) Response\n\t-execute(stub shim.ChaincodeStubInterface, args []string) Response\n\t-installedChaincodes(stub shim.ChaincodeStubInterface, args []string) Response\n}\nclass VirtualMachine {\n...\n\t+ImportResolver ImportResolver\n\n}\nclass ImportResolver {\n\t<<interface>>\n\t+ResolveFunc(module, field string) FunctionImport\n\t+ResolveGlobal(module, field string) int64\n}\nclass Resolver {\n\t-string chaincodeName\n\t-shim.ChaincodeStubInterface stub          \n\t-[]string args          \n\t-[]byte result        \n\t-[]byte errMsg        \n\t+ResolveFunc(module, field string) FunctionImport\n\t+ResolveGlobal(module, field string) int64\n}\nclass ChaincodeStubInterface {\n\t<<interface>>\n\t...\n}\nclass ChaincodeStub {\n\t...\n}\n\nChaincodeStubInterface <|.. ChaincodeStub\nImportResolver <|.. Resolver\nWASMChaincode <-- VirtualMachine\nWASMChaincode ..> ChaincodeStubInterface\nVirtualMachine ..> ImportResolver\nResolver --> WASMChaincode\n\n{% endmermaid %}\n\n**wasm链码的创建流程（create/execute/installedChaincodes三个流程类似）**\n\n{% mermaid %}\nsequenceDiagram\n\tparticipant gRpc Client\n\tparticipant WASMChaincode\n\tparticipant ChaincodeStub\n  gRpc Client ->> WASMChaincode: 调用链码的create函数（触发链码Invoke）\n  WASMChaincode ->> ChaincodeStub: 获取函数及函数参数数组\n  ChaincodeStub -->> WASMChaincode: 返回被调用函数及函数参数数组\n  WASMChaincode ->> WASMChaincode: 调用自身create函数\n  WASMChaincode ->> ChaincodeStub: 检查链码是否存在\n  ChaincodeStub -->> WASMChaincode: 链码已存在\n  WASMChaincode -->> gRpc Client: 失败，链码已存在\n  ChaincodeStub -->> WASMChaincode: 链码不存在，继续执行\n  WASMChaincode ->> WASMChaincode: 对wasm字节码进行解码，得能解压后的字节流\n  WASMChaincode ->> WASMChaincode: 给Resolver对象赋值（里面保存了链码名，stub, 函数参数数组）\n  WASMChaincode ->> WASMChaincode: 调用runWASM，传入wasm字节流,函数名\"init\",参数个数，以及Resolver对象\n  WASMChaincode -->> gRpc Client: 调用runWASM失败立即返回\n  WASMChaincode ->> WASMChaincode: 创建\"chaincodeData\"和链码名的组合键\n  WASMChaincode ->> ChaincodeStub: \"chaincodeData\"和链码名的组合为键，wasm字节流为值，存入状态库\n  ChaincodeStub -->> WASMChaincode: 返回\n  WASMChaincode -->> gRpc Client: 返回\n\n{% endmermaid %}\n\n### 定义一个结构体\n\n```go\ntype WASMChaincode struct {\n}\n```\n\n## Init方法\n\n```go\nfunc (t *WASMChaincode) Init(stub shim.ChaincodeStubInterface) pb.Response {\n\tlogger.Infof(\"Init invoked\")\n\treturn shim.Success(nil)\n}\n```\n\n链码创建或升级时被调用，`wasmcc `的`Init`内部只记录了一下日志，没有其它多余的操作\n\n## Invoke方法\n\n```go\nfunc (t *WASMChaincode) Invoke(stub shim.ChaincodeStubInterface) pb.Response {\n\tlogger.Infof(\"Invoke function\")\n\tfunction, args := stub.GetFunctionAndParameters()\n\tlogger.Debugf(\"Invoke function %s with args %v\", function, args)\n\n\tif function == \"create\" {\n\t\t// Create a new wasm chaincode\n\t\treturn t.create(stub, args)\n\t} else if function == \"execute\" {\n\t\t// execute wasm chaincode\n\t\treturn t.execute(stub, args)\n\t} else if function == \"installedChaincodes\" {\n\t\t// get the list of installed wasm chaincode\n\t\treturn t.installedChaincodes(stub, args)\n\t}\n\n\treturn shim.Error(\"Invalid invoke function name. Expecting \\\"execute\\\" \\\"create\\\" \\\"query\\\"\")\n}\n```\n\n这个方法的功能：\n\n- 1. 创建wasm chaincode: 调用函数`create`\n\n     ```go\n     // Store a new wasm chaincode in state. Receives chaincode name and wasm file encoded in hex\n     func (t *WASMChaincode) create(stub shim.ChaincodeStubInterface, args []string) pb.Response {\n     \tlogger.Infof(\"Create function\")\n     \tif len(args) < 2 {\n     \t\treturn shim.Error(\"Incorrect number of arguments. Expecting atleast 2 arguments\")\n     \t}\n     \n     \tchaincodeName := args[0]\n     \tlogger.Infof(\"Installing wasm chaincode: \" + chaincodeName)\n     \n     \t//check if same chaincode name is already present\n     \tchaincodeFromState, err := stub.GetState(chaincodeName)\n     \tif chaincodeFromState != nil {\n     \t\treturn shim.Error(ChaincodeExists)\n     \t}\n     \n     \t//Decode the chaincode\n     \tchaincodeHexEncoded := args[1]\n     \tchaincodeDecoded, err := decodeReceivedWASMChaincode(chaincodeHexEncoded)\n     \n     \tif err != nil {\n     \t\treturn shim.Error(err.Error())\n     \t}\n     \n     \t//Initialize global variables for exported wasm functions\n     \tr := Resolver{\n     \t\tchaincodeName, stub, args[2:], nil, nil,\n     \t}\n     \n     \tresult := runWASM(chaincodeDecoded, \"init\", len(args)-2, &r)\n     \n     \tlogger.Infof(\"Init Response:%d\\n\", result)\n     \n     \tif result != 0 {\n     \t\treturn shim.Error(\"Chaincode init invocation failed\")\n     \t}\n     \n     \t// Store the chaincode in\n     \tledgerChaincodeKey, err := stub.CreateCompositeKey(chaincodeStoreIndex, []string{chaincodeName})\n     \terr = stub.PutState(ledgerChaincodeKey, chaincodeDecoded)\n     \tif err != nil {\n     \t\ts := fmt.Sprintf(UnknownError, err.Error())\n     \t\treturn shim.Error(s)\n     \t}\n     \treturn shim.Success([]byte(\"Success! Installed wasm chaincode\"))\n     }\n     ```\n\n- 2. 执行wasm chaincode 中的函数\n\n     ```go\n     func (t *WASMChaincode) execute(stub shim.ChaincodeStubInterface, args []string) pb.Response {\n     \n     \tif len(args) < 2 {\n     \t\treturn shim.Error(\"Incorrect number of arguments. Expecting chaincode name to invoke\")\n     \t}\n     \n     \tchaincodeName := args[0]\n     \tfuncToInvoke := args[1]\n     \n     \t//Initialize global variables for exported wasm functions\n     \tr := Resolver{\n     \t\tchaincodeName, stub, args[2:], nil, nil,\n     \t}\n     \n     \t// Get the state from the ledger\n     \tledgerChaincodeKey, _ := stub.CreateCompositeKey(chaincodeStoreIndex, []string{chaincodeName})\n     \tChaincodebytes, _ := stub.GetState(ledgerChaincodeKey)\n     \tif Chaincodebytes == nil {\n     \t\tjsonResp := \"{\\\"Error\\\":\\\"No Chaincode for \" + chaincodeName + \"\\\"}\"\n     \t\treturn shim.Error(jsonResp)\n     \t}\n     \n     \tresult := runWASM(Chaincodebytes, funcToInvoke, len(args)-2, &r)\n     \n     \tlogger.Infof(\"Invoke Response:%d\\n\", result)\n     \treturn txnResult(result, r.result)\n     }\n     ```\n\n\n- 3. 获取已安装的`wasm chaincode`\n\n     ```go\n     func (t *WASMChaincode) installedChaincodes(stub shim.ChaincodeStubInterface, args []string) pb.Response {\n     \n     \t// Get all chaincodes from the ledger\n     \tinstalledChaincodeResultsIterator, err := stub.GetStateByPartialCompositeKey(chaincodeStoreIndex, []string{})\n     \tif err != nil {\n     \t\treturn shim.Error(err.Error())\n     \t}\n     \n     \t// Iterate through result set and get chaincode names\n     \tvar i int\n     \tvar installedChaincodeNamesList = \"\"\n     \n     \tfor i = 0; installedChaincodeResultsIterator.HasNext(); i++ {\n     \t\t// Note that we don't get the value (2nd return variable), we'll just get the marble name from the composite key\n     \t\tresponseRange, err := installedChaincodeResultsIterator.Next()\n     \t\tif err != nil {\n     \t\t\treturn shim.Error(err.Error())\n     \t\t}\n     \n     \t\t// get the color and name from color~name composite key\n     \t\tobjectType, compositeKeyParts, err := stub.SplitCompositeKey(responseRange.Key)\n     \t\tif err != nil {\n     \t\t\treturn shim.Error(err.Error())\n     \t\t}\n     \t\treturnedChaincodeName := compositeKeyParts[0]\n     \t\tlogger.Infof(\"- found a chaincode from index:%s name:%s\\n\", objectType, returnedChaincodeName)\n     \t\tinstalledChaincodeNamesList += returnedChaincodeName\n     \t\tinstalledChaincodeNamesList += \"\\n\"\n     \n     \t}\n     \n     \tlogger.Infof(\"Invoke Response:%s\\n\", installedChaincodeNamesList)\n     \treturn shim.Success([]byte(installedChaincodeNamesList))\n     }\n     ```\n","tags":["wasm","chaincode"],"categories":["区块链","Fabric"]},{"title":"Fabric-通过samples了解fabric（一）","url":"/2022/11/02/Fabric-通过samples了解fabric（一）/","content":"\n# 通过fabric-samples了解fabric\n\n需要有以下几个步骤：\n\n- 1. 如果需要，请克隆 [hyperledger/fabric-samples](https://github.com/hyperledger/fabric-samples) 仓库\n- 2. 检出适当的版本标签\n- 3. 将指定版本的 Hyperledger Fabric 平台特定二进制文件和配置文件安装到 fabric-samples 下的 /bin 和 /config 目录中\n- 4. 下载指定版本的 Hyperledger Fabric docker 镜像\n\n**无梯子会比较麻烦，下面这种方法行不通**\n\n# 方法1. 使用脚本完成\n\n因为`curl -sSL https://bit.ly/2ysbOFE`会下载一个脚本，这个脚本如果在无梯子的情况下，是执行不成功的，可以先下载这个脚本，自行修改。\n\n如果想要最新的生产发布版，忽略所有的版本标识符\n\n```shell\ncurl -sSL https://bit.ly/2ysbOFE | bash -s\n```\n\n如果你想要一个指定的发布版本，传入一个 Fabric、Fabric-ca 和第三方 Docker 镜像的版本标识符。下边的命令显示了如何下载最新的生产发布版 - **Fabric v2.2.0** 和 **Fabric CA v1.4.7** 。\n\n```shell\ncurl -sSL https://bit.ly/2ysbOFE | bash -s -- <fabric_version> <fabric-ca_version>\ncurl -sSL https://bit.ly/2ysbOFE | bash -s -- 2.2.0 1.4.7\n```\n\n\n\n# 方法2. 通过fabric项目中的一个脚本\n\n- 先`clone fabric`代码\n\n  ```shell\n  git clone https://github.com/hyperledger/fabric.git\n  ```\n  \n- 进入到`fabric`目录下\n\n  ```shell\n  cd fabric/scripts/\n  ./bootstrap.sh\n  ```\n\n  接下来无梯子还是会遇到问题,可以对bootstrap.sh中的内容进行修改，或按脚本的流程自己手动下载\n\n# 启动测试网络\n\n## 进入到相关目录\n\n```shell\ncd fabric-samples/test-network\n```\n\n## 删除掉先前运行的所有容器或工程\n\n```shell\n./network.sh down\n```\n\n## 启动测试网\n\n```shell\n./network.sh up\n```\n\n","tags":["fabric","test-network"],"categories":["区块链","Fabric"]},{"title":"Linux-SSH免密登录问题","url":"/2022/11/02/Linux-SSH免密登录问题/","content":"\n阿里云服务器的`authorized_keys`中已经添加过我个人电脑的公钥，一开始是可以免密码登录的，后来估计不知道我个人电脑更新了啥，ssh 登录远程服务器时，提示：\n\n```shell\nUnable to negotiate with `服务器IP地址` port 22: no matching host key type found. Their offer: ssh-rsa,ssh-dss\n```\n\n解决方法记录一下：\n\n```shell\nvim ~/.ssh/config # 没有就创建\n```\n\n添加以下内容，保存退出\n\n```shell\nHost xxx.xxx.xxx.xxx                          # 服务器地址\nHostKeyAlgorithms +ssh-dss\nPubkeyAcceptedKeyTypes ssh-rsa,ssh-dss\n```\n\n网上一般都说是添加上面的前两行就解决了，但我试了不行，只有添加了上面3行内容才解决\n","tags":["linux","ssh","key","免密码","免密登录","远程登录"],"categories":["Linux"]},{"title":"Fabric-链码的基本结构和示例说明","url":"/2022/11/02/Fabric-链码的基本结构和示例说明/","content":"\n# 链码结构\n\n## 链码接口\n\n链码启动必须通过调用 shim 包中的 Start 函数，传递一个类型为 Chaincode 的参数，该参数是一个接口类型，有两个重要的函数 Init 与 Invoke 。\n\n```go\ntype Chaincode interface {\n    Init(stub ChaincodeStubInterface) peer.Response\n    Invoke(stub ChaincodeStubInterface) peer.Response\n}\n```\n\n- Init: 在链码实例化或升级时被调用，完成初始化数据的工作\n- Invoke: 更新或查询帐本数据状态时被调用，需要在此方法中**实现响应调用或查询的业务逻辑**\n\n实际开发中，开发人员可以自行定义一个结构体，重写Chaincode接口的两个方法，并将两个方法指定为自定义的结构体的成员方法。相当于java语言里面写一个类实现链码的接口，实现接口中的`Init`和`Invoke`方法。\n\n## 链码结构\n\n```go\npackage main\n\n// 引入必要的包\nimport (\n    \"fmt\"\n\n    \"github.com/hyperledger/fabric/core/chaincode/shim\"\n    pb \"github.com/hyperledger/fabric/protos/peer\"\n)\n\n// 声明一个结构体\ntype SimpleChaincode struct {\n}\n\n// 为结构体添加Init方法\nfunc (t *SimpleChaincode) Init(stub shim.ChaincodeStubInterface) pb.Response {\n    // 在该方法中实现链码初始化或升级时的处理逻辑\n    // 编写时可灵活使用stub中的API\n}\n\n// 为结构体添加Invoke方法\nfunc (t *SimpleChaincode) Invoke(stub shim.ChaincodeStubInterface) pb.Response {\n    // 在该方法中实现链码运行中被调用或查询时的处理逻辑\n    // 编写时可灵活使用stub中的API\n}\n\n// 主函数，需要调用shim.Start（）方法\nfunc main() {\n    err := shim.Start(new(SimpleChaincode))\n    if err != nil {\n        fmt.Printf(\"Error starting Simple chaincode: %s\", err)\n    }\n}\n```\n\n- **shim**`: 用来访问/操作数据状态、事务上下文和调用`其它链`代码的API，链码通过`shim.ChaincodeStub`提供的方法来读取和修改帐本的状态。\n\n- **peer**: 提供了链码执行后的响；应信息的API， `peer.Response`封装了响应信息\n\n# 链码相关API\n\n`shim`包提供了如下几种类型的接口：\n\n- **参数解析AP**`：调用链码时需要给被调用的目标函数/方法传递参数，该 API 提供解析这些参数的方法，链码被调用时触发链码中的`Invoke`方法被调用，在`Invoke`内部，可以通过参数`stub`来获取目标函数/方法参数。\n- **帐本状态数据操作API**: 该 API 提供了对账本数据状态进行操作的方法，包括对状态数据的查询及事务处理等\n- **交易信息获取 API：**获取提交的交易信息的相关 API\n- **对 PrivateData 操作的 API：** Hyperledger Fabric 在 1.2.0 版本中新增的对私有数据操作的相关 API\n- **其他 API：**其他的 API，包括事件设置、调用其他链码操作\n\n## 参数解析API\n\n```go\n// 返回调用链码时指定提供的参数列表（以字符串数组形式返回）\nGetStringArgs() []string\n\n// 返回调用链码时在交易提案中指定提供的被调用的函数名称及函数的参数列表（以字符串数组形式返回）\nGetFunctionAndParameters() (function string, params []string)\n\n// 返回提交交易提案时提供的参数列表（以字节串数组形式返回）\nGetArgsSlice() ([]byte, error)\n\n// 返回调用链码时在交易提案中指定提供的被调用的函数名称及函数的参数列表（以字节串数组形式返回）\nGetArgs() [][]byte\n```\n\n一般使用 GetFunctionAndParameters() 及 GetStringArgs() 。\n\n## 帐本数据状态操作API\n\n```go\n// 查询账本，返回指定键对应的值\nGetState(key string) ([]byte, error)\n\n// 尝试添加/更新账本中的一对键值\n// 这一对键值会被添加到写集合中，等待 Committer 进一步确认，验证通过后才会真正写入到账本\nPutState(key string, value []byte) error\n\n// 尝试删除账本中的一对键值\n// 同样，对该对键值删除会添加到写集合中，等待 Committer 进一步确认，验证通过后才会真正写入到账本\nDelState(key string) error\n\n// 查询指定范围的键值，startKey 和 endkey 分别指定开始（包括）和终止（不包括），当为空时默认是最大范围\n// 返回结果是一个迭代器结构，可以按照字典序迭代每个键值对，最后需要调用 Close() 方法关闭\nGetStateByRange(startKey, endKey string) (StateQueryIteratorInterface, error)\n\n// 返回指定键的所有历史值。该方法的使用需要节点配置中打开历史数据库特性（ledger.history.enableHistoryDatabase=true）\nGetHistoryForKey(key string) (HistoryQueryIteratorInterface, error)\n\n// 给定一组属性（attributes），将这些属性组合起来构造返回一个复合键\n// 例如：CreateComositeKey(\"name-age\",[]string{\"Alice\", \"12\"});\nCreateCompositeKey(objectType string, attributes []string) (string, error)\n\n// 将指定的复合键进行分割，拆分成构造复合键时所用的属性\nSplitCompositeKey(compositeKey string) (string, []string, error)\n\n// 根据局部的复合键（前缀）返回所有匹配的键值，即与账本中的键进行前缀匹配\n// 返回结果是一个迭代器结构，可以按照字典序迭代每个键值对，最后需要调用 Close() 方法关闭\nGetStateByPartialCompositeKey(objectType string, keys []string) (StateQueryIteratorInterface, error)\n\n// 对(支持富查询功能的)状态数据库进行富查询，返回结果是一个迭代器结构，目前只支持 CouchDB\n// 注意该方法不会被 Committer 重新执行进行验证，所以不能用于更新账本状态的交易中\nGetQueryResult(query string) (StateQueryIteratorInterface, error)\n```\n\n**注意：** 通过 put 写入的数据状态不能立刻 get 到，因为 put 只是链码执行的模拟交易（防止重复提交攻击），并不会真正将状态保存到账本中，必须经过 Orderer 达成共识之后，将数据状态保存在区块中，然后保存在各 peer 节点的账本中。\n\n## 交易信息相关API\n\n```go\n// 返回交易提案中指定的交易 ID。\n// 一般情况下，交易 ID 是客户端提交提案时由 Nonce 随机串和签名者身份信息哈希产生的数字摘要\nGetTxID() string\n\n// 返回交易提案中指定的 Channel ID\nGetChannelID() string\n\n// 返回交易被创建时的客户端打上的的时间戳\n// 这个时间戳是直接从交易 ChannnelHeader 中提取的，所以在所以背书节点处看到的值都相同\nGetTxTimestamp() (*timestamp.Timestamp, error)\n\n// 返回交易的 binding 信息\n// 交易的 binding 信息是将交提案的 nonse、Creator、epoch 等信息组合起来哈希得到数字摘要\nGetBinding() ([]byte, error)\n\n// 返回该 stub 的 SignedProposal 结构，包括了跟交易提案相关的所有数据\nGetSignedProposal() (*pb.SignedProposal, error)\n\n// 返回该交易提交者的身份信息（用户证书）\n// 从 SignedProposal 中的 SignatureHeader.Creator 提取\nGetCreator() ([]byte, error)\n\n// 返回交易中带有的一些临时信息\n// 从 ChaincodeProposalPayload.transient 提取，可以存放与应用相关的保密信息，该信息不会被写入到账本\nGetTransient() (map[string][]byte, error)\n```\n\n## 对 PrivateData 操作的 API\n\n```go\n// 根据指定的 key，从指定的私有数据集中查询对应的私有数据\nGetPrivateData(collection, key string) ([]byte, error)\n\n// 将指定的 key 与 value 保存到私有数据集中\nPutPrivateData(collection string, key string, value []byte) error\n\n// 根据指定的 key 从私有数据集中删除相应的数据\nDelPrivateData(collection, key string) error\n\n// 根据指定的开始与结束 key 查询范围（不包含结束key）内的私有数据\nGetPrivateDataByRange(collection, startKey, endKey string) (StateQueryIteratorInterface, error)\n\n// 根据给定的部分组合键的集合，查询给定的私有状态\nGetPrivateDataByPartialCompositeKey(collection, objectType string, keys []string) (StateQueryIteratorInterface, error)\n\n// 根据指定的查询字符串执行富查询 （只支持支持富查询的 CouchDB）\nGetPrivateDataQueryResult(collection, query string) (StateQueryIteratorInterface, error)\n```\n\n## 其他 API\n\n```go\n// 设定当这个交易在 Committer 处被认证通过，写入到区块时发送的事件（event），一般由 Client 监听\nSetEvent(name string, payload []byte) error\n\n// 调用另外一个链码的 Invoke 方法\n// 如果被调用链码在同一个通道内，则添加其读写集合信息到调用交易；否则执行调用但不影响读写集合信息\n// 如果 channel 为空，则默认为当前通道。目前仅限读操作，同时不会生成新的交易\nInvokeChaincode(chaincodeName string, args [][]byte, channel string) pb.Response\n```\n\n# 链码开发\n\n## 帐户转帐\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"strconv\"\n\n\t\"github.com/hyperledger/fabric-chaincode-go/shim\"\n\t\"github.com/hyperledger/fabric-protos-go/peer\"\n)\n\n// 声明一个结构体\ntype SimpleChaincode struct {\n}\n\n// 初始化数据状态， 实例化/升级链码时被自动调用\nfunc (t *SimpleChaincode) Init(stub shim.ChaincodeStubInterface) peer.Response {\n\t// println 函数的输出信息会出现在链码容器的日志中\n\tfmt.Println(\"ex02 Init\")\n\n\t// 获取用户传递给调用链码的所需参数\n\t_, args := stub.GetFunctionAndParameters()\n\n\tvar A, B string    // 两个帐户\n\tvar Aval, Bval int // 两个帐户的余额\n\tvar err error\n\n\t// 检查合法性，检查参数数量是否为4个，如果不是，则返回错误信息\n\tif len(args) != 4 {\n\t\treturn shim.Error(\"Incorrect number of arguments. Expecting 4\")\n\t}\n\n\tA = args[0]                       // 帐户A用户名\n\tAval, err = strconv.Atoi(args[1]) // 帐户A余额\n\tif err != nil {\n\t\treturn shim.Error(\"Expecting integer value for asset holding\")\n\t}\n\n\tB = args[2]                       // 账户B用户名\n\tBval, err = strconv.Atoi(args[3]) // 帐户B余额\n\tif err != nil {\n\t\treturn shim.Error(\"Expecting integer value for asset holding\")\n\t}\n\n\tfmt.Printf(\"Aval = %d, Bval = %d\\n\", Aval, Bval)\n\n\t// 将账户A的状态写入账本中\n\terr = stub.PutState(A, []byte(strconv.Itoa(Aval)))\n\tif err != nil {\n\t\treturn shim.Error(err.Error())\n\t}\n\n\t// 将帐户B的状态写入账本\n\terr = stub.PutState(B, []byte(strconv.Itoa(Bval)))\n\tif err != nil {\n\t\treturn shim.Error(err.Error())\n\t}\n\n\t// 一切成功，返回\n\treturn shim.Success(nil)\n}\n\n// 对帐户数据进行操作时（query、invoke）被自动调用\nfunc (t *SimpleChaincode) Invoke(stub shim.ChaincodeStubInterface) peer.Response {\n\tfmt.Println(\"ex02 Invoke\")\n\t// 获取用户传递给调用链码的函数名称及参数\n\tfunction, args := stub.GetFunctionAndParameters()\n\n\t// 对获取到的函数名称进行判断\n\tif function == \"invoke\" {\n\t\t// 调用invoke函数实现转帐操作\n\t\treturn t.invoke(stub, args)\n\t} else if function == \"delete\" {\n\t\t// 调用delete函数实现帐户注销\n\t\treturn t.delete(stub, args)\n\t} else if function == \"query\" {\n\t\t// 调用query实现帐户查询操作\n\t\treturn t.query(stub, args)\n\t}\n\t// 调用的链码函数名出错，返回shim.Error()\n\treturn shim.Error(\"Invalid invoke function name. Expecting \\\"invoke\\\" \\\"delete\\\" \\\"query\\\"\")\n}\n\n// 帐户间转钱\nfunc (t *SimpleChaincode) invoke(stub shim.ChaincodeStubInterface, args []string) peer.Response {\n\tvar A, B string    // 帐户A和B\n\tvar Aval, Bval int // 帐户余额\n\tvar X int          // 转账金额\n\tvar err error\n\n\tif len(args) != 3 {\n\t\treturn shim.Error(\"Incorrect number of arguments. Expecting 3\")\n\t}\n\n\tA = args[0] // 帐户A用户名\n\tB = args[1] // 帐户B用户名\n\n\t// 从账本中获取A的余额\n\tAvalbytes, err := stub.GetState(A)\n\tif err != nil {\n\t\treturn shim.Error(\"Failed to get state\")\n\t}\n\tif Avalbytes == nil {\n\t\treturn shim.Error(\"Entity not found\")\n\t}\n\tAval, _ = strconv.Atoi(string(Avalbytes))\n\n\t// 从帐本中获取B的余额\n\tBvalbytes, err := stub.GetState(B)\n\tif err != nil {\n\t\treturn shim.Error(\"Failed to get state\")\n\t}\n\tif Bvalbytes == nil {\n\t\treturn shim.Error(\"Entity not found\")\n\t}\n\tBval, _ = strconv.Atoi(string(Bvalbytes))\n\n\t// X 为转账金额\n\tX, err = strconv.Atoi(args[2])\n\tif err != nil {\n\t\treturn shim.Error(\"Invalid transaction amount, expecting a integer value\")\n\t}\n\n\t// 转帐\n\tAval = Aval - X\n\tBval = Bval + X\n\tfmt.Printf(\"Aval = %d, Bval = %d\\n\", Aval, Bval)\n\n\t// 更新转帐后账本中A余额\n\terr = stub.PutState(A, []byte(strconv.Itoa(Aval)))\n\tif err != nil {\n\t\treturn shim.Error(err.Error())\n\t}\n\n\t// 更新转帐后账本中B余额\n\terr = stub.PutState(B, []byte(strconv.Itoa(Bval)))\n\tif err != nil {\n\t\treturn shim.Error(err.Error())\n\t}\n\n\treturn shim.Success(nil)\n}\n\n// 帐户注销\nfunc (t *SimpleChaincode) delete(stub shim.ChaincodeStubInterface, args []string) peer.Response {\n\tif len(args) != 1 {\n\t\treturn shim.Error(\"Incorrect number of arguments. Expecting 1\")\n\t}\n\n\tA := args[0] // 帐户用户名\n\n\t// 从账本中删除该帐户状态\n\terr := stub.DelState(A)\n\tif err != nil {\n\t\treturn shim.Error(err.Error())\n\t}\n\n\treturn shim.Success(nil)\n}\n\n// 帐户查询\nfunc (t *SimpleChaincode) query(stub shim.ChaincodeStubInterface, args []string) peer.Response {\n\tvar A string\n\tvar err error\n\n\tif len(args) != 1 {\n\t\treturn shim.Error(\"Incorrect number of arguments. Expecting name of the person to query\")\n\t}\n\n\tA = args[0] // 帐户用户名\n\n\t// 从帐户中获取该帐户余额\n\tAvalbytes, err := stub.GetState(A)\n\tif err != nil {\n\t\tjsonResp := \"{\\\"Error\\\": \\\"Failed to get state for \" + A + \"\\\"}\"\n\t\treturn shim.Error(jsonResp)\n\t}\n\tif Avalbytes == nil {\n\t\tjsonResp := \"{\\\"Error\\\":\\\"Nil amount for \" + A + \"\\\"}\"\n\t\treturn shim.Error(jsonResp)\n\t}\n\n\tjsonResp := \"{\\\"Name\\\":\\\"\" + A + \"\\\",\\\"Amount\\\":\\\"\" + string(Avalbytes) + \"\\\"}\"\n\tfmt.Printf(\"Query Response:%s\\n\", jsonResp)\n\t// 返回转帐金额\n\treturn shim.Success(Avalbytes)\n}\n\nfunc main() {\n\terr := shim.Start(new(SimpleChaincode))\n\tif err != nil {\n\t\tfmt.Printf(\"Error starting Simple chaincode: %s\", err)\n\t}\n}\n```\n\n","tags":["chaincode","fabric","shim","帐本"],"categories":["区块链","Fabric"]},{"title":"Rust学习-知识点-5","url":"/2022/10/19/Rust学习-知识点-5/","content":"\n# Rust中Trait的继承\n\n`Trait`类似于`java`中的`interface`，可以继承\n\n# Rust中的Struct的继承\n\n~~**已被移除**~~\n\n那怎么办呢？改为组合吧，文字描述总是苍白的，直接看代码吧\n\n`inherit.rs`\n\n```rust\nuse std::ops::{Deref, DerefMut};\n\npub struct Dog<'a> {\n    name: &'a str,\n}\n\nimpl<'a> Dog<'a> {\n    pub fn new(name: &'a str) -> Dog {\n        Dog {\n            name\n        }\n    }\n    pub fn run(&self) {\n        println!(\"the dog is running.\")\n    }\n\n    pub fn sleep(&self) {\n        println!(\"the dog is sleeping.\")\n    }\n\n    pub fn bark() {\n        println!(\"the dog is barking.\")\n    }\n}\n\npub struct Husky<'a> {\n    dog: Dog<'a>,\n}\n\nimpl<'a> Husky<'a> {\n    pub fn new(name: &'a str) -> Husky<'a> {\n        Husky {\n            dog: Dog::new(name)\n        }\n    }\n    pub fn get_dog(&'a self) -> &Dog<'a> {\n        &self.dog\n    }\n    pub fn run(&self) {\n        println!(\"the husky is running.\");\n    }\n    pub fn sleep(&self) {\n        println!(\"the husky is sleeping.\");\n    }\n    pub fn do_stupid_thing(&self) {\n        println!(\"the husky is acting as a fool.\")\n    }\n}\n\nimpl<'a> Deref for Husky<'a> {\n    type Target = Dog<'a>;\n\n    fn deref(&self) -> &Self::Target {\n        &self.dog\n    }\n}\n\nimpl<'a> DerefMut for Husky<'a> {\n    fn deref_mut(&mut self) -> &mut Dog<'a> {\n        &mut self.dog\n    }\n}\n```\n\n调用端代码：`main.rs`\n\n```rust\nmod inherit;\n\nuse inherit::{Dog, Husky};\n\nfn main() {\n    let husky = Husky::new(\"fool\");\n    husky.sleep(); // the husky is sleeping.\n    husky.run(); // the husky is running.\n    husky.do_stupid_thing(); // the husky is acting as a fool.\n\n    let mut husky_dog: &Dog = &husky;\n    husky.get_dog().sleep(); // the dog is sleeping.\n    husky_dog.sleep(); // the dog is sleeping.\n    husky_dog.run(); // the dog is running.\n}\n```\n\n\n\n\n\n","tags":["Result","Option","错误传播","错误处理"],"categories":["Rust","基础"]},{"title":"Rust学习-知识点-4","url":"/2022/10/19/Rust学习-知识点-4/","content":"\n# 传播错误\n\n程序中涉及到的函数调用往往会嵌套多层，而错误的处理也往往不是在哪出错，就在哪里处理，底层被调用的函数一般会把错误上传交给调用者去处理。因为上层调用方一般会涉及业务逻辑，底层不对错误做相应的业务处理。比如：\n\n```rust\nuse std::fs::File;\nuse std::io::{self, Read};\n\nfn read_username_from_file() -> Result<String, io::Error> {\n    // 打开文件，f是`Result<文件句柄,io::Error>`\n    let f = File::open(\"hello.txt\");\n\n    let mut f = match f {\n        // 打开文件成功，将file句柄赋值给f\n        Ok(file) => file,\n        // 打开文件失败，将错误返回(向上传播)\n        Err(e) => return Err(e),\n    };\n    // 创建动态字符串s\n    let mut s = String::new();\n    // 从f文件句柄读取数据并写入s中\n    match f.read_to_string(&mut s) {\n        // 读取成功，返回Ok封装的字符串\n        Ok(_) => Ok(s),\n        // 将错误向上传播\n        Err(e) => Err(e),\n    }\n}\n```\n\n`read_username_from_file()`内部一般只需要向上抛出错误即可；该函数的调用者最终会对错误进行处理，至于怎么处理就是调用者的事，可以选择向上传播，也可以直接`panic`，亦或将具体的错误原因包装后呈现给用户。\n\n虽然错误是传播出去了，但是，代码写起来有点长，`rust` 提供了`?`来简化错误的传播。\n\n```rust\nuse std::fs::File;\nuse std::io;\nuse std::io::Read;\n\nfn read_username_from_file() -> Result<String, io::Error> {\n    let mut f = File::open(\"hello.txt\")?;\n    let mut s = String::new();\n    f.read_to_string(&mut s)?;\n    Ok(s)\n}\n```\n\n代码量减少明显，其实`?`就是一个宏，它的作用中上面的`match`一样：\n\n```rust\nlet mut f = match f {\n    // 打开文件成功，将file句柄赋值给f\n    Ok(file) => file,\n    // 打开文件失败，将错误返回(向上传播)\n    Err(e) => return Err(e),\n};\n```\n\n但`?`还有一点比`match`更强的地方，想像一下，一个系统中，肯定有自定义的错误特征，错误之间很可能会存在上下级关系，例如标准库中的`std::io:Error`和`std::error:Error`，前者是IO相关的错误结构体，后者是一个最通用的标准错误特征，同时前者实现在了后者，因此`std::io::Error`可以转换为`std::error::Error`。\n\n明白了上述的错误转换，再来看下面的一段代码来体会一下`?`比`match`更强的地方：\n\n```rust\nfn open_file() -> Result<File, Box<dyn std::error::Error>> {\n    let mut f = File::open(\"hello.txt\")?;\n    Ok(f)\n}\n```\n\n`?`还可以实现链式调用，写起代码来更加连贯：\n\n```rust\nuse std::fs::File;\nuse std::io;\nuse std::io::Read;\n\nfn read_username_from_file() -> Result<String, io::Error> {\n    let mut s = String::new();\n\n    File::open(\"hello.txt\")?.read_to_string(&mut s)?;\n\n    Ok(s)\n}\n```\n\n# `Option`的传播\n\n`?`不仅仅可以用于`Result`的传播，还能用于`Option`的传播，`Option`的定义如下：\n\n```rust\npub enum Option<T> {\n  Some(T),\n  None,\n}\n```\n\n`Result`通过`？`反回错误，那么`Option`就通过`?`返回None：\n\n```rust\nfn first(arr: &[i32]) -> Option<&i32> {\n   let v = arr.get(0)?;\n   Some(v)\n}\n```\n\n上面的代码只是为了演示`Option`的传播，从功能上来说，完全可以用以下简化的版本：\n\n```rust\nfn first(arr: &[i32]) -> Option<&i32> {\n   arr.get(0)\n}\n```\n\n当然，开发中肯定有`Option`传播的应用场景的：\n\n```rust\nfn last_char_of_first_line(text: &str) -> Option<char> {\n    text.lines().next()?.chars().last()\n}\n```\n\n上面代码展示了在链式调用中使用`?`提前返回`None`的用法，`.next`方法返回的是`Option`类型：如果返回`Some(&str)`，那么继续调用`chars`方法，如果返回`None`，则直接`last_char_of_first_line`返回,返回`None`，不再继续链式调用。\n\n","tags":["Result","Option","错误传播","错误处理"],"categories":["Rust","基础"]},{"title":"Rust学习-知识点-3","url":"/2022/10/14/Rust学习-知识点-3/","content":"\n# 拥有共享数据的链表\n\n以一道题开始吧，尝试用`Box<T>`实现下面的链表\n\n![链表.webp](https://s2.loli.net/2022/10/14/JAjkKl3hcapqr86.webp)\n\n# 使用`Box<T>`实现\n\n```rust\nuse crate::List::{Cons, Nil};\n\nenum List {\n    Cons(i32, Box<List>),\n    Nil,\n}\n\nfn main() {\n    // 创建链表a\n    let a = Cons(5, Box::new(Cons(10, Box::new(List::new(Nil)))));\n\n    // 创建链表b， 并链接到链表a\n    let b = Cons(3, Box::new(a)); // b链接到a时，就把a的所有权给转移走了\n\n    // 创建链表c，并连接到链表a\n    let c = Cons(4, Box::new(a)); // 报错了，因为a的所有权已经被转移了\n}\n```\n\n# 使用引用解决所有权问题\n\n- 引用方式一：\n\n```rust\nuse crate::List::{Cons, Nil};\n#[derive(Debug)]\nenum List<'a> {\n    Cons(i32, Box<&'a List<'a>>),\n    Nil,\n}\n\nfn main() {\n    let a = Cons(5,\n        Box::new(&Cons(10,\n            Box::new(List::new(&Nil))) // 报错，创建临时引用&Nil，但是在a赋值时已经被销毁\n        ) \n    ); // &Nil在这里的结束语句被销毁\n    println!(\"{:?}\", a);\n}\n```\n\n这里涉及到生命周期的问题 `&Nil`是一个临时引用，在这里它的生命周期比a的生命周期要短。编译时就会报错了。\n\n- 引用方式二：\n\n```rust\nuse crate::List::{Cons, Nil};\n#[derive(Debug)]\nenum List<'a> {\n    Cons(i32, Box<&'a List<'a>>),\n    Nil,\n}\n\nfn main() {\n    let a2 = &Nil;\n    let a1 = &Cons(10, Box::new(a2));\n    let a = &Cons(5, Box::new(a1));\n    \n    let b = Cons(3, Box::new(a));\n    let c = Cons(4, Box::new(a));\n    \n    println!(\"{:?}\", b); // Cons(3, Cons(5, Cons(10, Nil)))\n    println!(\"{:?}\", c); // Cons(4, Cons(5, Cons(10, Nil)))\n}\n```\n\n虽然可以实现，但代码看上去太质朴，不够优雅，不能一眼看出嵌套关系，也就是不够直观。\n\n# `Rc<T>` 登场\n\n- 所有权转移引发的血案\n- 使用引用又觉得不够优雅\n\n`Rc<T>`来解决，它支持多重所有权，是`Reference counting`的缩写。它内部维护了一个引用次数计数器，用于确认这个值是否仍在使用。如果对一个值的引用次数为零，那么意味着这个值可以被安全清理掉了，而不会触发引用失效的问题：\n\n```rust\nuse std::rc::Rc;\n\n#[derive(Debug)]\nenum List {\n    Cons(i32, Rc<List>),\n    // 替换Box为Rc\n    Nil,\n}\n\nfn main() {\n    // 创建Rc实例\n    let a = Rc::new(Cons(5,\n                         Rc::new(Cons(10,\n                                      Rc::new(Nil)))));\n    // 这里的Rc::clone只是增加引用计数，虽然使用a.clone也可以实现，但是数据会被深拷贝\n    let b = Cons(3, Rc::clone(&a));\n\n    // 再次增加引用次数\n    let c = Cons(4, Rc::clone(&a));\n\n    println!(\"{:?}\", b);    // Cons(3, Cons(5, Cons(10, Nil)))\n    println!(\"{:?}\", c);    // Cons(4, Cons(5, Cons(10, Nil)))\n}\n```\n\n# 观察引用计数\n\n```rust\nuse std::rc::Rc;\n\n#[derive(Debug)]\nenum List {\n    Cons(i32, Rc<List>),\n    // 替换Box为Rc\n    Nil,\n}\n\nfn main() {\n    // 创建Rc实例\n    let a = Rc::new(Cons(5,\n                         Rc::new(Cons(10,\n                                      Rc::new(Nil)))));\n    println!(\"创建a之后的引用计数：{}\", Rc::strong_count(&a)); // 1\n\n    let b = Cons(3, Rc::clone(&a));\n    println!(\"创建b之后胡引用计数：{}\", Rc::strong_count(&a)); // 2\n\n    // 进入一个代码块作用域\n    {\n        let c = Cons(4, Rc::clone(&a));\n        println!(\"创建c之后的引用计数：{}\", Rc::strong_count(&a)); // 3\n    } // 离开代码块，c的作用域结束，c析构，a的引用计数会减1，变回到2\n\n    println!(\"销毁c之后胡引用计数：{}\", Rc::strong_count(&a)); // 2\n}\n```\n\n# 总结\n\n`Rc<T>`通过不可变引用使得程序的不同部分之间可以共享只读数据。如果`Rc<T>`允许持有多个可变引用的话，那么它就会违反借用规则：只允许多个不可变借用或一个可变借用。\n\n","tags":["Rc<T>","Box<T>","链表","嵌套"],"categories":["Rust","基础"]},{"title":"Rust学习-知识点-2","url":"/2022/10/14/Rust学习-知识点-2/","content":"\n# 在多个线程间共享`Mutex<T>`\n\n我们启动10个线程，并在每个线程中分别为共享的计数器的值加1。如果正常执行完成，最终会让计数器的值从0累计到10：\n\n```rust\nuse std::thread;\nuse std::sync::Mutex;\n\nfn main() {\n    //用于计数的互斥体\n    let counter = Mutex::new(0);\n    // 用于存储线程\n    let mut handles = vec![];\n\n    for _ in 0..10 {\n        let handle = thread::spawn(move || {\n          \t\t\t\t\t\t\t\t\t\t\t// ^^^^^^^ value moved into closure here, in previous iteration of loop \n          \tlet mut num = counter.lock().unwrap();\n            *num += 1;\n        });\n        handles.push(handle);\n    }\n\n    for handle in handles {\n        // 等待所有线程都执行完毕\n        handle.join().unwrap();\n    }\n\n    println!(\"counter: {}\", *counter.lock().unwrap());\n}\n```\n\n代码中尝试将`counter`移动到线程中，编译出错，因为第一次循环时，创建一个子线程，`counter`的所有权已经被移动进去，等到第二次循环创建第二个子线程，`counter`已经没有了所有权。这样就导致第二次移动时理论上肯定会失败。编译器很聪明地捕捉到了这个问题，在编译阶段就扼杀了这个`bug`。\n\n# 尝试使用`Rc<T>`来共享counter\n\n`Rc<T>`是用来共享数据用的，我们可以用尝试一下使用`Rc<T>`在多线程的场景下使用看看能不能解决之前遇到的所有权问题。`Rc<T>`是智能指针，它内部有一个引用计数，被它（包裹）指向的数据的引用次数被`Rc<T>`内部的引用计数记录。`Rc<T>`的`clone()`方法是对智能指针本身的复制，用来指向同一份被智能指针包裹的数据。这样就能巧妙规避数据的数据的所有权问题了：因为循环时可以每次`clone`一个新的智能指针`Rc<T>`出来（这个智能指针指向我们真正要使用的数据）。但是，事实上呢？编译器又来教做人了。\n\n```rust\nuse std::rc::Rc;\nuse std::sync::Mutex;\nuse std::thread;\n\nfn main() {\n    // 将Mutex再包裹一层Rc\n    let counter = Rc::new(Mutex::new(0));\n    let mut handles = vec![];\n\n    for _ in 0..10 {\n        let counter = Rc::clone(&counter);\n        let handle = thread::spawn(move || {        // 报错，Rc<Mutex<i32>>类型无法安全地在线程中传递\n            let mut num = counter.lock().unwrap();\n            *num += 1;\n        });\n        handles.push(handle);\n    }\n\n    for handle in handles {\n        handle.join().unwrap();\n    }\n\n    println!(\"counter: {}\", *counter.lock().unwrap())\n}\n```\n\n当`Rc<T>`管理引用计数时，它会在每次调用`clone`的过程中增加引用计数，并在克隆出的实例被丢弃时减少引用计数，但它并没有使用任何并发原语来保证修改计数的过程不会被另一个线程所打断。\n\n# 使用原子引用计数`Arc<T>`\n\nrust还提供了`Arc<T>`类型，来代替`Rc<T>`类型来解决上面问题，它既拥有类似于`Rc<T>`的行为，又保证了自己可以被安全地用于并发场景：\n\n```rust\nuse std::sync::Arc;\nuse std::sync::Mutex;\nuse std::thread;\n\nfn main() {\n    // 将Rc替换为Arc\n    let counter = Arc::new(Mutex::new(0));\n    let mut handles = vec![];\n\n    for _ in 0..10 {\n        let counter = Arc::clone(&counter);\n        let handle = thread::spawn(move || {\n            let mut num = counter.lock().unwrap();\n            *num += 1;\n        });\n        handles.push(handle);\n    }\n\n    for handle in handles {\n        handle.join().unwrap();\n    }\n\n    println!(\"counter: {}\", *counter.lock().unwrap())\n}\n```\n\n改用` Arc<T>`后上面成功计算出了` counter` 的值。\n\n","tags":["Mutex","多线程","Rc","Arc"],"categories":["Rust","基础"]},{"title":"Rust学习-知识点-1","url":"/2022/10/13/Rust学习-知识点-1/","content":"\n**&和ref的使用有什么不同，哪里需要用`&`？哪里需要用`ref`？**\n\n---\n\n# 一、`&`和`ref`通用的场景\n\n先来看看第1个示例：\n\n```rust\nfn main() {\n    let mut a: i32 = 1;\n    let b = &a;\n    println!(\"{}\", *b); // 1\n\n    let ref c = a;\n    println!(\"{}\", *c); // 1\n}\n```\n\n示例中，`b` 和 `c` 声明的方式不同，但从结果来看并无不同，都是表示一个指针。\n\n- 相同点：这两个指针变量都各自保存了一个内存地址，这个内存地址就是可变变量`a` 的内存地址。\n- 不同点：声明方式不同，其中`let b = &a;` 和 `let ref c = a;` 这里只是语法形式上的不同；只需记忆即可\n\n再来看第2个示例：\n\n```rust\nfn main() {\n    let mut a: i32 = 1;\n\n    let b = &mut a; // 指针 b 本身是不可以修改的，但它指向的内容是可以修改的。\n    *b = 2;\n    println!(\"{}\", a); // 2\n\n    let ref mut c = a; // 指针 c 本身是不可以修改的，但它指向的内容是可以修改的。\n    *c = 3;\n    println!(\"{}\", a); //3\n}\n```\n\n到这里为止，从形式表现来说有点区别，似乎作用一致，那为啥要整两个表现形式出来呢？\n\n# 二、适合用`&`的场景\n\n惯例，不逼逼，看示例：\n\n```rust\nfn foo(x: &mut i32) {\n    *x = 666;\n}\nfn main() {\n    let mut a: i32 = 888;\n    foo(&mut a);\n    println!(\"{}\", a); // 666\n}\n```\n\n人狠话不多，再看：\n\n```rust\nfn foo(ref mut x: i32) {\n    *x = 666;\n}\nfn main() {\n    let mut a: i32 = 888;\n    foo(a);\n    println!(\"{}\", a); // 888\n}\n```\n\n一对比，就比较明显了。经过场景一里面的例子，我们对`&` 和 `ref`的认识，感觉这两货是一个东西；但是在函数/方法签名中的应用时，就有点反直觉了。只能说rust语法规定就是这样，这是龟腚。但是我们以之前其它语言的经验来看待场景二，又会觉得这个结果很合理。\n\n- 因为`foo(a)`的调用语义就是传入一个类型为`i32`的整型变量，而不是传入`&i32`。也就是说传入的是整型变量本身，不是传入整型变量的引用或者指针。我们再看`foo`函数的签名：`fn foo(ref mut x: i32)` ，签名中明确说传入的参数类型是`i32`，没毛病。那这个函数被调用时，内存里面到底是怎么样的呢？看现象，我觉得是这样的：调用`foo(ref mut x: i32)`时，也就是`foo(a)`，传入的是i32类型的一个变量`a`，它的值为`888`（注意不是i32变量的引用或者指针，或者说不是一个内存地址），那么会在内存栈中拷贝一个`888`这个值的副本出来放在栈中，我们可以想象成这个变量叫`a'`,这个`a'`和原来的`a`不是在一个内存地址里面，但它们的值都为`888`，我不想画图，自己想象一下吧，然后把形参`x`指向了这个副本`a'`的内存地址，然后`*x = 666`修改的是这个副本的内存地里面的值，传入的`实参888`没做修改。**不管什么语言，数据在内存中的来龙去脉想清楚非常重要，学习语法不是死记硬背，了解内存模型对掌握一门语言非常重要**\n长话短说，懂的都懂：\n- `foo(a)`调用时，要把`a`的值复制一份放在栈空间中，就是`a`的一个副本。`foo`函数中操作就是这个`a的副本`。你既然修改的是`a的副本`，那关`a`啥事？\n- `a的副本`的值是被修改了，但是`a`的值没有被修改，所以最后打印出来的还是888\n\n那我非要在函数/方法的参数中使用`ref`，还要达到`&`一样的效果呢？也不是不行。\n\n**没有困难，创造困难上 —— 老子**\n\n- 首先肯定是要改变`foo`函数的调用语义，起码要修改一下函数签名吧？函数签名中的参数类型起码得是引用吧？或者叫指针吧？\n- `fn foo(ref x: &mut i32)` 这个就是我们要的修改后的函数签名\n- 函数签名是有了，那么问题来了，我们给x 变量赋值应该怎么操作呢？是 `*x = 666;` 吗？那签名中的ref 不同意了：你当我不存在吗？因为这里有了`ref`，所以前面还得再加一个`*` ，仔细体会体会吧。\n\n```rust\nfn foo(ref x: &mut i32) {\n    **x = 666;\n}\nfn main() {\n    let mut a: i32 = 888;\n    foo(&mut a);\n    println!(\"{}\", a); // 666\n}\n```\n>那么问题来了，为啥这样就又可以了呢？因为形参的类型被改为了 &mut i32 了，那么调用时，foo(&mut a), 传入的是a的内存地址，而不是a变量本身，这个时候**不会发生**把这个传入的值进行拷贝一个副本存在栈中的操作。只是把形参x指向了实参a的内存地址，通俗但可能不够准确地说：x是一个指向指针的指针，也就是说 *x 代表的是 &a，**x是什么自己想想吧。\n\n稍稍总结一下：一个`*`用来表示指针变量取到指针所指的变量，如果指针所指的变量也是个指针变量呢？那就`**`，要是指针变量指向一个指针变量再指向一个指针变量……那就是`***`。所以在函数参数声明中，一般用`&`比较多。\n\n# 三、只能用`ref`的场景\n\n直接上代码示例：\n\n```rust\nfn main() {\n    let s = Some(String::from(\"Hello!\"));\n    match s {\n        Some(t) => println!(\"t = {}\", t),\n        _ => {}\n    }\n    println!(\"s = {}\", s.unwrap());\n}\n```\n\n你觉得rust编译器会让你过？太天真。简简单单一段代码，涉及到了rust中的变量所有权问题。我们先来看编译器的报错结果：\n\n```shell\n   --> src/main.rs:124:24\n    |\n121 |         Some(t) => println!(\"t = {}\", t),\n    |              - value partially moved here\n...\n124 |     println!(\"s = {}\", s.unwrap());\n    |                        ^ value used here after partial move\n    |\n    = note: partial move occurs because value has type `String`, which does not implement the `Copy` trait\nhelp: borrow this field in the pattern to avoid moving `s.0`\n    |\n121 |         Some(ref t) => println!(\"t = {}\", t),\n    |              +++\n\n```\n\nrust编译器就是最好最严厉的那个老师。她说的很清楚了为什么不让你通过，给你分析得明明白白，而且还给出了参考答案。\n\n编译器大佬的意思就是说：你定义了一个变量`s`，它的值是用Some包裹的一个String类型的\"Hello!\"。一开始这个\"Hello!\"的所有权是s的。经过了match s，发现匹配到了Some(t)，也就是s里面还是有货的，这个货呢，就是\"Hello!\"，那现在就要把这个\"Hello!\"赋值给了t，这过程中就会发生变量所有权的转移：所有权由 `s` 转给了 `t`。但是编译器发现，代码最后一行，你竟然又去使用变量s，因为这个时候s所代表的Some包裹已经失去了\"Hello!\"的所有权。编译器认为你违反了内存安全的规则。\n\n那么编译器既然有这个规则，不能硬来，那怎么办呢？那就不转移变量的所有权；那就要提到RUST中的借用的概念。通俗但是可能不准确的说法就是：不用变量直接进行复制操作，把变量的引用或者指针赋值给另外的变量，这就是发生了借用，但是所有权保持不变。这样就符合规则了。\n\n那么回到示例中，关键点就是`Some(t) => println!(\"t = {}\", t)`这句语句有问题，那我们就要对它进行改造，编译器老师都已经告诉我们怎么改造了。就是改为：`Some(ref t) => println!(\"t = {}\", t)`\n\n那有人会问，我能这样改造吗？`Some(& t) => println!(\"t = {}\", t)` ，我也想这样，无奈编译器不答应啊。这也能理解：\n\n- s变量是一个 Some 类型的值， 这个Some里面要么是String类型，要么是None ，但是不能是 &String 类型。所以match s的时候，类型要匹配上。\n- 那么现在Some(ref t)，t 有 ref 的加持，这里就表示是借用，借用就不会发生所有权从s到t的转移，例子中也符合rust的借用规则，编译器老师就会让你通过考核。\n\n我非要用&呢？也不是没有办法，还有一个变通的办法。既然问题根源是s的所有权问题，那我就直接在借用s，而它内部包裹的String变量自然而然也不会发生所有权转移。这不就从根源是解决问题了？浅尝试一下：\n\n```rust\nfn main() {\n    let s = Some(String::from(\"Hello!\"));\n    match &s {\n        Some(t) => println!(\"t = {}\", t),\n        _ => {}\n    }\n    println!(\"s = {}\", s.unwrap());\n}\n```\n\n# 四、更多的例子\n\n```rust\nfn main() {\n    let v = 123;\n\n    let x: &i32 = &v; // OK!\n    let x: &i32 = &(123 + 456); // OK!\n    if let Some(x) = Some(123) {} // OK!\n\n    let ref x: i32 = v; // OK!\n    let ref x: i32 = 123 + 456; // OK!\n    if let Some(ref x) = Some(123) {} // OK!\n\n    if let Some(x: &i32) = Some(&123) {} // Error！\n}\n```\n\n# 五、指针变量的解引用\n\n以下操作，`@cpp`,rust自动解多层嵌套引用大法，妈妈再也不用我数错`*`个数了\n\n```rust\nfn main() {\n    let a: &i32 = &123;\n    let b: &&i32 = &a;\n    let c: &&&i32 = &b;\n\n    println!(\"a = {}, b = {}, c = {}\", a, b, c);\n    println!(\"*a = {}, **b = {}, ***c = {}\", *a, **b, ***c);\n}\n\n/* output\na = 123, b = 123, c = 123\n*a = 123, **b = 123, ***c = 123\n*/\n```\n\n","tags":["rust","ref","指针"],"categories":["Rust","基础"]},{"title":"Hexo服务器搭建","url":"/2022/10/12/Hexo服务器搭建/","content":"\n# 第一部分：服务端操作\n\n## 1. 安装git和nginx\n\n```shell\nyum install -y nginx git\n```\n\n## 2. 添加用户并做免密码登录\n\n### 2.1 服务器端root用户免密登录\n\n```shell\nvim ~/.ssh/authorized_keys    #root用户的免密码登录，将本地机器的ssh公钥添加进去\n```\n\n### 2.2 服务器端添加git用户\n\n```shell\nuseradd git\npasswd git\n\n# 给git用户配置sudo权限\nchmod 740 /etc/sudoers\nvim /etc/sudoers\n# 找到root ALL=(ALL) ALL，在它下方加入一行\ngit ALL=(ALL) ALL\n\nchmod 400 /etc/sudoers\n```\n\n### 2.3 git用户免密登录\n\n```shell\nsu - git\nmkdir -p ~/.ssh\ntouch ~/.ssh/authorized_keys\nchmod 600 ~/.ssh/authorzied_keys\nchmod 700 ~/.ssh\nvim ~/.ssh/authorized_keys   #git用户的免密码登录，将本地机器的ssh公钥添加进去\n```\n\n## 3. 创建仓库并使用git-hooks实现自动部署\n\n```shell\nsudo mkdir -p /var/repo #新建目录，这是git仓库的位置\nsudo mkdir -p /var/www/hexo #站点根目录\ncd /var/repo\nsudo git init --bare blog.git #创建一个名叫blog的仓库\n```\n\n## 4. 创建post-update脚本\n\n```shell\nsudo vim /var/repo/blog.git/hooks/post-update\n```\n\n脚本内容如下：\n\n```shell\n#!/bin/bash\ngit --work-tree=/var/www/hexo --git-dir=/var/repo/blog.git checkout -f\n```\n\n添加权限\n\n```shell\ncd /var/repo/blog.git/hooks/\nsudo chown -R git:git /var/repo/\nsudo chown -R git:git /var/www/hexo\nsudo chmod +x post-update  #赋予其可执行权限\n```\n\n## 5.配置nginx\n\n```shell\ncd /etc/nginx/conf.d\nvim blog.conf\n```\n\n`blog.conf`的内容如下：\n\n```shell\nserver {\n    listen    80 default_server;\n    listen    [::] default_server;\n    server_name    www.blockchainof.com;\n    root    /var/www/hexo;\n}\n```\n\n检查Nginx配置语法并重启nginx:\n\n```shell\nnginx -t # 检查语法\nnginx -s reload # 重新加载\n```\n\n# 第二部分：本地配置（Mac）\n\n## 1. 安装Hexo及其插件\n\n```shell\nsudo npm install hexo-cli hexo-server hexo-deployer-git -g\n```\n\n## 2. 本地初始化博客站点\n\n```shell\nhexo init ~/blog\nnpm install hexo-deployer-git --save\n```\n\n## 3. 本地Hexo配置\n\n```shell\n# 修改Hexo的deploy配置\ncd blog\nvim _config.yml\n\n# 找到deploy配置部分\n# Deployment\n## Docs: https://hexo.io/docs/deployment.html\ndeploy:\n  type: git\n  repo: root@xxx.xx.xxx.xxx:/var/repo/blog.git # IP填写自己服务器的IP即可\n  branch: master\n```\n\n## 4. 将本地Hexo部署到远程服务器\n\n```shell\n# 清除缓存\nhexo clean\n\n# 生成静态页面\nhexo generate\n\n# 将本地静态页面目录部署到云服务器\nhexo delopy\n```\n\n可以将上面的3条指令放在一个shell脚本内，方便部署\n\n```shell\n#!/bin/sh\n\nhexo clean\nhexo generate\nhexo deploy\n```\n\n","tags":["Hexo","git","nginx","免密码登录"],"categories":["环境搭建-Hexo"]}]